import os
import logging
import openai
from openai import OpenAI
import psycopg2
import datetime
from datetime import datetime, time
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext, TypeHandler, Defaults
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import asyncio
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup
from telegram.ext import CallbackQueryHandler
import hashlib
import re
import html
import requests
import aiohttp
from telegram.ext import CallbackContext
from googleapiclient.discovery import build
from telegram.error import TelegramError
from telegram.helpers import escape_markdown
import anthropic
from anthropic import AsyncAnthropic
from telegram.error import TimedOut, BadRequest
import tempfile
import sys

from google.cloud import texttospeech
import os
from pathlib import Path
from dotenv import load_dotenv
from pydub import AudioSegment
import io


application = None
global_assistants_cache = {}


client = OpenAI(timeout=60)

system_message = {
    "check_translation": """
    You are a strict and professional German language teacher tasked with evaluating translations from Russian to German. Your role is to assess translations rigorously, following a predefined grading system without excusing grammatical or structural errors. You are objective, consistent, and adhere strictly to the specified response format.

    Core Responsibilities:

    1. Evaluate translations based on the provided Russian sentence and the user's German translation.
    Apply a strict scoring system, starting at 100 points per sentence, with deductions based on error type, severity, and frequency.
    Ensure feedback is constructive, academic, and focused on error identification and improvement, without praising flawed translations.
    Adhere to B2-level expectations for German proficiency, ensuring translations use appropriate vocabulary and grammar.
    Output results only in the format specified by the user, with no additional words or praise.
    Input Format:
    You will receive the following in the user message:

    Original sentence (Russian)
    User's translation (German)
    
    Scoring Principles:

    Start at 100 points per sentence.
    Deduct points based on error categories (minor, moderate, severe, critical, fatal) as defined below.
    Apply cumulative deductions for multiple errors, but the score cannot be negative (minimum score is 0).
    Enforce maximum score caps:
    85 points: Any grammatical error in verbs, cases, or word order.
    70 points: Two or more major grammatical or semantic errors.
    50 points: Translation misrepresents the original meaning or structure.
    0 points: Empty or completely unrelated translation.
    Feedback must be strict, academic, and constructive, identifying errors, their impact, and suggesting corrections without undue praise.
    Acceptable Variations (No Deductions):

    Minor stylistic variations (e.g., "gl√ºcklich" vs. "zufrieden" for "—Å—á–∞—Å—Ç–ª–∏–≤—ã–π" if contextually appropriate).
    Natural word order variations (e.g., "Gestern wurde das Buch gelesen" vs. "Das Buch wurde gestern gelesen").
    Cultural adaptations for naturalness (e.g., "–≤–∑—è—Ç—å –Ω–∞ –∑–∞–º–µ—Ç–∫—É" as "zur Kenntnis nehmen").
    Error Categories and Deductions:

    Minor Mistakes (1‚Äì5 Points per Issue):
    Minor stylistic inaccuracy: Correct but slightly unnatural word choice (e.g., "Er hat viel Freude empfunden" instead of "Er war sehr froh" for "–û–Ω –±—ã–ª –æ—á–µ–Ω—å —Ä–∞–¥"). Deduct 2‚Äì3 points.
    Awkward but correct grammar: Grammatically correct but slightly unnatural phrasing (e.g., "Das Buch wurde von ihm gelesen" instead of "Er hat das Buch gelesen" when active voice is implied). Deduct 2‚Äì4 points.
    Minor spelling errors: Typos not affecting meaning (e.g., "Biodiversifit√§t" instead of "Biodiversit√§t"). Deduct 1‚Äì2 points.
    Overuse of simple structures: Using basic vocabulary/grammar when nuanced options are expected (e.g., "Er hat gesagt" instead of Konjunktiv I "Er habe gesagt" for indirect speech). Deduct 3‚Äì5 points.
    Behavior: Identify the issue, explain why it‚Äôs suboptimal, suggest a natural alternative. Cap deductions at 15 points for multiple minor errors per sentence.
    
    Moderate Mistakes (6‚Äì15 Points per Issue):
    Incorrect word order causing confusion: Grammatically correct but disrupts flow (e.g., "Im Park gestern spielte er" instead of "Gestern spielte er im Park" for "–í—á–µ—Ä–∞ –æ–Ω –∏–≥—Ä–∞–ª –≤ –ø–∞—Ä–∫–µ"). Deduct 6‚Äì10 points.
    Poor synonym choice: Synonyms altering tone/register (e.g., "Er freute sich sehr" instead of "Er war begeistert" for "–û–Ω –±—ã–ª –≤ –≤–æ—Å—Ç–æ—Ä–≥–µ"). Deduct 8‚Äì12 points.
    Minor violation of prompt requirements: Omitting a required structure without major impact (e.g., using "oder" instead of "entweder‚Ä¶oder" for "–ª–∏–±–æ‚Ä¶–ª–∏–±–æ"). Deduct 10‚Äì15 points.
    Inconsistent register: Overly formal/informal language (e.g., "Er hat Bock darauf" instead of "Er freut sich darauf" for "–û–Ω —Å –Ω–µ—Ç–µ—Ä–ø–µ–Ω–∏–µ–º –∂–¥—ë—Ç"). Deduct 6‚Äì10 points.
    Behavior: Highlight the deviation, its impact, and reference prompt requirements. Limit deductions to 30 points for multiple moderate errors per sentence.
    
    Severe Mistakes (16‚Äì30 Points per Issue):
    Incorrect article/case/gender: Errors not critically altering meaning (e.g., "Der Freund" instead of "Die Freundin" for "–ü–æ–¥—Ä—É–≥–∞"). Deduct 16‚Äì20 points.
    Incorrect verb tense/mode: Wrong tense/mode not fully distorting meaning (e.g., "Er geht" instead of Konjunktiv II "Er ginge" for "–ï—Å–ª–∏ –±—ã –æ–Ω –ø–æ—à—ë–ª"). Deduct 18‚Äì25 points.
    Partial omission of prompt requirements: Failing a required structure impacting accuracy (e.g., "Er baute das Haus" instead of "Das Haus wurde gebaut" for "–î–æ–º –±—ã–ª –ø–æ—Å—Ç—Ä–æ–µ–Ω"). Deduct 20‚Äì30 points.
    Incorrect modal particle usage: Misusing/omitting required particles (e.g., omitting "doch" in "Das ist doch klar" for "–≠—Ç–æ –∂–µ –æ—á–µ–≤–∏–¥–Ω–æ"). Deduct 16‚Äì22 points.
    Behavior: Apply 85-point cap for verb/case/word order errors. Specify the rule violated, quantify impact, and suggest corrections.
    
    Critical Errors (31‚Äì50 Points per Issue):
    Grammatical errors distorting meaning: Wrong verb endings/cases/agreement misleading the reader (e.g., "Er hat das Buch gelesen" instead of "Das Buch wurde gelesen" for "–ö–Ω–∏–≥–∞ –±—ã–ª–∞ –ø—Ä–æ—á–∏—Ç–∞–Ω–∞"). Deduct 31‚Äì40 points.
    Structural change: Changing required structure (e.g., active instead of passive). Deduct 35‚Äì45 points.
    Wrong subjunctive use: Incorrect/missing Konjunktiv I/II (e.g., "Er sagt" instead of "Er habe gesagt" for "–û–Ω —Å–∫–∞–∑–∞–ª"). Deduct 35‚Äì50 points.
    Major vocabulary errors: False friends/wrong terms (e.g., "Gift" instead of "Giftstoff" for "–Ø–¥"). Deduct 31‚Äì40 points.
    Misrepresentation of meaning: Translation conveys different intent (e.g., "Er ging nach Hause" instead of "Er blieb zu Hause" for "–û–Ω –æ—Å—Ç–∞–ª—Å—è –¥–æ–º–∞"). Deduct 40‚Äì50 points.
    Multiple major errors: Two or more severe errors. Deduct 45‚Äì50 points.
    Behavior: Apply 70-point cap for multiple major errors; 50-point cap for misrepresented meaning. Provide detailed error breakdown and corrections.
    
    Fatal Errors (51‚Äì100 Points per Issue):
    Incomprehensible translation: Nonsense or unintelligible (e.g., "Das Haus fliegt im Himmel" for "–î–æ–º –±—ã–ª –ø–æ—Å—Ç—Ä–æ–µ–Ω"). Deduct 51‚Äì80 points.
    Completely wrong structure/meaning: Translation unrelated to original (e.g., "Er liebt Katzen" for "–û–Ω —É—à—ë–ª –¥–æ–º–æ–π"). Deduct 51‚Äì80 points.
    
    Empty translation: No translation provided. Deduct 100 points.

    Additional Evaluation Rules:
    Prompt Adherence: Deduct points for missing required structures (e.g., passive voice, Konjunktiv II, double conjunctions) based on severity (minor: 10‚Äì15 points; severe: 20‚Äì30 points; critical: 35‚Äì50 points).
    Contextual Consistency: Deduct 5‚Äì15 points for translations breaking the narrative flow of the original Russian story.
    B2-Level Appropriateness: Deduct 5‚Äì10 points for overly complex/simple vocabulary or grammar not suited for B2 learners.

    2. **Identify all mistake categories**  
    (you may select multiple categories if needed, but STRICTLY from the enumeration below.  
    Return them as a single comma-separated string, without explanations or formatting):
    Nouns, Cases, Verbs, Tenses, Adjectives, Adverbs, Conjunctions, Prepositions, Moods, Word Order, Other mistake

    3. **Identify all specific mistake subcategories**(you may select multiple subcategories if needed, but STRICTLY from the list below. Return them as a single comma-separated string, without grouping or explanations):
    Gendered Articles, Pluralization, Compound Nouns, Declension Errors,  
    Nominative, Accusative, Dative, Genitive, Akkusativ + Preposition, Dative + Preposition, Genitive + Preposition,  
    Placement, Conjugation, Weak Verbs, Strong Verbs, Mixed Verbs, Separable Verbs, Reflexive Verbs, Auxiliary Verbs, Modal Verbs, Verb Placement in Subordinate Clause,  
    Present, Past, Simple Past, Present Perfect, Past Perfect, Future, Future 1, Future 2, Plusquamperfekt Passive, Futur 1 Passive, Futur 2 Passive,  
    Endings, Weak Declension, Strong Declension, Mixed Declension, Comparative, Superlative, Incorrect Adjective Case Agreement,  
    Multiple Adverbs, Incorrect Adverb Usage,  
    Coordinating, Subordinating, Incorrect Use of Conjunctions,  
    Accusative, Dative, Genitive, Two-way, Incorrect Preposition Usage,  
    Indicative, Declarative, Interrogative, Imperative, Subjunctive 1, Subjunctive 2,  
    Standard, Inverted, Verb-Second Rule, Position of Negation, Incorrect Order in Subordinate Clause, Incorrect Order with Modal Verb

    4. **Provide the correct translation.**  

    ---

    **FORMAT YOUR RESPONSE STRICTLY as follows (without extra words):**  
    Score: X/100  
    Mistake Categories: ... (if there are multiple categories, return them as a comma separated string)  
    Subcategories: ... (if there are multiple subcategories, return them as a comma separated string)   
    Correct Translation: ...  

""",
"generate_sentences":"""
You are an expert Russian language tutor and creative writer specializing in crafting coherent, engaging stories for language learners at the B2 level. 
Your role is to act as a skilled language instructor who designs Russian sentences tailored for translation into German, incorporating specific grammatical structures and thematic requirements 
as outlined in the prompt. You are meticulous, ensuring each sentence aligns with the requested in request linguistic features while maintaining NATURAL, EVERYDAY VOCABULARY and LOGICAL FLOW. 
Your goal is to produce clear, contextually connected sentences FROM THE REAL LIFE that serve as effective learning material, 
formatted precisely as specified, without including translations. 
You are a reliable guide, prioritizing accuracy, creativity, and adherence to the user‚Äôs detailed instructions.

Create the necessary number of connected sentences (the number will be specified by the user as Number of sentences) at a B2 level on a topic that the user will choose and specify as Topic. 
Sentences must be in Russian language for translation into German.

Requirements:

Connect sentences into one logical story.
Use passive voice and Konjunktiv II in at least one sentence.
Topics: the verb "lassen", Futur II, subjective meaning of modal verbs, passive voice in all tenses and alternative constructions, nouns with prepositions/cases, indefinite pronouns, adjectives with prepositions/cases, modal particles, word order in sentences with adverbials of time, cause, manner, place, all types of subordinate clauses.
Use Konjunktiv I for indirect speech.
Include correlative conjunctions (entweder...oder, zwar...aber, nicht nur...sondern auch, sowohl...als auch, weder...noch, je...desto).
Add fixed verb-noun collocations (for example, lead to success, take part, provide assistance, make an impression, exercise control, make a mistake, have significance, take into account).
Each sentence should be on a separate line.
DO NOT add translation! Only the original Russian sentences.
Sentences should contain vocabulary and grammar commonly used in everyday life.

Example output format:
If he had a friend nearby, playing would be more fun.
Knowing that he would soon need to go home, he tried to use every minute.
When it started getting dark, he said goodbye to the neighbor's cat and ran into the house.
After doing his homework, he went to bed thinking about tomorrow.
""", 
"send_me_analytics_and_recommend_me": """
You are an expert German grammar tutor specializing in error analysis and targeted learning recommendations. 
Your role is to analyze user mistakes which you will receive in user_message in a variable:
- **Mistake category:** ...
- **First subcategory:** ...
- **Second subcategory:** ...

Based on provided error categories and subcategories, then identify and output a single, precise German grammar topic (e.g., "Plusquamperfekt") 
for the user to study. 
You act as a concise, knowledgeable guide, ensuring the recommended topic directly addresses the user‚Äôs most critical grammar weaknesses 
while adhering strictly to this instruction format and requirements.

**Provide only one word which describes the user's mistake the best. Give back inly one word or short phrase.**
""",
"check_translation_with_claude": """
You are an expert in Russian and German languages, a professional translator, and a German grammar instructor.

Your task is to analyze the student's translation from Russian to German and provide detailed feedback according to the following criteria:

‚ùóÔ∏è Important: Do NOT repeat the original sentence or the translation in your response. Only provide conclusions and explanations. LANGUAGE OF CAPTIONS: ENGLISH. LANGUAGE OF EXPLANATIONS: GERMAN.

Analysis Criteria:
1. Error Identification:

    Identify the main errors and classify each error into one of the following categories:

        Grammar (e.g., noun cases, verb tenses, prepositions, syntax)

        Vocabulary (e.g., incorrect word choice, false friends)

        Style (e.g., formality, clarity, tone)

2. Grammar Explanation:

    Explain why the grammatical structure is incorrect.

    Provide the corrected form.

    If the error concerns verb usage or prepositions, specify the correct form and proper usage.

3. Alternative Sentence Construction:

    Suggest one alternative version of the sentence.

    Note: Only provide the alternative sentence without explanation.

4. Synonyms:

    Suggest up to two synonyms for incorrect or less appropriate words.

    Format: Original Word: ‚Ä¶
    Possible Synonyms: ‚Ä¶

üîé Important Notes:
Follow the format exactly as specified.

Provide objective, constructive feedback without personal comments.

Avoid introductory or summarizing phrases (e.g., "Here‚Äôs my analysis...").

Keep the response clear, concise, and structured.

Provided Information:
You will receive:
Original Sentence (in Russian)
User's Translation (in German)

Response Format (STRICTLY FOLLOW THIS):

Error 1: (OBLIGATORY: Brief description of the grammatical, lexical, or stylistic error)
Error 2: (OBLIGATORY: Brief description of the grammatical, lexical, or stylistic error)
Error 3: (OBLIGATORY: Brief description of the grammatical, lexical, or stylistic error)
Correct Translation: ‚Ä¶
Grammar Explanation:
Alternative Sentence Construction: ‚Ä¶
Synonyms:
Original Word: ‚Ä¶
Possible Synonyms: ‚Ä¶ (maximum two)
"""
}


# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–≥–µ—Ä –≥–ª–æ–±–∞–ª—å–Ω–æ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)  # –≤—ã–≤–æ–¥ –≤ stdout
    ]
)

load_dotenv(dotenv_path=Path(__file__).parent/".env") # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
# –¢—ã –∫–ª–∞–¥—ë—à—å GOOGLE_APPLICATION_CREDENTIALS=/path/... –≤ .env.
# load_dotenv() –∑–∞–≥—Ä—É–∂–∞–µ—Ç .env –∏ –¥–µ–ª–∞–µ—Ç –≤–∏–¥, —á—Ç–æ —ç—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
# os.getenv(...) —á–∏—Ç–∞–µ—Ç —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è.
# –¢—ã –≤—Ä—É—á–Ω—É—é —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—à—å —ç—Ç–æ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
# os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = key_path
success=load_dotenv(dotenv_path=Path(__file__).parent/".env")


def get_assistant_id_from_db(task_name:str) -> str | None:
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
                SELECT assistant_id FROM assistants
                WHERE task_name = %s;
            """, (task_name, ))
            result = cursor.fetchone()
            return result[0] if result else None

def save_assistant_id_to_db(task_name: str, assistant_id: str) -> None:
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
                INSERT INTO assistants (task_name, assistant_id) 
                VALUES (%s,%s) ON CONFLICT (task_name) DO UPDATE 
                SET assistant_id = EXCLUDED.assistant_id;
            """, (task_name,assistant_id))


def get_or_create_openai_resources(system_instruction: str, task_name: str):

    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å assistant_id –∏–∑ –±–∞–∑—ã
    assistant_id = get_assistant_id_from_db(task_name)
    if assistant_id:
        global_assistants_cache[task_name] = assistant_id
        logging.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è assistant –∏–∑ –±–∞–∑—ã –¥–ª—è '{task_name}': {assistant_id}")
        return assistant_id, None
    # ‚úÖ # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ ‚Äî —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤–æ–≥–æ
    try:
        assistant = client.beta.assistants.create(
        name = "MyAssistant for " + task_name,
        model="gpt-4.1-2025-04-14",
        instructions=system_message[system_instruction]
        )
        global_assistants_cache[task_name] = assistant.id
        save_assistant_id_to_db(task_name, assistant.id)
        logging.info(f"ü§ñ –ù–æ–≤—ã–π assistant —Å–æ–∑–¥–∞–Ω –¥–ª—è –∑–∞–¥–∞—á–∏ '{task_name}': {assistant.id}")
        return assistant.id, None
    
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ assistant –¥–ª—è –∑–∞–¥–∞—á–∏ '{task_name}': {e}")
        raise # –∏–ª–∏ –º–æ–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å None, None


# Buttons in Telegramm
TOPICS = [
    "üíº Business",
    "üè• Medicine",
    "üé® Hobbies",
    "‚úàÔ∏è Travel",
    "üî¨ Science",
    "üíª Technology",
    "üñºÔ∏è Art",
    "üéì Education",
    "üçΩÔ∏è Food",
    "‚öΩ Sports",
    "üåø Nature",
    "üéµ Music",
    "üìö Literature",
    "üß† Psychology",
    "üèõÔ∏è History",
    "üì∞ News"
]


# –ü–æ–ª—É—á–∏ –∫–ª—é—á –Ω–∞ https://console.cloud.google.com/apis/credentials
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# –í–∞—à API-–∫–ª—é—á –¥–ª—è CLAUDE 3.7
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")
if CLAUDE_API_KEY:
    logging.info("‚úÖ CLAUDE_API_KEY —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:   
    logging.error("‚ùå –û—à–∏–±–∫–∞: CLAUDE_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

# –í–∞—à API-–∫–ª—é—á –¥–ª—è mediastack
API_KEY_NEWS = os.getenv("API_KEY_NEWS")

# ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —É—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
VALID_CATEGORIES = [
    'Nouns', 'Cases', 'Verbs', 'Tenses', 'Adjectives', 'Adverbs', 
    'Conjunctions', 'Prepositions', 'Moods', 'Word Order', 'Other mistake'
]

VALID_SUBCATEGORIES = {
    'Nouns': ['Gendered Articles', 'Pluralization', 'Compound Nouns', 'Declension Errors'],
    'Cases': ['Nominative', 'Accusative', 'Dative', 'Genitive', 'Akkusativ + Preposition', 'Dative + Preposition', 'Genitive + Preposition'],
    'Verbs': ['Placement', 'Conjugation', 'Weak Verbs', 'Strong Verbs', 'Mixed Verbs', 'Separable Verbs', 'Reflexive Verbs', 'Auxiliary Verbs', 'Modal Verbs', 'Verb Placement in Subordinate Clause'],
    'Tenses': ['Present', 'Past', 'Simple Past', 'Present Perfect', 'Past Perfect', 'Future', 'Future 1', 'Future 2', 'Plusquamperfekt Passive', 'Futur 1 Passive', 'Futur 2 Passive'],
    'Adjectives': ['Endings', 'Weak Declension', 'Strong Declension', 'Mixed Declension', 'Placement', 'Comparative', 'Superlative', 'Incorrect Adjective Case Agreement'],
    'Adverbs': ['Placement', 'Multiple Adverbs', 'Incorrect Adverb Usage'],
    'Conjunctions': ['Coordinating', 'Subordinating', 'Incorrect Use of Conjunctions'],
    'Prepositions': ['Accusative', 'Dative', 'Genitive', 'Two-way', 'Incorrect Preposition Usage'],
    'Moods': ['Indicative', 'Declarative', 'Interrogative', 'Imperative', 'Subjunctive 1', 'Subjunctive 2'],
    'Word Order': ['Standard', 'Inverted', 'Verb-Second Rule', 'Position of Negation', 'Incorrect Order in Subordinate Clause', 'Incorrect Order with Modal Verb'],
    'Other mistake': ['Unclassified mistake']
}


# ‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º VALID_CATEGORIES –∏ VALID_SUBCATEGORIES –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø—Ä–æ–π—Ç–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∫—É –≤ —Ñ—É–Ω–∫—Ü–∏–∏ log_translation_mistake
VALID_CATEGORIES_lower = [cat.lower() for cat in VALID_CATEGORIES]
VALID_SUBCATEGORIES_lower = {k.lower(): [v.lower() for v in values] for k, values in VALID_SUBCATEGORIES.items()}

# === –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö PostgreSQL ===
DATABASE_URL = os.getenv("DATABASE_URL_RAILWAY")

if DATABASE_URL:
    logging.info("‚úÖ DATABASE_URL —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:   
    logging.error("‚ùå –û—à–∏–±–∫–∞: DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

def get_db_connection():
    return psycopg2.connect(DATABASE_URL, sslmode='require')

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
conn = get_db_connection()
cursor = conn.cursor()
cursor.execute("SELECT version();")
db_version = cursor.fetchone()

print(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞! –í–µ—Ä—Å–∏—è: {db_version}")

cursor.close()
conn.close()


# # === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ ===
TELEGRAM_DeepSeek_BOT_TOKEN = os.getenv("TELEGRAM_DeepSeek_BOT_TOKEN")

if TELEGRAM_DeepSeek_BOT_TOKEN:
    logging.info("‚úÖ TELEGRAM_DeepSeek_BOT_TOKEN —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå TELEGRAM_DeepSeek_BOT_TOKEN –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

# ID –≥—Ä—É–ø–ø—ã
TEST_DEEPSEEK_BOT_GROUP_CHAT_ID = -1002258968332

if TEST_DEEPSEEK_BOT_GROUP_CHAT_ID:
    logging.info("‚úÖ GROUP_CHAT_ID —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå GROUP_CHAT_ID –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

TEST_DEEPSEEK_BOT_GROUP_CHAT_ID = int(TEST_DEEPSEEK_BOT_GROUP_CHAT_ID)

# # === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DeepSeek API ===
# api_key_deepseek = os.getenv("DeepSeek_API_Key")

# if api_key_deepseek:
#     logging.info("‚úÖ DeepSeek_API_Key —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
# else:
#     logging.error("‚ùå –û—à–∏–±–∫–∞: DeepSeek_API_Key –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Open AI API ===
openai.api_key = os.getenv("OPENAI_API_KEY")
if openai.api_key:
    logging.info("‚úÖ OPENAI_API_KEY —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå OPENAI_API_KEY –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

print("üöÄ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è Railway:")
for key, value in os.environ.items():
    print(f"{key}: {value[:10]}...")  # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏




# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –Ω–µ–º–µ—Ü–∫–æ–º
async def send_german_news(context: CallbackContext):
    url = f"http://api.mediastack.com/v1/news?access_key={API_KEY_NEWS}&languages=de&technology&countries=de,au&limit=2" # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ 3 –Ω–æ–≤–æ—Å—Ç–µ–π
    #url = f"http://api.mediastack.com/v1/news?access_key={API_KEY_NEWS}&languages=de&countries=at&limit=3" for Austria

    response = requests.get(url)

    if response.status_code == 200:
        data = response.json()

        if "data" in data and len(data["data"]) > 0:
            print("üì¢ Nachrichten auf Deutsch:")
            for i, article in enumerate(data["data"], start=1):  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ 3 –Ω–æ–≤–æ—Å—Ç–µ–π in API request
                title = article.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
                source = article.get("source", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")
                url = article.get("url", "#")

                message = f"üì∞ {i}. *{title}*\n\nüìå {source}\n\n[–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({url})"
                await context.bot.send_message(
                    chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
                    text=message,
                    parse_mode="Markdown",
                    disable_web_page_preview=False  # –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∂–∞–ª–∏—Å—å –ø—Ä–µ–≤—å—é —Å—Ç—Ä–∞–Ω–∏—Ü
                )
        else:
            await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text="‚ùå –ù–µ—Ç —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Å–µ–≥–æ–¥–Ω—è!")
    else:
        await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text=f"‚ùå –û—à–∏–±–∫–∞: {response.status_code} - {response.text}")



# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã–≤–∞—è –∫—É—Ä—Å–æ—Ä –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
def initialise_database():
    with get_db_connection() as connection:
        with connection.cursor() as curr:

            # Table with user translations with 80 or more points
            curr.execute("""
                CREATE TABLE IF NOT EXISTS successful_translations(
                id SERIAL PRIMARY KEY,
                user_id BIGINT NOT NULL,
                sentence_id BIGINT,
                score INT NOT NULL,
                attempt INT NOT NULL,
                date TIMESTAMP
                );
            """)  

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
            curr.execute("""
                CREATE TABLE IF NOT EXISTS sentences_deepseek (
                        id SERIAL PRIMARY KEY,
                        sentence TEXT NOT NULL
                        
                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            curr.execute("""
                CREATE TABLE IF NOT EXISTS translations_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL,
                        session_id BIGINT,
                        username TEXT,
                        sentence_id INT NOT NULL,
                        user_translation TEXT,
                        score INT,
                        feedback TEXT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)

            # ‚úÖ –ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (—á—Ç–æ–±—ã —É—á–∏—Ç—ã–≤–∞—Ç—å –ª–µ–Ω–∏–≤—ã—Ö)
            curr.execute("""
                CREATE TABLE IF NOT EXISTS messages_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL UNIQUE,
                        username TEXT NOT NULL,
                        message TEXT NOT NULL,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)    

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ daily_sentences
            curr.execute("""
                CREATE TABLE IF NOT EXISTS daily_sentences_deepseek (
                        id SERIAL PRIMARY KEY,
                        date DATE NOT NULL DEFAULT CURRENT_DATE,
                        sentence TEXT NOT NULL,
                        unique_id INT NOT NULL,
                        user_id BIGINT,
                        session_id BIGINT,
                        id_for_mistake_table INT
                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ user_progress
            curr.execute("""
                CREATE TABLE IF NOT EXISTS user_progress_deepseek (
                    session_id BIGINT PRIMARY KEY,
                    user_id BIGINT,
                    username TEXT,
                    start_time TIMESTAMP,
                    end_time TIMESTAMP,
                    completed BOOLEAN DEFAULT FALSE,
                    CONSTRAINT unique_user_session_deepseek UNIQUE (user_id, start_time)
                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –ø–µ—Ä–µ–≤–æ–¥–∞
            curr.execute("""
                CREATE TABLE IF NOT EXISTS translation_errors_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL,
                        category TEXT NOT NULL CHECK (category IN ('–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞', '–õ–µ–∫—Å–∏–∫–∞', '–ü–∞–¥–µ–∂–∏', '–û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è', '–°–∏–Ω—Ç–∞–∫—Å–∏—Å')),  
                        error_description TEXT NOT NULL,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–ø–∞—Å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–≤—è–∑–∏ –ò–ª–∏ –æ—à–∏–±–∫–∏ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ Open AI API
            curr.execute("""
                CREATE TABLE IF NOT EXISTS spare_sentences_deepseek (
                    id SERIAL PRIMARY KEY,
                    sentence TEXT NOT NULL
                );
                         
            """)


            # —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è id assistant API Open AI
            curr.execute("""
                CREATE TABLE IF NOT EXISTS assistants(
                    task_name TEXT PRIMARY KEY,
                    assistant_id TEXT NOT NULL
                    );
            """)


            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–æ–∫
            curr.execute("""
                    CREATE TABLE IF NOT EXISTS detailed_mistakes_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL,
                        sentence TEXT NOT NULL,
                        added_data TIMESTAMP,
                        main_category TEXT CHECK (main_category IN (
                            -- üîπ Nouns
                            'Nouns', 'Cases', 'Verbs', 'Tenses', 'Adjectives', 'Adverbs', 
                            'Conjunctions', 'Prepositions', 'Moods', 'Word Order', 'Other mistake'
                        )),  
                        sub_category TEXT CHECK (sub_category IN (
                            -- üîπ Nouns
                            'Gendered Articles', 'Pluralization', 'Compound Nouns', 'Declension Errors',
                            
                            -- üîπ Cases
                            'Nominative', 'Accusative', 'Dative', 'Genitive',
                            'Akkusativ + Preposition', 'Dative + Preposition', 'Genitive + Preposition',
                            
                            -- üîπ Verbs
                            'Placement', 'Conjugation', 'Weak Verbs', 'Strong Verbs', 'Mixed Verbs', 
                            'Separable Verbs', 'Reflexive Verbs', 'Auxiliary Verbs', 'Modal Verbs',
                            'Verb Placement in Subordinate Clause',
                            
                            -- üîπ Tenses
                            'Present', 'Past', 'Simple Past', 'Present Perfect', 
                            'Past Perfect', 'Future', 'Future 1', 'Future 2',
                            'Plusquamperfekt Passive', 'Futur 1 Passive', 'Futur 2 Passive',

                            -- üîπ Adjectives
                            'Endings', 'Weak Declension', 'Strong Declension', 'Mixed Declension', 
                            'Placement', 'Comparative', 'Superlative', 'Incorrect Adjective Case Agreement',

                            -- üîπ Adverbs
                            'Placement', 'Multiple Adverbs', 'Incorrect Adverb Usage',

                            -- üîπ Conjunctions
                            'Coordinating', 'Subordinating', 'Incorrect Use of Conjunctions',

                            -- üîπ Prepositions
                            'Accusative', 'Dative', 'Genitive', 'Two-way',
                            'Incorrect Preposition Usage',

                            -- üîπ Moods
                            'Indicative', 'Declarative', 'Interrogative', 'Imperative',
                            'Subjunctive 1', 'Subjunctive 2',

                            -- üîπ Word Order
                            'Standard', 'Inverted', 'Verb-Second Rule', 'Position of Negation',
                            'Incorrect Order in Subordinate Clause', 'Incorrect Order with Modal Verb',

                            -- üîπ Other
                            'Unclassified mistake' -- –î–ª—è –æ—à–∏–±–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–ø–∞–ª–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        )),
                        
                        mistake_count INT DEFAULT 1, -- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, –∫–æ–≥–¥–∞ –æ—à–∏–±–∫–∞ –±—ã–ª–∞ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞
                        first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- –í—Ä–µ–º—è –ø–µ—Ä–≤–æ–π —Ñ–∏–∫—Å–∞—Ü–∏–∏ –æ—à–∏–±–∫–∏
                        last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –æ—à–∏–±–∫–∏
                        error_count_week INT DEFAULT 0, -- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
                        sentence_id INT,
                        correct_translation TEXT NOT NULL,
                        score INT,
                        attempt INT DEFAULT 1,

                        -- ‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                        CONSTRAINT for_mistakes_table UNIQUE (user_id, sentence, main_category, sub_category)
                    );

            """)
                         
    connection.commit()

    print("‚úÖ –¢–∞–±–ª–∏—Ü—ã sentences_deepseek, translations_deepseek, daily_sentences_deepseek, messages_deepseek, user_progress_deepseek, translation_errors_deepseek –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")

initialise_database()

async def log_all_messages(update: Update, context: CallbackContext):
    """–õ–æ–≥–∏—Ä—É–µ–º –í–°–ï —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏."""
    try:
        if update.message and update.message.text:
            logging.info(f"üì© –ë–æ—Ç –ø–æ–ª—É—á–∏–ª —Å–æ–æ–±—â–µ–Ω–∏–µ: {update.message.text}")
        else:
            logging.warning("‚ö†Ô∏è update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
    

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –≤—Å–µ—Ö id –°–æ–æ–±—â–µ–Ω–∏–π –∫–æ—Ç–æ—Ä—ã–µ –ø–æ—Ç–æ–º —è –±—É–¥—É —É–¥–∞–ª—è—Ç—å, –≠—Ç–æ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ
def add_service_msg_id(context, message_id):
    context_id = id(context)
    logging.info(f"DEBUG: context_id={context_id} –≤ add_service_msg_id, –¥–æ–±–∞–≤–ª—è–µ–º message_id={message_id}")
    if "service_message_ids" not in context.user_data:
        logging.info(f"üìù –°–æ–∑–¥–∞—ë–º service_message_ids –¥–ª—è user_id={context._user_id}")
        context.user_data["service_message_ids"] = []
    context.user_data["service_message_ids"].append(message_id)
    logging.info(f"DEBUG: –î–æ–±–∞–≤–ª–µ–Ω message_id: {message_id}, —Ç–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫: {context.user_data['service_message_ids']}")


#–ò–º–∏—Ç–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ —Å typing-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º
async def simulate_typing(context, chat_id, duration=3):
    """–≠–º—É–ª–∏—Ä—É–µ—Ç –Ω–∞–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ –≤ —á–∞—Ç–µ."""
    await context.bot.send_chat_action(chat_id=chat_id, action="typing")
    await asyncio.sleep(duration)  # –ò–º–∏—Ç–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π —Ç–µ–∫—Å—Ç–∞



# Buttons in Telegram
async def send_main_menu(update: Update, context: CallbackContext):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é —Å –∫–Ω–æ–ø–∫–∞–º–∏."""
    keyboard = [
        ["üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É"],  # ‚ùó –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç–µ–∫—Å—Ç –∑–¥–µ—Å—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
        ["üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥", "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥"],
        ["üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥", "üü° –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"]
    ]
    
    # —Å–æ–∑–¥–∞–µ–º –≤ —Å–ª–æ–≤–∞—Ä–µ –∫–ª—é service_message_ids –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö id –°–æ–æ–±—â–µ–Ω–∏–π, –î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –±—ã–ª–æ –∏—Ö —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞
    context.user_data.setdefault("service_message_ids", [])

    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

    # 1Ô∏è‚É£ –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
    #await update.message.reply_text("‚è≥ –û–±–Ω–æ–≤–ª—è–µ–º –º–µ–Ω—é...", reply_markup=ReplyKeyboardMarkup([[]], resize_keyboard=True))

    # 2Ô∏è‚É£ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ –º–µ–Ω—é
    await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏:", reply_markup=reply_markup)

async def debug_message_handler(update: Update, context: CallbackContext):
    print(f"üîπ –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ (DEBUG): {update.message.text}")


async def handle_button_click(update: Update, context: CallbackContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ –∫–Ω–æ–ø–∫–∏ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é."""
    
    print("üõ† handle_button_click() –≤—ã–∑–≤–∞–Ω!")  # –õ–æ–≥–∏—Ä—É–µ–º —Å–∞–º –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏

    if not update.message:
        print("‚ùå –û—à–∏–±–∫–∞: update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!")
        return
    
    text = update.message.text.strip()
    print(f"üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {text}")

    # –î–æ–±–∞–≤–ª—è–µ–º message_id –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–∏—Å–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    add_service_msg_id(context, update.message.message_id)
    logging.info(f"üì© –î–æ–±–∞–≤–ª–µ–Ω message_id –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {update.message.message_id}")
    
    if text == "üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É":
        await choose_topic(update, context)
    elif text == "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
        await letsgo(update, context)
    elif text == "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
        await done(update, context)
    elif text == "üü° –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É":
        await user_stats(update, context)
    elif text == "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
        logging.info(f"üìå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {update.message.from_user.id} –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'. –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É.")
        await check_translation_from_text(update, context)  # ‚úÖ –¢–µ–ø–µ—Ä—å —Å—Ä–∞–∑—É –∑–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤


# üîπ **–§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤**
async def check_translation_from_text(update: Update, context: CallbackContext):
    user_id = update.message.from_user.id

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã
    if "pending_translations" not in context.user_data or not context.user_data["pending_translations"]:
        logging.info(f"‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–∞–∂–∞–ª 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥', –Ω–æ —É –Ω–µ–≥–æ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤!")
        msg_1 = await update.message.reply_text("‚ùå –£ –≤–∞—Å –Ω–µ—Ç –Ω–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤! –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ø–µ—Ä–µ–≤–æ–¥, –∑–∞—Ç–µ–º –Ω–∞–∂–º–∏—Ç–µ 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'.")
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å ID={msg_1.message_id}")
        add_service_msg_id(context, msg_1.message_id)
        return

    logging.info(f"üìå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'. –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤.")

    # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ "–Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
    formatted_translations = []
    for t in context.user_data["pending_translations"]:
        match = re.match(r"^(\d+)\.\s*(.+)", t)  # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏ –ø–µ—Ä–µ–≤–æ–¥
        if match:
            formatted_translations.append(f"{match.group(1)}. {match.group(2)}")

    # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤, –≤—ã–¥–∞—ë–º –æ—à–∏–±–∫—É
    if not formatted_translations:
        msg_2 = await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞: –ù–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏!")
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ for translation —Å ID={msg_2.message_id}")
        add_service_msg_id(context, msg_2.message_id)
        return

    # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É "/translate" —Å –Ω—É–∂–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º
    translation_text = "/translate\n" + "\n".join(formatted_translations)

    # ‚úÖ –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–∂–∏–¥–∞—é—â–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (—á—Ç–æ–±—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–ª–∏—Å—å)
    #context.user_data["pending_translations"] = []

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π –≤ `check_user_translation()`
    logging.info(f"üìú –ü–µ—Ä–µ–¥–∞—ë–º –≤ check_user_translation():\n{translation_text}")

    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ `check_user_translation()`
    await check_user_translation(update, context, translation_text)

    

async def start(update: Update, context: CallbackContext):
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é."""
    context.user_data.setdefault("service_message_ids", [])  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫
    await send_main_menu(update, context)

async def log_message(update: Update, context: CallbackContext):
    """–ª–æ–≥–∏—Ä—É—é—Ç—Å—è (—Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è) –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    if not update.message: #–ï—Å–ª–∏ update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∑–Ω–∞—á–∏—Ç, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–æ—Ç–æ, –≤–∏–¥–µ–æ, —Å—Ç–∏–∫–µ—Ä).
        return #–í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –º—ã –Ω–µ –ª–æ–≥–∏—Ä—É–µ–º —ç—Ç–æ –∏ –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏
    
    user = update.message.from_user # –î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ —Å–æ–¥–µ—Ä–∂–∏—Ç ID –∏ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    message_text = update.message.text.strip() if update.message else "" #—Å–∞–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è.

    if not message_text:
        print("‚ö†Ô∏è –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ.")
        return
    
    username = user.username or f"{user.first_name or ''} {user.last_name or ''}".strip()
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    print(f"üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {username} ({user.id}): {message_text}")

    conn = get_db_connection()
    cursor = conn.cursor()
    try: 
        cursor.execute("""
            INSERT INTO messages_deepseek (user_id, username, message)
            VALUES(%s, %s, %s)
            ON CONFLICT (user_id)
            DO UPDATE SET timestamp = NOW();
            """,
            (user.id, username, 'user_message')
        )

        conn.commit()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑—É: {e}")
    finally:
        cursor.close()
        conn.close()

# —É—Ç—Ä–µ–Ω–Ω–µ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ —á–ª–µ–Ω–æ–º –≥—Ä—É–ø–ø—ã
async def send_morning_reminder(context:CallbackContext):
    time_now= datetime.now().time()
    # –§–æ—Ä–º–∏—Ä—É–µ–º —É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = (
        f"üåÖ {'–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ' if time(2, 0) < time_now < time(10, 0) else ('–î–æ–±—Ä—ã–π –¥–µ–Ω—å' if time(10, 1) < time_now < time(17, 0) else '–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä')}!\n\n"
        "–ß—Ç–æ–±—ã –ø—Ä–∏–Ω—è—Ç—å —É—á–∞—Å—Ç–∏–µ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É. –ü–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –Ω–∞—á–∞–ª–æ —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–∫–∏ üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥.\n\n"
        "üìå –í–∞–∂–Ω–æ:\n"
        "üîπ –ü–µ—Ä–µ–≤–æ–¥–∏—Ç–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ.\n\n"
        "üîπ –ü–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤—ã–ø–æ–ª–Ω–∏—Ç–µ üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –Ω–∞–∂–∞—Ç–∏–µ–º ‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥.\n\n"
        "üîπ –í 09:05, 14:05 –∏ 18:05 - –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏—Ç–æ–≥–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —É—á–∞—Å—Ç–Ω–∏–∫—É.\n\n"
        "üîπ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª—É—á–∏–º –≤ 22:52.\n\n"
        "üîπ –£–∑–Ω–∞—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É - –∂–º–∏ üü° –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.\n"
    )

    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥
    commands = (
        "üìú **–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**\n"
        "üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É - –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞\n"
        "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ - –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã.\n"
        "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ - –ü–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥\n"
        "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ - –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è.\n"
        "/stats - –£–∑–Ω–∞—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n"
    )

    await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text = message)
    #await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text= commands)



async def letsgo(update: Update, context: CallbackContext):
    user = update.message.from_user
    user_id = user.id
    chat_id = update.message.chat_id  # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∞—Ç—Ä–∏–±—É—Ç
    username = user.username or user.first_name

    context.user_data.setdefault("service_message_ids", [])

     # ‚úÖ –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—è `start_times` –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –µ–≥–æ (—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –Ω–∞—á–∞–ª–µ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞, –ö–æ–≥–¥–∞ –µ—â—ë –Ω–µ—Ç —Å–ª–æ–≤–∞—Ä—è)
    if "start_times" not in context.user_data:
        context.user_data["start_times"] = {}
    
    # ‚úÖ –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞ **–¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**
    context.user_data["start_times"][user_id] = datetime.now()

    # # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–∞–π–º–µ—Ä–æ–º
    # timer_message = await update.message.reply_text(f"‚è≥ –í—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: 0 –º–∏–Ω 0 —Å–µ–∫")

    # # ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ–º `start_timer()` —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
    # asyncio.create_task(start_timer(chat_id, context, timer_message.message_id, user_id))


    # üîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–µ–º—É
    chosen_topic = context.user_data.get("chosen_topic")
    if not chosen_topic:
        msg_1 = await update.message.reply_text(
            "‚ùå –í—ã –Ω–µ –≤—ã–±—Ä–∞–ª–∏ —Ç–µ–º—É! –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –∏—Å–ø–æ–ª—å–∑—É—è –∫–Ω–æ–ø–∫—É 'üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É'"
        )
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ —Ç–µ–º—ã —Å ID={msg_1.message_id}")
        add_service_msg_id(context, msg_1.message_id)
        return  # ‚õî –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏, –µ—Å–ª–∏ —Ç–µ–º–∞ –Ω–µ –≤—ã–±—Ä–∞–Ω–∞

    conn = get_db_connection()
    cursor = conn.cursor()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª –ª–∏ —É–∂–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥ (–Ω–æ —Ç–æ–ª—å–∫–æ –∑–∞ –°–ï–ì–û–î–ù–Ø!)
    cursor.execute("""
        SELECT user_id FROM user_progress_deepseek
        WHERE user_id = %s AND start_time::date = CURRENT_DATE AND completed = FALSE;
        """, (user_id, ))
    active_session = cursor.fetchone()

    if active_session is not None:
        logging.info(f"‚è≥ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {username} ({user_id}) —É–∂–µ –Ω–∞—á–∞–ª –ø–µ—Ä–µ–≤–æ–¥ —Å–µ–≥–æ–¥–Ω—è.")
        #await update.message.reply_animation("https://media.giphy.com/media/3o7aD2saalBwwftBIY/giphy.gif")
        msg_2 = await update.message.reply_text("‚ùå –í—ã —É–∂–µ –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–≤–æ–¥! –ó–∞–≤–µ—Ä—à–∏—Ç–µ –µ–≥–æ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –∑–∞–ø—É—Å–∫–æ–º –Ω–∞–∂–∞–≤ –Ω–∞ –∫–Ω–æ–ø–∫—É '‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'")
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ —Å ID={msg_2.message_id}")
        add_service_msg_id(context, msg_2.message_id)
        cursor.close()
        conn.close()
        return

    # ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–∞–µ–º –≤—á–µ—Ä–∞—à–Ω–∏–µ —Å–µ—Å—Å–∏–∏**
    cursor.execute("""
        UPDATE user_progress_deepseek
        SET end_time = NOW(), completed = TRUE
        WHERE user_id = %s AND start_time::date < CURRENT_DATE AND completed = FALSE;
    """, (user_id,))

    # üîπ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º session_id –Ω–∞ –æ—Å–Ω–æ–≤–µ user_id + —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    session_id = int(hashlib.md5(f"{user_id}{datetime.now()}".encode()).hexdigest(), 16) % (10 ** 12)

    # ‚úÖ **–°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ `user_progress`, –ù–ï –ó–ê–¢–ò–†–ê–Ø —Å—Ç–∞—Ä—ã–µ —Å–µ—Å—Å–∏–∏ –∏ –ø–æ–ª—É—á–∞–µ–º `session_id`****
    cursor.execute("""
        INSERT INTO user_progress_deepseek (session_id, user_id, username, start_time, completed) 
        VALUES (%s, %s, %s, NOW(), FALSE);
    """, (session_id, user_id, username))
    
    conn.commit()


    # ‚úÖ **–í—ã–¥–∞—ë–º –Ω–æ–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è**
    sentences = [s.strip() for s in await get_original_sentences(user_id, context) if s.strip()]

    if not sentences:
        msg_3 = await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: ‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ —Å ID={msg_3.message_id}")
        add_service_msg_id(context, msg_3.message_id)       
        cursor.close()
        conn.close()
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å (–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–µ–ª–∞–ª /getmore)
    cursor.execute("""
        SELECT COUNT(*) FROM daily_sentences_deepseek WHERE date = CURRENT_DATE AND user_id = %s;
    """, (user_id,))
    last_index = cursor.fetchone()[0]

    # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å, –±—ã–ª–∏ –ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    original_sentences = sentences
    sentences = correct_numbering(sentences)

    for before, after in zip(original_sentences, sentences):
        if before != after:
            logging.info(f"‚ö†Ô∏è –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω—É–º–µ—Ä–∞—Ü–∏—è: '{before}' ‚Üí '{after}'")

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º b—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –±–∞–∑—É
    tasks = []

    for i, sentence in enumerate(sentences, start=last_index+1):
        # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —Ç–∞–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º
        cursor.execute("""
            SELECT id_for_mistake_table
            FROM daily_sentences_deepseek
            WHERE sentence = %s
            LIMIT 1;
        """, (sentence, ))
        result = cursor.fetchone()

        if result:
            id_for_mistake_table = result[0]
            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π id_for_mistake_table = {id_for_mistake_table} –¥–ª—è —Ç–µ–∫—Å—Ç–∞: '{sentence}'")
        else:
            # ‚úÖ –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç ‚Äî –ø–æ–ª—É—á–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π ID –∏ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π
            cursor.execute("""
                SELECT MAX(id_for_mistake_table) FROM daily_sentences_deepseek;
            """)
            result = cursor.fetchone()
            max_id = result[0] if result and result[0] is not None else 0
            id_for_mistake_table = max_id + 1
            logging.info(f"‚úÖ –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –Ω–æ–≤—ã–π id_for_mistake_table = {id_for_mistake_table} –¥–ª—è —Ç–µ–∫—Å—Ç–∞: '{sentence}'")

        # ‚úÖ –í—Å—Ç–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü—É —Å id_for_mistake_table
        cursor.execute("""
            INSERT INTO daily_sentences_deepseek (date, sentence, unique_id, user_id, session_id, id_for_mistake_table)
            VALUES (CURRENT_DATE, %s, %s, %s, %s, %s);
        """, (sentence, i, user_id, session_id, id_for_mistake_table))
        
        tasks.append(f"{i}. {sentence}")

    conn.commit()
    cursor.close()
    conn.close()

    logging.info(f"üöÄ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {username} ({user_id}) –Ω–∞—á–∞–ª –ø–µ—Ä–µ–≤–æ–¥. –ó–∞–ø–∏—Å–∞–Ω–æ {len(tasks)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")

    # üîπ **–°–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**
    context.user_data["pending_translations"] = []


    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ **–∏ —Ç–∞–π–º–µ—Ä–æ–º**
    task_text = "\n".join(tasks)
    print(f"Sentences before sending to the user: {task_text}")

    text= (
    f"üöÄ {user.first_name}, –í—ã –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–≤–æ–¥! –í—Ä–µ–º—è –ø–æ—à–ª–æ.\n\n"
    "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à–∏ –ø–µ—Ä–µ–≤–æ–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n1. Mein Name ist Konchita.\n\n"
    )

    msg_4 = await context.bot.send_message(chat_id=update.message.chat_id, text=text)
    logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å ID={msg_4.message_id}")
    add_service_msg_id(context, msg_4.message_id)

    msg_5 = await update.message.reply_text(
        f"{user.first_name}, –í–∞—à–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è:\n{task_text}\n\n"
        #"–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –≤—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ –≤—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã, –Ω–∞–∂–º–∏—Ç–µ **'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'**, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Ö.\n"
        #"–ö–æ–≥–¥–∞ –≤—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã –±—É–¥—É—Ç –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã, –Ω–∞–∂–º–∏—Ç–µ **'‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'**, —á—Ç–æ–±—ã –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è!"
    )
    logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ —Å ID={msg_5.message_id}")
    add_service_msg_id(context, msg_5.message_id)



# üîπ **–§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã, –Ω–æ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö**
async def handle_user_message(update: Update, context: CallbackContext):
    # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ update.message –¥–∞–Ω–Ω—ã–µ
    if update.message is None or update.message.text is None:
        logging.warning("‚ö†Ô∏è update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")
        return  # ‚õî –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç

    user_id = update.message.from_user.id
    text = update.message.text.strip()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–æ–º (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π)
    pattern = re.compile(r"^(\d+)\.\s*([^\d\n]+(?:\n[^\d\n]+)*)", re.MULTILINE)
    translations = pattern.findall(text)

    if translations:
        if "pending_translations" not in context.user_data:
            context.user_data["pending_translations"] = []

        for num, trans in translations:
            full_translation = f"{num}. {trans.strip()}"
            context.user_data["pending_translations"].append(full_translation)
            logging.info(f"üìù –î–æ–±–∞–≤–ª–µ–Ω –ø–µ—Ä–µ–≤–æ–¥: {full_translation}")

        msg = await update.message.reply_text(
            "‚úÖ –í–∞—à –ø–µ—Ä–µ–≤–æ–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω.\n\n"
            "–ö–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã, –Ω–∞–∂–º–∏—Ç–µ:\n"
            "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥.\n\n"
            "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —á—Ç–æ–±—ã –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è.\n"
            )
        add_service_msg_id(context, msg.message_id)
    else:
        await handle_button_click(update, context)


async def delete_message_with_retry(bot, chat_id, message_id, retries=3, delay=2):
    for attempt in range(retries):
        try:
            await bot.delete_message(chat_id=chat_id, message_id=message_id)
            print(f"DEBUG: –£—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ {message_id}")
            return
        except TimedOut as e:
            print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}): {e}")
            if attempt < retries - 1:
                await asyncio.sleep(delay)
        except BadRequest as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Telegram –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}: {e}")
            return  # –°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ —É–∂–µ —É–¥–∞–ª–µ–Ω–æ
        except Exception as e:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}: {e}")
            return
    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {message_id} –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫")


async def done(update: Update, context: CallbackContext):
    user = update.message.from_user
    user_id = user.id
    context_id = id(context)
    logging.info(f"DEBUG: context_id={context_id} –≤ done")


    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è
    cursor.execute("""
        SELECT session_id
        FROM user_progress_deepseek 
        WHERE user_id = %s AND completed = FALSE
        ORDER BY start_time DESC
        LIMIT 1;""", 
        (user_id,))
    session = cursor.fetchone()

    if not session:
        msg_1 = await update.message.reply_text("‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏: 'üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É' -> 'üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥' —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")
        logging.info(f"üì© –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Å–µ—Å—Å–∏–∏ —Å ID={msg_1.message_id}")
        add_service_msg_id(context, msg_1.message_id)
        cursor.close()
        conn.close()
        return
    session_id = session[0]   # ID —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏

    # üìä –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    cursor.execute("""
        SELECT COUNT(*) 
        FROM daily_sentences_deepseek 
        WHERE user_id = %s AND session_id = %s;
        """, (user_id, session_id))
    
    total_sentences = cursor.fetchone()[0]
    logging.info(f"üîÑ –û–∂–∏–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ –≤—Å–µ—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}. –í—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {total_sentences}")

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (–∏–∑ pending_translations)
    pending_translations_count = len(context.user_data.get("pending_translations", []))
    logging.info(f"üì§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {pending_translations_count}")

    # –î–∞–µ–º –≤—Ä–µ–º—è –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∏–∑ check_translation_from_text)
    logging.info("‚è≥ –î–∞–µ–º –≤—Ä–µ–º—è –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ –±–∞–∑—É...")
    await asyncio.sleep(5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–µ—Ä–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ –±–∞–∑–µ
    cursor.execute("""
        SELECT COUNT(*) 
        FROM translations_deepseek 
        WHERE user_id = %s AND session_id = %s;
        """, (user_id, session_id))
    translated_count = cursor.fetchone()[0]
    logging.info(f"üì¨ –£–∂–µ –∑–∞–ø–∏—Å–∞–Ω–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {translated_count}/{pending_translations_count}")


    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –±–æ–ª—å—à–µ, —á–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —Å–µ—Å—Å–∏–∏
    if pending_translations_count > total_sentences:
        logging.warning(f"‚ö†Ô∏è pending_translations_count ({pending_translations_count}) –±–æ–ª—å—à–µ total_sentences ({total_sentences})")
        pending_translations_count = min(pending_translations_count, total_sentences)

    #await asyncio.sleep(10)


    # –û–∂–∏–¥–∞–µ–º, –ø–æ–∫–∞ –≤—Å–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–µ –∑–∞–ø–∏—à—É—Ç—Å—è –≤ –±–∞–∑—É
    max_attempts = 30  # –ú–∞–∫—Å–∏–º—É–º 30 –ø–æ–ø—ã—Ç–æ–∫ (30 * 5 —Å–µ–∫—É–Ω–¥ = 150 —Å–µ–∫—É–Ω–¥)
    attempt = 0
    start_time = datetime.now()

    logging.info(f"üö© START while-loop: translated_count={translated_count}, pending_translations_count={pending_translations_count}")

    while translated_count < pending_translations_count and attempt < max_attempts:
        cursor.execute("""
            SELECT COUNT(*) 
            FROM translations_deepseek 
            WHERE user_id = %s AND session_id = %s;
            """, (user_id, session_id))
        translated_count = cursor.fetchone()[0]
        elapsed_time = (datetime.now() - start_time).total_seconds()
        logging.info(f"‚åõ –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–ø–∏—Å—å –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {translated_count}/{pending_translations_count}. –ü—Ä–æ—à–ª–æ {elapsed_time:.1f} —Å–µ–∫, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}")

        if translated_count >= pending_translations_count:
            logging.info(f"‚úÖ –í—Å–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –∑–∞–ø–∏—Å–∞–Ω—ã: {translated_count}/{pending_translations_count}")
            break

        await asyncio.sleep(5)  # –ñ–¥–µ–º 5 —Å–µ–∫—É–Ω–¥
        attempt += 1

    # –õ–æ–≥–∏—Ä—É–µ–º, –µ—Å–ª–∏ –Ω–µ –≤—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã –∑–∞–ø–∏—Å–∞–Ω—ã
    if translated_count < pending_translations_count and attempt >= max_attempts:
        logging.warning(f"‚ö†Ô∏è –ù–µ –≤—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã –∑–∞–ø–∏—Å–∞–Ω—ã –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫: {translated_count}/{pending_translations_count}")


    # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–µ—Å—Å–∏—é
    cursor.execute("""
        UPDATE user_progress_deepseek
        SET end_time = NOW(), completed = TRUE
        WHERE user_id = %s AND session_id = %s AND completed = FALSE;
        """, (user_id, session_id))
    conn.commit()

    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º pending_translations
    context.user_data["pending_translations"] = []
    logging.info(f"DEBUG: –°–±—Ä–æ—à–µ–Ω—ã pending_translations –¥–ª—è user_id={user_id}")

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    if translated_count == 0:
        completion_msg = await update.message.reply_text(
            f"üòî –í—ã –Ω–µ –ø–µ—Ä–µ–≤–µ–ª–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ {total_sentences} –≤ —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏.\n"
            f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–æ–∫ 'üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É' -> 'üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥'.",
            parse_mode="Markdown"
        )
    elif translated_count < total_sentences:
        completion_msg = await update.message.reply_text(
            f"‚ö†Ô∏è *–í—ã –ø–µ—Ä–µ–≤–µ–ª–∏ {translated_count} –∏–∑ {total_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π!*\n"
            f"–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω, –Ω–æ –Ω–µ –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã. –≠—Ç–æ –ø–æ–≤–ª–∏—è–µ—Ç –Ω–∞ –≤–∞—à –∏—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª.",
            parse_mode="Markdown"
        )
    else:
        completion_msg = await update.message.reply_text(
            f"üéâ *–í—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥!*\n"
            f"–í—Å–µ {total_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã! üöÄ",
            parse_mode="Markdown"
        )
    
    message_ids = context.user_data.get("service_message_ids", [])
    
    # Deletion messages from the chat
    for message_id in message_ids:
        await delete_message_with_retry(context.bot, update.effective_chat.id, message_id)

    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫
    logging.info(f"DEBUG: –°–±—Ä–∞—Å—ã–≤–∞–µ–º service_message_ids. –ë—ã–ª–æ: {context.user_data['service_message_ids']}")
    context.user_data["service_message_ids"] = []

    cursor.close()
    conn.close()


def correct_numbering(sentences):
    """!?! –ù–æ —ç—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª–∏–Ω—ã —à–∞–±–ª–æ–Ω–∞ –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–±–æ–∫(?<=^\d+\.), –ü–æ—ç—Ç–æ–º—É –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç.–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é, —É–¥–∞–ª—è—è —Ç–æ–ª—å–∫–æ –≤—Ç–æ—Ä—É—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Ü–∏—Ñ—Ä—É.
    (?<=^\d+\.) ‚Äî –ù–∞–π–¥–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥ –Ω–∏–º –µ—Å—Ç—å —á–∏—Å–ª–æ —Å —Ç–æ—á–∫–æ–π –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
    –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è lookbehind assertion. –ù–∞–ø—Ä–∏–º–µ—Ä, 29. –±—É–¥–µ—Ç –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –Ω–µ –∑–∞–º–µ–Ω–µ–Ω–æ.
    \s*\d+\.\s* ‚Äî —Ç–µ–ø–µ—Ä—å –∑–∞–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤—Ç–æ—Ä–∞—è —Ü–∏—Ñ—Ä–∞."""
    corrected_sentences = []
    for sentence in sentences:
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ **–≤—Ç–æ—Ä–æ–µ** —á–∏—Å–ª–æ, –æ—Å—Ç–∞–≤–ª—è—è –ø–µ—Ä–≤–æ–µ
        cleaned_sentence = re.sub(r"^(\d+)\.\s*\d+\.\s*", r"\1. ", sentence).strip()
        corrected_sentences.append(cleaned_sentence)
    return corrected_sentences


# –°–æ–∑–¥–∞—ë—Ç –∫–Ω–æ–ø–∫–∏ —Å —Ç–µ–º–∞–º–∏ (Business, Medicine, Hobbies –∏ —Ç. –¥.).
async def choose_topic(update: Update, context: CallbackContext):
    print("üîπ –§—É–Ω–∫—Ü–∏—è choose_topic() –≤—ã–∑–≤–∞–Ω–∞!")  # üëà –õ–æ–≥–∏—Ä—É–µ–º –≤—ã–∑–æ–≤
    global TOPICS
    
    context.user_data.setdefault("service_message_ids", [])
    message_ids = context.user_data["service_message_ids"]
    #message_ids = context.user_data.get("service_message_ids", [])
    print(f"DEBUG: message_ids in choose_topic function: {message_ids}")
    
    buttons = []
    row = []
    for i, topic in enumerate(TOPICS, 1):
        row.append(InlineKeyboardButton(topic, callback_data=topic))
        if i % 2 == 0:
            buttons.append(row)
            row = []
    if row:  # –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –∫–Ω–æ–ø–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∫—Ä–∞—Ç–Ω—ã 3 (–Ω–∞–ø—Ä–∏–º–µ—Ä 10 —Ç–µ–º ‚Äî 9 + 1)
        buttons.append(row)

    reply_markup = InlineKeyboardMarkup(buttons)

    if update.callback_query:
        msg = await update.callback_query.message.edit_text("üìå –í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:", reply_markup=reply_markup)
        add_service_msg_id(context, msg.message_id)
    else:
        msg_1 = await update.message.reply_text("üìå –í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:", reply_markup=reply_markup) #–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–º–∏ –∫–Ω–æ–ø–∫–∞–º–∏.
        add_service_msg_id(context, msg_1.message_id)



# –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç –Ω–∞ –∫–Ω–æ–ø–∫—É, Telegram –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç callback-–∑–∞–ø—Ä–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –º—ã –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –≤ topic_selected().
async def topic_selected(update: Update, context: CallbackContext):
    """Handles the button click event when the user selects a topic."""
    query = update.callback_query
    await query.answer()  # Acknowledge the button press: –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –Ω–∞–∂–∞—Ç–∏–µ –∫–Ω–æ–ø–∫–∏ (–∏–Ω–∞—á–µ –∫–Ω–æ–ø–∫–∞ –±—É–¥–µ—Ç –≤–∏—Å–µ—Ç—å)

    if not query.data:
        logging.error("‚ùå –û—à–∏–±–∫–∞: callback_data –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!")
        return

    chosen_topic = query.data  # Get the selected topic: # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–∫–∞–∫—É—é –∫–Ω–æ–ø–∫—É –Ω–∞–∂–∞–ª–∏)
    logging.info(f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª —Ç–µ–º—É: {chosen_topic}")

    context.user_data["chosen_topic"] = chosen_topic  # Store it in user data: # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é —Ç–µ–º—É –≤ –ø–∞–º—è—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    msg_1 = await query.message.reply_text(f"‚úÖ –í—ã –≤—ã–±—Ä–∞–ª–∏ —Ç–µ–º—É: {chosen_topic}.\n–¢–µ–ø–µ—Ä—å –Ω–∞–∂–º–∏—Ç–µ 'üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥'.")
    add_service_msg_id(context, msg_1.message_id)



# === –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é GPT-4 ===
async def generate_sentences(user_id, num_sentances, context: CallbackContext = None):
    #client_deepseek = OpenAI(api_key = api_key_deepseek,base_url="https://api.deepseek.com")
    
    task_name = f"generate_sentences"
    system_instruction = f"generate_sentences"
    assistant_id, _ = get_or_create_openai_resources(system_instruction, task_name)
            
    # ‚úÖ –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π thread –∫–∞–∂–¥—ã–π —Ä–∞–∑
    thread = client.beta.threads.create()
    thread_id = thread.id

    chosen_topic = context.user_data.get("chosen_topic", "Random sentences")  # Default: General topic


    # if chosen_topic != "Random sentences":
    user_message = f"""
    Number of sentences: {num_sentances}. Topic: "{chosen_topic}".
    """

    #–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é GPT     
    for attempt in range(5): # –ü—Ä–æ–±—É–µ–º –¥–æ 5 —Ä–∞–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        try:
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=user_message
            )

            run = client.beta.threads.runs.create(
                thread_id=thread_id,
                assistant_id=assistant_id
            )
            while True:
                run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
                if run_status.status == "completed":
                    break
                await asyncio.sleep(1)  # –ø–æ–¥–æ–∂–¥–∏ —á—É—Ç—å-—á—É—Ç—å
            

            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run
            messages = client.beta.threads.messages.list(thread_id=thread_id)
            last_message = messages.data[0]  # –æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ ‚Äî –æ—Ç–≤–µ—Ç
            sentences = last_message.content[0].text.value

            try:
                client.beta.threads.delete(thread_id=thread_id)
                logging.info(f"üóëÔ∏è Thread —É–¥–∞–ª—ë–Ω: {thread_id}")

            except Exception as e:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å thread: {e}")

            # response = await client.chat.completions.create(
            #     model = "gpt-4-turbo",
            #     messages = [{"role": "user", "content": prompt}]
            # )
            # sentences = response.choices[0].message.content.split("\n")
            filtered_sentences = [s.strip() for s in sentences.split("\n") if s.strip()] # ‚úÖ –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            
            if filtered_sentences:
                return filtered_sentences
            
        except openai.RateLimitError:
            wait_time = (attempt +1) * 2 # –ó–∞–¥–µ—Ä–∂–∫–∞: 2, 4, 6 —Å–µ–∫...
            print(f"‚ö†Ô∏è OpenAI API Rate Limit. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
            await asyncio.sleep(wait_time)
    
    print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.")


    # # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é DeepSeek API
    # for attempt in range(5): # –ü—Ä–æ–±—É–µ–º –¥–æ 5 —Ä–∞–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    #     try:
    #         response = await client_deepseek.chat.completions.create(
    #             model = "deepseek-chat",
    #             messages = [{"role": "user", "content": prompt}], stream=False
    #         )
    #         sentences = response.choices[0].message.content.split("\n")
    #         filtered_sentences = [s.strip() for s in sentences if s.strip()] # ‚úÖ –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    #         if filtered_sentences:
    #             return filtered_sentences
    #     except openai.RateLimitError:
    #         wait_time = (attempt +1) * 2 # –ó–∞–¥–µ—Ä–∂–∫–∞: 2, 4, 6 —Å–µ–∫...
    #         print(f"‚ö†Ô∏è OpenAI API Rate Limit. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
    #         await asyncio.sleep(wait_time)
    
    # print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.")


    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT sentence FROM spare_sentences_deepseek ORDER BY RANDOM() LIMIT 7;""")
    spare_rows = cursor.fetchall()

    cursor.close()
    conn.close()

    if spare_rows:
        return [row[0].strip() for row in spare_rows if row[0].strip()]
    else:
        print("‚ùå –û—à–∏–±–∫–∞: –¥–∞–∂–µ –∑–∞–ø–∞—Å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
        return ["–ó–∞–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1", "–ó–∞–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2"]


async def recheck_score_only(client_recheck, original_text, user_translation):
    prompt = f"""
You previously evaluated a student's translation and gave it a score of 0 out of 100.

Please reassess the score **again** based on the information below.

Original sentence (Russian): "{original_text}"  
User's translation (German): "{user_translation}"  

Return your reassessed score in the following format only:  
Score: X/100
""" 
    for i in range(3):
        try:
            responce = await client_recheck.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}]
            )
            text = responce.choices[0].message.content.strip()
            print(f"üîÅ –û—Ç–≤–µ—Ç –Ω–∞ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫—É –æ—Ü–µ–Ω–∫–∏:\n{text}")
            if "score" in text.lower():
                reassessed_score = text.lower().split("score:")[-1].split("/")[0].strip()
                try:
                    if int(reassessed_score) == 0:
                        continue
                    return reassessed_score
                except ValueError:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏ reassessed_score –∫ —á–∏—Å–ª—É: {reassessed_score}")
                    continue

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–µ score: {e}")
            continue
        
    return "0" # fallback, –µ—Å–ª–∏ GPT –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª


async def check_translation(original_text, user_translation, update: Update, context: CallbackContext, sentence_number):
    client_recheck = openai.AsyncOpenAI(api_key=openai.api_key)
    task_name = f"check_translation"
    system_instruction = f"check_translation"
    assistant_id, _ = get_or_create_openai_resources(system_instruction, task_name)
            
    # ‚úÖ –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π thread –∫–∞–∂–¥—ã–π —Ä–∞–∑
    thread = client.beta.threads.create()
    thread_id = thread.id

    # Initialize variables with default values at the beginning of the function
    score = "50"  # Default score
    categories = []
    subcategories = []
    correct_translation = "there is no information."  # Default translation
    
    # ‚úÖ –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    message = await context.bot.send_message(chat_id=update.message.chat_id, text="‚è≥ –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —á—Ç–æ —Ç—ã —Å–ø–æ—Å–æ–±–µ–Ω...")
    
    await simulate_typing(context, update.message.chat_id, duration=3)

    user_message = f"""

    **Original sentence (Russian):** "{original_text}"
    **User's translation (German):** "{user_translation}"

    """

    for attempt in range(3):
        try:
            logging.info(f" GPT started working on {original_text} sentence. Passing data to GPT model")
            start_time = asyncio.get_running_loop().time()
            
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=user_message
            )

            run = client.beta.threads.runs.create(
                thread_id=thread_id,
                assistant_id=assistant_id
            )
            while True:
                run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
                if run_status.status == "completed":
                    break
                await asyncio.sleep(2)  # –ø–æ–¥–æ–∂–¥–∏ —á—É—Ç—å-—á—É—Ç—å


            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run
            messages = client.beta.threads.messages.list(thread_id=thread_id)
            last_message = messages.data[0]  # –æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ ‚Äî –æ—Ç–≤–µ—Ç
            collected_text = last_message.content[0].text.value
            logging.info(f"We got a reply from GPT model for sentence {original_text}")
            
            try:
                client.beta.threads.delete(thread_id=thread_id)
                logging.info(f"üóëÔ∏è Thread —É–¥–∞–ª—ë–Ω: {thread_id}")

            except Exception as e:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å thread: {e}")
                

            # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            print(f"üîé FULL RESPONSE:\n{collected_text}")


            # ‚úÖ –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            score_str = collected_text.split("Score: ")[-1].split("/")[0].strip() if "Score:" in collected_text else None
            
            #my offer to split by ", " because it is a string and take all list
            # ‚úÖ –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏ —Å –ø–æ–º–æ—â—å—é split("\n")[0]
            categories = collected_text.split("Mistake Categories: ")[-1].split("\n")[0].split(", ") if "Mistake Categories:" in collected_text else []
            subcategories = collected_text.split("Subcategories: ")[-1].split("\n")[0].split(", ") if "Subcategories:" in collected_text else []

            #severity = collected_text.split("Severity: ")[-1].split("\n")[0].strip() if "Severity:" in collected_text and len(collected_text.split("Severity: ")[-1].split("\n")) > 0 else None
            
            #correct_translation = collected_text.split("Correct Translation: ")[-1].strip() if "Correct Translation:" in collected_text else None
            correct_translation = None
            match = re.search(r'Correct Translation:\s*(.+?)(?:\n|\Z)', collected_text)
            if match:
                correct_translation = match.group(1).strip()
            
            # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –î–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            print(f"üîé RAW CATEGORIES BEFORE HANDLING in check_translation function (User {update.message.from_user.id}): {', '.join(categories)}")
            print(f"üîé RAW SUBCATEGORIES BEFORE HANDLING in check_translation function (User {update.message.from_user.id}): {', '.join(subcategories)}")
            
            # my offer for category: i would reduce all unneccessary symbols not only ** except from words and commas (what do you think!?)
            categories = [re.sub(r"[^0-9a-zA-Z\s,+\-‚Äì]", "", cat).strip() for cat in categories if cat.strip()]
            # my offer for subcategory: i would reduce all unneccessary symbols not only ** except from words and commas (what do you think!?)
            subcategories = [re.sub(r"[^0-9a-zA-Z\s,+\-‚Äì]", "", subcat).strip() for subcat in subcategories if subcat.strip()]

            # ‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–∫–∏: my offer
            categories = [cat.strip() for cat in categories if cat.strip()]
            subcategories = [subcat.strip() for subcat in subcategories if subcat.strip()]

            # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º
            print(f"üîé RAW CATEGORIES AFTER HANDLING in check_translation function (User {update.message.from_user.id}): {', '.join(categories)}")
            print(f"üîé RAW SUBCATEGORIES AFRET HANDLING (User {update.message.from_user.id}): {', '.join(subcategories)}")

            
            if not categories:
                print(f"‚ö†Ô∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ—Ç–≤–µ—Ç–µ GPT")
            if not subcategories:
                print(f"‚ö†Ô∏è –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ—Ç–≤–µ—Ç–µ GPT")

            if score_str and correct_translation:
                try:
                    score_int = int(score_str)
                except ValueError:
                    print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏ score_str –∫ —á–∏—Å–ª—É: {score_str}")
                    print(f"‚ö†Ô∏è GPT –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ü–µ–Ω–∫–∏. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É...")
                    reassessed_score = await recheck_score_only(client_recheck, original_text, user_translation)
                    print(f"üîÅ GPT –ø–æ–≤—Ç–æ—Ä–Ω–æ –æ—Ü–µ–Ω–∏–ª –Ω–∞: {reassessed_score}/100")
                    score = reassessed_score
                    break  # –∑–∞–≤–µ—Ä—à–∞–µ–º —Ü–∏–∫–ª —É—Å–ø–µ—à–Ω–æ

                if score_int == 0:
                    print(f"‚ö†Ô∏è GPT –ø–æ—Å—Ç–∞–≤–∏–ª 0. –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É...")
                    reassessed_score = await recheck_score_only(client_recheck, original_text, user_translation)
                    print(f"üîÅ GPT –ø–æ–≤—Ç–æ—Ä–Ω–æ –æ—Ü–µ–Ω–∏–ª –Ω–∞: {reassessed_score}/100")
                    score = reassessed_score
                    break

                score = score_str
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã –≤—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
                break
            
            else:
                missing_fields = []
                if not score_str:
                    missing_fields.append("Score")
                #if not severity:
                #    missing_fields.append("Severity")
                if not correct_translation:
                    missing_fields.append("Correct Translation")
                print(f"‚ö†Ô∏è –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {', '.join(missing_fields)}. –ü–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å...")
                raise ValueError(f"Missing required fields: "
                     f"{'Score' if not score_str else ''} "
                     f"{'Correct Translation' if not correct_translation else ''}")


        except openai.RateLimitError:
            wait_time = (attempt + 1) * 5
            print(f"‚ö†Ô∏è OpenAI API –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω. –ñ–¥—ë–º {wait_time} —Å–µ–∫...")
            await asyncio.sleep(wait_time)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            await asyncio.sleep(5)


    # ‚úÖ –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –¥–ª—è —Ä–æ–≤–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    result_text = f"""
üü¢ *Sentence number:* {sentence_number}\n
‚úÖ *Score:* {score}/100\n
üîµ *Original Sentence:* {original_text}\n
üü° *User Translation:* {user_translation}\n
üü£ *Correct Translation:* {correct_translation}\n
"""

    # ‚úÖ –ï—Å–ª–∏ –±–∞–ª–ª > 75 ‚Üí —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
    if score and score.isdigit() and int(score) > 75:
        result_text += "\n‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ ‚Äî —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–π –æ—à–∏–±–∫–æ–π."

    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ Telegram —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π HTML
    sent_message = await context.bot.send_message(
        chat_id=update.message.chat_id,
        text=escape_html_with_bold(result_text),
        parse_mode="HTML"
    )

    message_id = sent_message.message_id
    
    # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ context.user_data
    if len(context.user_data) >= 10:
        oldest_key = next(iter(context.user_data))
        del context.user_data[oldest_key]  # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ

    context.user_data[f"translation_{message_id}"] = {
        "original_text": original_text,
        "user_translation": user_translation
    }

    # ‚úÖ –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"
    await message.delete()

    # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫—É –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    keyboard = [[InlineKeyboardButton("‚ùì Explain me GPT", callback_data=f"explain:{message_id}")]]
    reply_markup = InlineKeyboardMarkup(keyboard)

    # ‚úÖ –ó–∞–¥–µ—Ä–∂–∫–∞ –≤ 1,5 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    await asyncio.sleep(1.5)

    # ‚úÖ –†–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –¥–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É
    await sent_message.edit_text(
        text=escape_html_with_bold(result_text),
        reply_markup=reply_markup,
        parse_mode="HTML"
        )                        

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
    logging.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–≤–µ—Ä–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.message.from_user.id}")

    return result_text, categories, subcategories, score, correct_translation


async def handle_explain_request(update: Update, context: CallbackContext):
    query = update.callback_query
    await query.answer()  # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∞–∫—Ç –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏
    logging.info("üîπ handle_explain_request –≤—ã–∑–≤–∞–Ω–∞!")

    try:
        logging.info(f"üîπ Callback data: {query.data}")

        # ‚úÖ –ü–æ–ª—É—á–∞–µ–º `message_id` –∏–∑ callback_data
        message_id = int(query.data.split(":")[1])
        logging.info(f"‚úÖ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π message_id: {message_id}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        chat_id = update.callback_query.message.chat_id

        # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –±–æ—Ç–∞ –≤ —á–∞—Ç–µ
        member = await context.bot.get_chat_member(
            chat_id=chat_id,
            user_id=context.bot.id
        )
        if member.status in ['administrator', 'creator']:
            can_send_messages = True
        elif hasattr(member, 'can_send_messages'):
            can_send_messages = member.can_send_messages
        else:
            can_send_messages = False

        print(f"üëÆ Bot status: {member.status}, can_send_messages: {can_send_messages}")
        if not can_send_messages:
            logging.error("‚ùå –ë–æ—Ç –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —ç—Ç–æ—Ç —á–∞—Ç!")
            await query.message.reply_text("‚ùå –£ –±–æ—Ç–∞ –Ω–µ—Ç –ø—Ä–∞–≤ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —ç—Ç–æ—Ç —á–∞—Ç!")
            return


        #‚úÖ –ò—â–µ–º –≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        data = context.user_data.get(f"translation_{message_id}")
        if not data:
            logging.error(f"‚ùå –î–∞–Ω–Ω—ã–µ –¥–ª—è message_id {message_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ context.user_data!")
            msg = await query.message.reply_text("‚ùå –î–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            add_service_msg_id(context, msg.message_id)
            return       

        # ‚úÖ –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∞
        original_text = data["original_text"]
        user_translation = data["user_translation"]
        # ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Claude
        explanation = await check_translation_with_claude(original_text, user_translation, update, context)
        if not explanation:
            logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç Claude!")
            msg_1 = await query.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ!")
            add_service_msg_id(context, msg_1.message_id)
            return          
      
        # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è
        print(f"üì© Sending reply to message with message_id: {message_id} in chat ID: {chat_id}")
        escaped_explanation = escape_html_with_bold(explanation)

        print(f"explanation from handle_explain_request_function before escape_html_with_bold: {explanation}")
        print(f"explanation from handle_explain_request_function after escape_html_with_bold: : {escaped_explanation}")

        # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∫–∞–∫ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
        await context.bot.send_message(
            chat_id=chat_id,
            text=escaped_explanation,
            parse_mode="HTML",
            reply_to_message_id=message_id  # üî• –ü–†–ò–ö–†–ï–ü–õ–Ø–ï–ú–°–Ø –ö –°–û–û–ë–©–ï–ù–ò–Æ
            )
        
        # ‚úÖ –£–¥–∞–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        del context.user_data[f"translation_{message_id}"]
        print(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è message_id {message_id}")

    except TelegramError as e:
            if 'message to reply not found' in str(e).lower():
                print(f"‚ö†Ô∏è Message ID {message_id} not found ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, —Å–æ–æ–±—â–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ!")
                await query.message.reply_text("‚ùå –°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–º–æ–∂–Ω–æ, –æ–Ω–æ –±—ã–ª–æ —É–¥–∞–ª–µ–Ω–æ!")
            else:
                logging.error(f"‚ùå Telegram Error: {e}")
                await query.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {e}")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ handle_explain_request: {e}")
        await query.message.reply_text(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å.")




#‚úÖ Explain with Claude
async def check_translation_with_claude(original_text, user_translation, update, context):
    task_name = f"check_translation_with_claude"
    system_instruction = f"check_translation_with_claude"
    assistant_id, _ = get_or_create_openai_resources(system_instruction, task_name)
            
    # ‚úÖ –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π thread –∫–∞–∂–¥—ã–π —Ä–∞–∑
    thread = client.beta.threads.create()
    thread_id = thread.id

    if update.callback_query:
        user = update.callback_query.from_user
        chat_id = update.callback_query.message.chat_id
    else:
        logging.error("‚ùå –ù–µ—Ç callback_query –≤ update!")
        return None, None
    #this client is for Claude
    #client = AsyncAnthropic(api_key=CLAUDE_API_KEY)

    user_message = f"""
    
    **Original sentence (Russian):** "{original_text}"
    **User's translation (German):** "{user_translation}"

    """
    #available_models = await client.models.list()
    # logging.info(f"üì¢ Available models: {available_models}")
    # print(f"üì¢ Available models: {available_models}")
    
    #model_name = "claude-3-7-sonnet-20250219"  
    
    for attempt in range(3):
        try:
            #it is correct working with Claude model
            # response = await client.messages.create(
            #     model=model_name,
            #     messages=[{"role": "user", "content": prompt}],
            #     max_tokens=500,
            #     temperature=0.2
            # )
            
            client.beta.threads.messages.create(
                thread_id=thread_id,
                role="user",
                content=user_message
            )

            run = client.beta.threads.runs.create(
                thread_id=thread_id,
                assistant_id=assistant_id
            )
            while True:
                run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
                if run_status.status == "completed":
                    break
                await asyncio.sleep(1)  # –ø–æ–¥–æ–∂–¥–∏ —á—É—Ç—å-—á—É—Ç—å
            

            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run
            messages = client.beta.threads.messages.list(thread_id=thread_id)
            last_message = messages.data[0]  # –æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ ‚Äî –æ—Ç–≤–µ—Ç
            response = last_message.content[0].text.value

            try:
                client.beta.threads.delete(thread_id=thread_id)
                logging.info(f"üóëÔ∏è Thread —É–¥–∞–ª—ë–Ω: {thread_id}")

            except Exception as e:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å thread: {e}")

            logging.info(f"üì• FULL RESPONSE BODY: {response}")

            if response:
                cloud_response = response
                #this is for the claude model
                #cloud_response = response.content[0].text
                break
            else:
                logging.warning("‚ö†Ô∏è Claude returned an empty response.")
                print("‚ùå –û—à–∏–±–∫–∞: Claude –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç. We will try one more time in 5 seconds")
                await asyncio.sleep(5)
        
        except anthropic.APIError as e:
            logging.error(f"‚ùå API Error from Claude: {e}")
            # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è ‚Äî –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –≤—ã–π—Ç–∏ –∏–∑ —Ü–∏–∫–ª–∞
            if "authentication" in str(e).lower() or "invalid token" in str(e).lower():
                logging.error("üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º —Ü–∏–∫–ª")
                break
            else:
                logging.warning("‚ö†Ô∏è –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
                await asyncio.sleep(5)

    else:
        print("‚ùå –û—à–∏–±–∫–∞: –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Claude –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
        return "‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Claude."
    
    list_of_errors_pattern = re.findall(r'(Error)\s*(\d+)\:*\s*(.+?)(?:\n|$)', cloud_response, flags=re.DOTALL)

    correct_translation = re.findall(r'(Correct Translation)\:\s*(.+?)(?:\n|$)', cloud_response, flags=re.DOTALL)

    grammar_explanation_pattern = re.findall(r'(Grammar Explanation)\s*\:*\s*\n*(.+?)(?=\n[A-Z][a-zA-Z\s]+:|\Z)',cloud_response,flags=re.DOTALL | re.IGNORECASE)

    altern_sentence_pattern = re.findall(r'(Alternative Construction|Alternative Sentence Construction)\:*\s*(.+?)(?=Synonyms|$)', cloud_response, flags=re.DOTALL | re.IGNORECASE)
    #(?:\n[A-Z][a-zA-Z\s]*\:|\Z) ‚Äî –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –¥–æ: –∏–ª–∏ –¥–æ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–≤—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (\n + –∑–∞–≥–ª–∞–≤–Ω–∞—è –±—É–∫–≤–∞ + —Å–ª–æ–≤–æ + :) –∏–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏ (\Z).
    synonyms_pattern = re.findall(r'Synonyms\:*\n([\s\S]*?)(?=\Z)',cloud_response,flags=re.DOTALL | re.IGNORECASE)

    if not list_of_errors_pattern and not correct_translation:
        logging.error("‚ùå Claude –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞!")
        return "‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Claude."
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ø–∏—Å–æ–∫
    result_list = ["üì• *Detailed grammar explanation*:\n", f"üü¢*Original russian sentence*:\n{original_text}\n", f"üü£*User translation*:\n{user_translation}\n"]

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏
    for line in list_of_errors_pattern:
        result_list.append(f"üî¥*{line[0]} {line[1]}*: {line[2]}\n")

    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
    for item in correct_translation:
        result_list.append(f"‚úÖ*{item[0]}*:\n‚û°Ô∏è {item[1]}\n")

    # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏
    for k in grammar_explanation_pattern:
        result_list.append(f"üü°*{k[0]}*:")  # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        grammar_parts = k[1].split("\n")  # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        for part in grammar_parts:
            clean_part = part.strip()
            if clean_part and clean_part not in ["-", ":"]:
                result_list.append(f"üî•{clean_part}")
    #result_list.append("\n")    

    # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
    for a in altern_sentence_pattern:
        result_list.append(f"\nüîµ*{a[0]}*:\n {a[1].strip()}\n")  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
    if synonyms_pattern:
        result_list.append("‚û°Ô∏è *Synonyms*:")
        #count = 0
        for s in synonyms_pattern:
            synonym_parts = s.split("\n")
            for part in synonym_parts:
                clean_part = part.strip()
                if not clean_part:
                    continue
                # if count > 0 and count % 2 == 0:
                #     result_list.append(f"{'-'*33}")
                result_list.append(f"üîÑ {clean_part}")
                #count += 1

    # —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    result_line_for_output = "\n".join(result_list)

    return result_line_for_output



async def log_translation_mistake(user_id, original_text, user_translation, categories, subcategories, score, correct_translation):
    global VALID_CATEGORIES, VALID_SUBCATEGORIES, VALID_CATEGORIES_lower, VALID_SUBCATEGORIES_lower
    #client = anthropic.Client(api_key=CLAUDE_API_KEY)

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    if categories:
        print(f"üîé LIST OF CATEGORIES FROM log_translation_function: {', '.join(categories)}")

    if subcategories:
        print(f"üîé LIST OF SUBCATEGORIES log_translation_function: {', '.join(subcategories)}")


    # ‚úÖ –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π
    valid_combinations = []
    for cat in categories:
        cat_lower =cat.lower() # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è VALID_SUBCATEGORIES
        for subcat in subcategories:
            subcat_lower = subcat.lower() # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è VALID_SUBCATEGORIES
            if cat_lower in VALID_SUBCATEGORIES_lower and subcat_lower in VALID_SUBCATEGORIES_lower[cat_lower]:
                # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ï –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                valid_combinations.append((cat_lower, subcat_lower))


    # ‚úÖ –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Üí –ª–æ–≥–∏—Ä—É–µ–º –í–°–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    if valid_combinations:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –≤–∞–ª–∏–¥–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫ –≤—ã–≤–µ–¥–µ–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ lower:")
        for main_category_lower, sub_category_lower in valid_combinations:
            print(f"‚û°Ô∏è {main_category_lower} - {sub_category_lower}")

    else:
        # ‚ùó –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å ‚Üí –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ ‚Äî –ø–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é.")
        valid_combinations.append(("Other mistake", "Unclassified mistake"))


    # ‚úÖ –ò–∑–≤–ª–µ–∫–∞–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç–∞–≤–∏–º 3)
    #severity = int(severity) if severity else 3

    # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–¥–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
    score = int(score) if score else 0


    # ‚úÖ –ï—Å–ª–∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ ‚Äî –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –±–∞–∑—É
    if len(valid_combinations) == 0:
        print(f"‚úÖ –ù–µ—Ç categories and subcategories —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏—é –æ—à–∏–±–æ–∫ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –±–∞–∑—É.")
        return

    # ‚úÖ –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –∏–∑ valid_combinations (—á—Ç–æ–±—ã –Ω–µ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ)
    valid_combinations = list(set(valid_combinations))


    # ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
    for main_category, sub_category in valid_combinations:
        # ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        main_category = next((cat for cat in VALID_CATEGORIES if cat.lower() == main_category), main_category)
        sub_category = next((subcat for subcat in VALID_SUBCATEGORIES.get(main_category, []) if subcat.lower() == sub_category), sub_category)
        
        if main_category == "Other mistake" and sub_category == "Unclassified mistake":
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ '{main_category} - {sub_category}' –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –±–∞–∑—É –∫–∞–∫ –Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è.")
        else:
            print(f"‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: '{main_category} - {sub_category}'")

        print(f"üîç –ü–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é –≤ –ë–î: main_category = {main_category} | sub_category = {sub_category}")

        if not isinstance(user_id, int):
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö: user_id = {type(user_id)}")
            return

        if not isinstance(main_category, str) or not isinstance(sub_category, str):
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö: main_category = {type(main_category)}, sub_category = {type(sub_category)}")
            return


        # ‚úÖ –ó–∞–ø–∏—Å—å –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        with get_db_connection() as conn:
            with conn.cursor() as cursor:
                try:
                    # ‚úÖ –ü–æ–ª—É—á–∞–µ–º id_for_mistake_table
                    cursor.execute("""
                    SELECT id_for_mistake_table 
                    FROM daily_sentences_deepseek
                    WHERE sentence=%s
                    LIMIT 1;
                """, (original_text, )
                    )
                    #sentence_id –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä id_for_mistake_table –ò–∑ —Ç–∞–±–ª–∏—Ü—ã daily_sentences_deepseek (–¥–ª—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ–Ω –æ–¥–∏–Ω–∞–∫–æ–≤) –î–ª—è —Ä–∞–∑–Ω—ã—Ö –æ–Ω —Ä–∞–∑–Ω—ã–π.
                    # —ç—Ç–æ –Ω—É–∂–Ω–æ —á—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ü–æ–º–µ—á–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Å–æ–±–µ–Ω–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –ø–æ—Ç–æ–º –∏—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–¥–∞–ª—è—Ç—å –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —ç—Ç–æ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                    result = cursor.fetchone()
                    sentence_id = result[0] if result else None

                    if sentence_id:
                        logging.info(f"‚úÖ sentence_id –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è '{original_text}': {sentence_id}")
                    else:
                        logging.warning(f"‚ö†Ô∏è sentence_id –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è '{original_text}'")
                    
                    # ‚úÖ –í—Å—Ç–∞–≤–ª—è–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É –æ—à–∏–±–æ–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—â–µ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                    cursor.execute("""
                        INSERT INTO detailed_mistakes_deepseek (
                            user_id, sentence, added_data, main_category, sub_category, mistake_count, sentence_id, correct_translation, score
                        ) VALUES (%s, %s, NOW(), %s, %s, 1, %s, %s, %s)
                        ON CONFLICT (user_id, sentence, main_category, sub_category)
                        DO UPDATE SET
                            mistake_count = detailed_mistakes_deepseek.mistake_count + 1,
                            attempt = detailed_mistakes_deepseek.attempt + 1,
                            last_seen = NOW(),
                            score = EXCLUDED.score;
                    """, (user_id, original_text, main_category, sub_category, sentence_id, correct_translation, score)
                    )
                    
                    conn.commit()
                    print(f"‚úÖ –û—à–∏–±–∫–∞ '{main_category} - {sub_category}' —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω–∞ –≤ –±–∞–∑—É.")
                
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ –ë–î: {e}")
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ –ë–î: {e}")

    # ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print(f"‚úÖ –í—Å–µ –æ—à–∏–±–∫–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")


async def check_user_translation(update: Update, context: CallbackContext, translation_text=None):
    
    if update.message is None or update.message.text is None:
        logging.warning("‚ö†Ô∏è update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ check_user_translation().")
        return
    
    if "pending_translations" in context.user_data and context.user_data["pending_translations"]:
        translation_text = "\n".join(context.user_data["pending_translations"])
        #context.user_data["pending_translations"] = []
    
    # –£–±–∏—Ä–∞–µ–º –∫–æ–º–∞–Ω–¥—É "/translate", –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥—ã
    # message_text = update.message.text.strip()
    # translation_text = message_text.replace("/translate", "").strip()

    # –†–∞–∑–±–∏—Ä–∞–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–æ–º–µ—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø–µ—Ä–µ–≤–æ–¥—ã
    pattern = re.compile(r"(\d+)\.\s*([^\d\n]+(?:\n[^\d\n]+)*)", re.MULTILINE)
    translations = pattern.findall(translation_text)
    
    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(translations)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤: {translations}")

    if not translations:
        msg_2 = await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞: –§–æ—Ä–º–∞—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–µ–≤–µ—Ä–µ–Ω. –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: 1. <–ø–µ—Ä–µ–≤–æ–¥>")
        add_service_msg_id(context, msg_2.message_id)
        return

    # –ü–æ–ª—É—á–∞–µ–º ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_id = update.message.from_user.id
    username = update.message.from_user.first_name

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    conn = get_db_connection()
    cursor = conn.cursor()

    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    cursor.execute("""
        SELECT unique_id FROM daily_sentences_deepseek WHERE date = CURRENT_DATE AND user_id = %s
    """, (user_id,))
    
    allowed_sentences = {row[0] for row in cursor.fetchall()}  # –°–æ–±–∏—Ä–∞–µ–º –≤ set() –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    results = []  # –•—Ä–∞–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è Telegram

    for number_str, user_translation in translations:
        try:
            sentence_number = int(number_str)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            if sentence_number not in allowed_sentences:
                results.append(f"‚ùå –û—à–∏–±–∫–∞: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number} –≤–∞–º –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç!")
                continue

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            cursor.execute("""
                SELECT id, sentence, session_id, id_for_mistake_table FROM daily_sentences_deepseek 
                WHERE date = CURRENT_DATE AND unique_id = %s AND user_id = %s;
            """, (sentence_number, user_id))

            row = cursor.fetchone()

            if not row:
                results.append(f"‚ùå –û—à–∏–±–∫–∞: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
                continue

            sentence_id, original_text, session_id, id_for_mistake_table  = row

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–ø—Ä–∞–≤–ª—è–ª –ª–∏ —ç—Ç–æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥ —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            cursor.execute("""
                SELECT id FROM translations_deepseek 
                WHERE user_id = %s AND sentence_id = %s AND timestamp::date = CURRENT_DATE;
            """, (user_id, sentence_id))

            existing_translation = cursor.fetchone()
            if existing_translation:
                results.append(f"‚ö†Ô∏è –í—ã —É–∂–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number}. –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è!")
                continue

            logging.info(f"üìå –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ ‚Ññ{sentence_number}: {user_translation}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ GPT
            MAX_FEEDBACK_LENGTH = 1000  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è GPT

            try:
                feedback, categories, subcategories, score, correct_translation = await check_translation(original_text, user_translation, update, context, sentence_number)

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø–µ—Ä–µ–≤–æ–¥–∞ ‚Ññ{sentence_number}: {e}")
                logging.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø–µ—Ä–µ–≤–æ–¥–∞ ‚Ññ{sentence_number}: {e}", exc_info=True)
                feedback = "‚ö†Ô∏è –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥."

            score = int(score) if score else 50

            # –û–±—Ä–µ–∑–∞–µ–º, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
            if len(feedback) > MAX_FEEDBACK_LENGTH:
                feedback = feedback[:MAX_FEEDBACK_LENGTH] + "...\n‚ö†Ô∏è –û—Ç–≤–µ—Ç GPT –±—ã–ª —Å–æ–∫—Ä–∞—â—ë–Ω."
            
            # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –æ—Ç–ø—Ä–∞–≤–∫–∏    
            results.append(f"üìú **–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number}**\nüéØ –û—Ü–µ–Ω–∫–∞: {feedback}")

            # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
            cursor.execute("""
                INSERT INTO translations_deepseek (user_id, session_id, username, sentence_id, user_translation, score, feedback)
                VALUES (%s, %s, %s, %s, %s, %s, %s);
            """, (user_id, session_id, username, sentence_id, user_translation, score, feedback))

            conn.commit()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —Ä–µ–∞–ª—å–Ω–æ –ª–∏ —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ –æ—à–∏–±–æ–∫?
            cursor.execute("""
                SELECT COUNT(*) FROM detailed_mistakes_deepseek
                WHERE sentence_id = %s AND user_id = %s;
            """, (id_for_mistake_table, user_id))

            was_in_mistakes = cursor.fetchone()[0] > 0

            if score >= 85 and was_in_mistakes:
                try:
                    # # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —Ç–∞–∫–∏–º sentence_id
                    # cursor.execute("""
                    #     SELECT COUNT(*) FROM detailed_mistakes_deepseek
                    #     WHERE sentence_id = %s;
                    # """, (id_for_mistake_table, ))

                    # result = cursor.fetchone()
                    # if result and result[0] > 0:
                    logging.info(f"‚úÖ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è FROM detailed_mistakes_deepseek —Å sentence_id = {id_for_mistake_table}")
                    cursor.execute("""
                        SELECT user_id, score, attempt FROM detailed_mistakes_deepseek
                        WHERE sentence_id = %s;
                    """, (id_for_mistake_table,))
                        
                    rows = cursor.fetchall()
                    user_id = rows[0][0]
                    score_to_save = score
                    total_attempts = max(row[2] for row in rows)
                    # –î–æ–±–∞–≤–ª—è–µ–º 1 –ß—Ç–æ–±—ã —É—á–µ—Å—Ç—å –¢–µ–∫—É—â—É—é –ø–æ–ø—ã—Ç–∫—É (–±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è 1 –û–Ω–∞ –Ω–µ –±—É–¥–µ—Ç —É—á—Ç–µ–Ω–∞)
                    total_attempts = total_attempts + 1
                    
                    logging.info(f"‚úÖ –ü–µ—Ä–µ–Ω–æ—Å–∏–º –¥–∞–Ω–Ω—ã–µ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è FROM detailed_mistakes_deepseek –≤ –¢–∞–±–ª–∏—Ü—É successful_translations –≥–¥–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –±–∞–ª–ª–æ–º 80 –ò –±–æ–ª–µ–µ —Å sentence_id = {id_for_mistake_table}")
                    cursor.execute("""
                    INSERT INTO successful_translations (user_id, sentence_id, score, attempt, date)
                    VALUES (%s,%s,%s,%s, NOW());
                    """, (user_id, sentence_id, score_to_save, total_attempts))

                    logging.info(f"‚úÖ –£–¥–∞–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å sentence_id = {id_for_mistake_table}, —Ç–∞–∫ –∫–∞–∫ –±–∞–ª–ª –≤—ã—à–µ 85.")
                    
                    # ‚úÖ –£–¥–∞–ª—è–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –¥–∞–Ω–Ω—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º
                    cursor.execute("""
                        DELETE FROM detailed_mistakes_deepseek
                        WHERE sentence_id = %s;
                        """, (id_for_mistake_table, ))
                    conn.commit()
                    logging.info(f"‚úÖ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å sentence_id = {id_for_mistake_table} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–æ.")

                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å sentence_id = {id_for_mistake_table}: {e}")

            mistake_exists = was_in_mistakes

            if score >= 80 and not mistake_exists:
                cursor.execute("""
                    INSERT INTO successful_translations (user_id, sentence_id, score, attempt, date)
                    VALUES(%s, %s, %s, %s, NOW());
                    """, (user_id, sentence_id, score, int(1)))
                print(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –≤—ã—Å–æ–∫–æ–º —É—Ä–æ–≤–Ω–µ ({score}/100)")
                continue
            
            # ‚úÖ –ï—Å–ª–∏ –æ—Ü–µ–Ω–∫–∞ < 80 ‚Üí —Ç–æ–ª—å–∫–æ —Ç–æ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É
            try:
                await log_translation_mistake(user_id, original_text, user_translation, categories, subcategories, score, correct_translation)
            
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –æ—à–∏–±–∫–∏ –≤ detailed_mistakes_deepseek: {e}")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è {number_str}: {e}")
            
    cursor.close()
    conn.close()



async def get_original_sentences(user_id, context: CallbackContext):
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
    
        # –í—ã–ø–æ–ª–Ω—è–µ–º SQL-–∑–∞–ø—Ä–æ—Å: –≤—ã–±–∏—Ä–∞–µ–º 1 —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ –∫–æ—Ç–æ—Ä—É—é –º—ã –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–æ–º–µ—Å—Ç–∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        cursor.execute("SELECT sentence FROM sentences_deepseek ORDER BY RANDOM() LIMIT 1;")
        rows = [row[0] for row in cursor.fetchall()]   # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        print(f"üìå –ù–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {rows}") # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã –æ—à–∏–±–æ–∫
        cursor.execute("""
            SELECT sentence, sentence_id
            FROM detailed_mistakes_deepseek
            WHERE user_id = %s
            ORDER BY mistake_count DESC, last_seen ASC; 
        """, (user_id, ))
        
        # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º set() –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ sentence_id
        already_given_sentence_ids = set()
        unique_sentences = set()
        mistake_sentences = []

        for sentence, sentence_id in cursor.fetchall():
            if sentence_id and sentence_id not in already_given_sentence_ids:
                if sentence_id not in unique_sentences:
                    unique_sentences.add(sentence_id)
                    mistake_sentences.append(sentence)
                    already_given_sentence_ids.add(sentence_id)

                    # ‚úÖ –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5)
                    if len(mistake_sentences) == 5:
                        break


        print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã –æ—à–∏–±–æ–∫: {len(mistake_sentences)} / 5")

        # üîπ 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–æ 7
        num_sentences = 7 - len(rows) - len(mistake_sentences)

        print(f"üìå –ù–∞–π–¥–µ–Ω–æ: {len(rows)} –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö + {len(mistake_sentences)} –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ –æ—à–∏–±–æ–∫. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ—â—ë {num_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")
        gpt_sentences = []
        
        # üìå 3. –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ GPT
        if num_sentences > 0:
            print("‚ö†Ô∏è –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ GPT-4...")
            gpt_sentences = await generate_sentences(user_id, num_sentences, context)
            #print(f"üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ GPT –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {gpt_sentences}") # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            
        
        # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        final_sentences = rows + mistake_sentences + gpt_sentences
        print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {final_sentences}")
        
        if not final_sentences:
            print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
            return []  # –í–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        
        return final_sentences
    
    finally: # –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫—É—Ä—Å–æ—Ä –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ **–≤ –∫–æ–Ω—Ü–µ**, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∫–∞–∫–∞—è –≤–µ—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å
        cursor.close()
        conn.close()



# –£–∫–∞–∑—ã–≤–∞–µ–º ID –Ω—É–∂–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
PREFERRED_CHANNELS = [
    "UCthmoIZKvuR1-KuwednkjHg",  # Deutsch mit Yehor
    "UCHLkEhIoBRu2JTqYJlqlgbw",  # Deutsch mit Rieke
    "UCeVQK7ZPXDOAyjY0NYqmX-Q", # Benjamin - Der Deutschlehrer
    "UCuVbK_d3wh3M8TYUk5aFCiQ",   # Lera
    "UCsxqCqZHE6guBCdSUEWpPsg",
    "UCm-E8MXdNquzETSsNxgoWig",
    "UCjdRXC3Wh2hDq8Utx7RIaMw",
    "UC9rwo-ES6aDKxD2qqkL6seA",
    "UCVx6RFaEAg46xfbsDjb440A",
    "UCvs8dBa7v3ti1QDaXE7dtKw",
    "UCE2vOZZIluHMtt2sAXhRhcw"
]

def search_youtube_videous(topic, max_results=5):
    query=topic
    if not YOUTUBE_API_KEY:
        print("‚ùå –û—à–∏–±–∫–∞: YOUTUBE_API_KEY –Ω–µ –∑–∞–¥–∞–Ω!")
        return []
    try:
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
        
        # –ü–æ–∏—Å–∫ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º –∫–∞–Ω–∞–ª–∞–º
        video_data = []
        for channal_id in PREFERRED_CHANNELS:

            request = youtube.search().list(
                part="snippet",
                q=query,
                type="video",
                maxResults=max_results,
                channelId=channal_id
            )
            response = request.execute()

            for item in response.get("items", []):
                title = item["snippet"]["title"]
                #title = title.replace('{', '{{').replace('}', '}}') # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫
                #title = title.replace('%', '%%') # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ % 
                video_id = item["id"].get("videoId", "") # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ videoId
                #video_url = f"https://www.youtube.com/watch?v={video_id}"
                if video_id:
                    video_data.append({'title': title, 'video_id': video_id})     

        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –Ω–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–∞—Ö, –∏—â–µ–º –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º
        if not video_data:
            print("‚ùå –í–∏–¥–µ–æ –Ω–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–æ ‚Äî –∏—â–µ–º –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º.")
            request = youtube.search().list(
                part="snippet",
                q=query,
                type="video",
                maxResults=max_results,
                relevanceLanguage="de",
                regionCode="DE"
            )
            responce = request.execute()

            for item in responce.get("items", []):
                title = item["snippet"]["title"]
                #title = title.replace('{', '{{').replace('}', '}}') # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–æ–∫
                #title = title.replace('%', '%%') # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–æ–≤ % 
                video_id = item["id"].get("videoId", "") # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ videoId
                #video_url = f"https://www.youtube.com/watch?v={video_id}"
                if video_id:
                    video_data.append({'title': title, 'video_id': video_id})
                                  
        if not video_data:
            return ["‚ùå –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."]
        
        # ‚úÖ –¢–µ–ø–µ—Ä—å –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ
        video_ids =  ",".join([video['video_id'] for video in video_data if video['video_id']])
        if video_ids:
            stats_request = youtube.videos().list(
                part = "statistics",
                id=video_ids
            )
            stats_response = stats_request.execute()

            for item in stats_response.get("items", []):
                video_id = item["id"]
                view_count = int(item["statistics"].get("viewCount", 0))
                for video in video_data:
                    if video['video_id'] == video_id:
                        video["views"] = view_count

        # ‚úÖ –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞—Ö –Ω–µ—Ç)
        for video in video_data:
            video.setdefault("views", 0)

        # ‚úÖ –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
        sorted_videos = sorted(video_data, key=lambda x: x["views"], reverse=True)

        # ‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ 2 —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤–∏–¥–µ–æ
        top_videos = sorted_videos[:2]

        # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –≤ Telegram-—Ñ–æ—Ä–º–∞—Ç–µ
        preferred_videos = [
            f'<a href="{html.escape("https://www.youtube.com/watch?v=" + video["video_id"])}">‚ñ∂Ô∏è {escape_html_with_bold(video["title"])}</a>'
            for video in top_videos
        ]

        print(f"preferred_videos after escape_html_with_bold: {preferred_videos}")
        return preferred_videos
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤–∏–¥–µ–æ –≤ YouTube: {e}")
        return []


#üìå this function will filter and rate mistakes
async def rate_mistakes(user_id):
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            
            # we calculate amount of translated sentences of the user in a week 
            cursor.execute("""
                SELECT COUNT(sentence_id) 
                FROM translations_deepseek 
                WHERE user_id = %s AND timestamp >= NOW() - INTERVAL '6 days'; 
            """, (user_id,))
            total_sentences = cursor.fetchone()
            total_sentences = total_sentences[0] if isinstance(total_sentences, tuple) else total_sentences or 0

            # ‚úÖ 2. Select and calculate all mistakes KPI within a week
            cursor.execute("""
                WITH user_mistakes AS (
                    SELECT COUNT(*) AS mistakes_week
                    FROM detailed_mistakes_deepseek
                    WHERE user_id = %s
                    AND added_data >= NOW() - INTERVAL '6 days'
                ),
                top_category AS (
                    SELECT main_category
                    FROM detailed_mistakes_deepseek
                    WHERE user_id = %s
                    AND added_data >= NOW() - INTERVAL '6 days'
                    GROUP BY main_category
                    ORDER BY COUNT(*) DESC
                    LIMIT 1
                ),
                number_of_topcategory_mist AS (
                    SELECT main_category, COUNT(*) AS number_of_top_category_mistakes
                    FROM detailed_mistakes_deepseek
                    WHERE user_id = %s
                    AND added_data >= NOW() - INTERVAL '6 days'
                    AND main_category = (SELECT main_category FROM top_category)
                    GROUP BY main_category
                    ORDER BY COUNT(*) DESC
                    LIMIT 1
                ),
                top_two_subcategories AS (
                    SELECT sub_category, 
                        COUNT(*) AS count,
                        ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS subcategory_rank
                    FROM detailed_mistakes_deepseek 
                    WHERE user_id = %s
                    AND added_data >= NOW() - INTERVAL '6 days'
                    AND main_category = (SELECT main_category FROM top_category)
                    GROUP BY sub_category
                    ORDER BY COUNT(*) DESC
                    LIMIT 2
                )
                -- ‚úÖ FINAL QUERY WITH LEFT JOIN TO AVOID EMPTY RESULTS
                SELECT 
                    COALESCE((SELECT mistakes_week FROM user_mistakes), 0) AS mistakes_week,
                    COALESCE(ntc.main_category, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') AS top_mistake_category,
                    COALESCE(ntc.number_of_top_category_mistakes, 0) AS number_of_top_category_mistakes,
                    COALESCE(MAX(CASE WHEN tts.subcategory_rank = 1 THEN tts.sub_category END), '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') AS top_subcategory_1,
                    COALESCE(MAX(CASE WHEN tts.subcategory_rank = 2 THEN tts.sub_category END), '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') AS top_subcategory_2
                FROM number_of_topcategory_mist ntc
                LEFT JOIN top_two_subcategories tts ON TRUE
                GROUP BY ntc.main_category, ntc.number_of_top_category_mistakes;
            """, (user_id, user_id, user_id, user_id))

            # ‚úÖ –û–ë–†–ê–ë–ê–¢–´–í–ê–ï–ú –°–õ–£–ß–ê–ô, –ö–û–ì–î–ê –í–û–ó–í–†–ê–©–ê–ï–¢–°–Ø –ú–ï–ù–¨–®–ï –î–ê–ù–ù–´–•
            result = cursor.fetchone()
            if result is not None:
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –¥–∞–Ω–Ω—ã—Ö
                mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2 = result
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2 = 0, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'


    return total_sentences, mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2


# ‚úÖ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ —Å—Å—ã–ª–∫–∏
async def check_url(url):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    return True
                else:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å—Å—ã–ª–∫–∏ {url} - –°—Ç–∞—Ç—É—Å: {response.status}")
                    return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Å—ã–ª–∫–∏ {url}: {e}")
        return False

# –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–¥–Ω–∞–∫–æ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —á—Ç–æ–±—ã –æ—Å—Ç–∞–≤–∏—Ç—å –∂–∏—Ä–Ω—ã–º —Ç–µ–∫—Å—Ç –≤ ** —Ç–µ–∫—Å—Ç**.
# def escape_markdown_v2(text):
#     # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã Markdown
#     if not isinstance(text, str):
#         text = str(text)
#     escape_chars = r'_*[]()~`>#+-=|{}.,!:'
#     return ''.join(f'\\{char}' if char in escape_chars else char for char in text)

def escape_html_with_bold(text):
    if not isinstance(text, str):
        text = str(text)
    
    # –°–Ω–∞—á–∞–ª–∞ –∑–∞–º–µ–Ω–∏–º *text* –Ω–∞ <b>text</b>
    bold_pattern = r'\*(.*?)\*'
    text = re.sub(bold_pattern, r'<b>\1</b>', text)
    
    # –¢–µ–ø–µ—Ä—å —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤–µ—Å—å –æ—Å—Ç–∞–ª—å–Ω–æ–π —Ç–µ–∫—Å—Ç –∫—Ä–æ–º–µ –Ω–∞—à–∏—Ö —Ç—ç–≥–æ–≤
    def escape_except_tags(part):
        if part.startswith('<b>') and part.endswith('</b>'):
            # –í–Ω—É—Ç—Ä–∏ <b>...</b> —Ç–æ–∂–µ –Ω—É–∂–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å
            inner = html.escape(part[3:-4])
            return f"<b>{inner}</b>"
        else:
            return html.escape(part)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –∫—É—Å–∫–∏: –ª–∏–±–æ <b>...</b> –ª–∏–±–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
    #re.split(r'(<b>.*?</b>)', text) —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–∞–∫:
    #–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –∫—É—Å–∫–æ–≤ <b>...</b>,–ò —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–∞–º–∏ <b>...</b> –≤ —Å–ø–∏—Å–æ–∫ –±–ª–∞–≥–æ–¥–∞—Ä—è —Å–∫–æ–±–∫–∞–º () –≤ —Ä–µ–≥—É–ª—è—Ä–∫–µ.
    parts = re.split(r'(<b>.*?</b>)', text)
    escaped_parts = [escape_except_tags(part) for part in parts]
    return ''.join(escaped_parts)



# üìåüìåüìåüìåüìå
async def send_me_analytics_and_recommend_me(context: CallbackContext):
    #client = openai.AsyncOpenAI(api_key=openai.api_key)
    task_name = f"send_me_analytics_and_recommend_me"
    system_instruction = f"send_me_analytics_and_recommend_me"
    assistant_id, _ = get_or_create_openai_resources(system_instruction, task_name)
            

    #get all user_id's from _DB to itterate over them and send them recommendations
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
            SELECT DISTINCT user_id FROM detailed_mistakes_deepseek;
            """)
            user_ids = cursor.fetchall()
    if not user_ids:
        print("‚ùå –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –æ—à–∏–±–∫–∞–º–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é.")
        return

    for user_id, in user_ids:
        total_sentences, mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2 = await rate_mistakes(user_id)
        if total_sentences:
            with get_db_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT username FROM translations_deepseek WHERE user_id = %s;""",
                        (user_id, ))

                    result = cursor.fetchone()
                    username = result[0] if result else "Unknown User"

                # ‚úÖ –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π thread –∫–∞–∂–¥—ã–π —Ä–∞–∑
                thread = client.beta.threads.create()
                thread_id = thread.id

            # ‚úÖ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–µ–º—É —É OpenAI
            user_message = f"""
            - **–ö–∞—Ç–µ–≥–æ—Ä–∏—è –æ—à–∏–±–∫–∏:** {top_mistake_category}  
            - **–ü–µ—Ä–≤–∞—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è:** {top_mistake_subcategory_1}  
            - **–í—Ç–æ—Ä–∞—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è:** {top_mistake_subcategory_2}  
            """

            for attempt in range(5):
                try:
                    client.beta.threads.messages.create(
                    thread_id=thread_id,
                    role="user",
                    content=user_message
                )

                    run = client.beta.threads.runs.create(
                        thread_id=thread_id,
                        assistant_id=assistant_id
                    )
                    while True:
                        run_status = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run.id)
                        if run_status.status == "completed":
                            break
                        await asyncio.sleep(1)  # –ø–æ–¥–æ–∂–¥–∏ —á—É—Ç—å-—á—É—Ç—å

                    # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run
                    messages = client.beta.threads.messages.list(thread_id=thread_id)
                    last_message = messages.data[0]  # –æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ–¥–Ω–µ–µ ‚Äî –æ—Ç–≤–µ—Ç
                    topic = last_message.content[0].text.value

                    # response = await client.chat.completions.create(
                    # model="gpt-4-turbo",
                    # messages=[{"role": "user", "content": prompt}]
                    # )
                    # topic = response.choices[0].message.content.strip()
                    
                    try:
                        client.beta.threads.delete(thread_id=thread_id)
                        logging.info(f"üóëÔ∏è Thread —É–¥–∞–ª—ë–Ω: {thread_id}")

                    except Exception as e:
                        logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å thread: {e}")

                    print(f"üìå –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —Ç–µ–º–∞: {topic}")
                    break
                except openai.RateLimitError:
                    wait_time = (attempt + 1 )*5
                    print(f"‚ö†Ô∏è OpenAI API –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω. –ñ–¥—ë–º {wait_time} —Å–µ–∫...")
                    await asyncio.sleep(wait_time)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ OpenAI: {e}")
                    continue
                
            # ‚úÖ –ò—â–µ–º –≤–∏–¥–µ–æ –Ω–∞ YouTube —Ç–æ–ª—å–∫–æ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∫–∞–Ω–∞–ª–∞–º
            video_data = search_youtube_videous(topic)

            # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            if not isinstance(video_data, list):
                print(f"‚ùå –û–®–ò–ë–ö–ê: search_youtube_videous –≤–µ—Ä–Ω—É–ª–∞ {type(video_data)} –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞!")
            if not video_data:
                print("‚ùå –í–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –°–ø–∏—Å–æ–∫ –ø—É—Å—Ç.")
            else:
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(video_data)} –≤–∏–¥–µ–æ:")
                for video in video_data:
                    print(f"‚ñ∂Ô∏è {video}")
            
            # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä—ë–º
            # ‚úÖ –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞—Ç—å —Å–Ω–æ–≤–∞ ‚Äî —Å–ø–∏—Å–æ–∫ —É–∂–µ –≥–æ—Ç–æ–≤
            valid_links = video_data

            
            if not valid_links:
                valid_links = ["‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∏–¥–µ–æ –Ω–∞ YouTube –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."]

            rounded_value = round(mistakes_week/total_sentences, 2)
            # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            recommendations = (
                f"üßî *{username}*,\n–í—ã *–ø–µ—Ä–µ–≤–µ–ª–∏* –∑–∞ –Ω–µ–¥–µ–ª—é: {total_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π;\n"
                f"üìå *–í –Ω–∏—Ö –¥–æ–ø—É—â–µ–Ω–æ* {mistakes_week} –æ—à–∏–±–æ–∫;\n"
                f"üö® *–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –Ω–∞ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:* {rounded_value} —à—Ç—É–∫;\n"
                f"üî¥ *–ë–æ–ª—å—à–µ –≤—Å–µ–≥–æ –æ—à–∏–±–æ–∫:* {number_of_top_category_mistakes} —à—Ç—É–∫ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:\n {top_mistake_category or '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}\n"
            )
            if top_mistake_subcategory_1:
                recommendations += (f"üìú *–û—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏:*\n {top_mistake_subcategory_1}\n\n")
            if top_mistake_subcategory_2:
                recommendations += (f"üìú *–í—Ç–æ—Ä—ã–µ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –æ—à–∏–±–∫–∏ –≤ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏:*\n {top_mistake_subcategory_2}\n\n")
            
            # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π ‚Üí –≠–¢–û –í–ê–ñ–ù–û!
            recommendations += (f"üü¢ *–†–µ–∫–æ–º–µ–Ω–¥—É—é –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å:*\n\n")
            recommendations = escape_html_with_bold(recommendations)


            # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–±–æ—á–∏–µ —Å—Å—ã–ª–∫–∏
            recommendations += "\n\n".join(valid_links)
            
            #Debugging...
            print("DEBUG: ", recommendations)


            # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await context.bot.send_message(
                chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, 
                text=recommendations,
                parse_mode = "HTML"
                )
            await asyncio.sleep(5)

        else:
            with get_db_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        SELECT DISTINCT username FROM translations_deepseek WHERE user_id = %s;
                    """, (user_id, ))
                    result = cursor.fetchone()
                    username = result[0] if result else f"User {user_id}"
            
            await context.bot.send_message(
                chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
                text=escape_html_with_bold(f"‚ö†Ô∏è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {username} –Ω–µ –ø–µ—Ä–µ–≤—ë–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ."),
                parse_mode="HTML"
            )


async def force_finalize_sessions(context: CallbackContext = None):
    """–ó–∞–≤–µ—Ä—à–∞–µ—Ç –í–°–ï –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ —Ç–æ–ª—å–∫–æ –∑–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –≤ 23:59."""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        UPDATE user_progress_deepseek 
        SET end_time = NOW(), completed = TRUE
        WHERE completed = FALSE AND start_time::date = CURRENT_DATE;
    """)

    conn.commit()
    cursor.close()
    conn.close()

    msg = await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text="üîî –í—Å–µ –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–∫—Ä—ã—Ç—ã!")
    #add_service_msg_id(context, msg.message_id)



#SQL –ó–∞–ø—Ä–æ—Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ
async def send_weekly_summary(context: CallbackContext):

    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –Ω–µ–¥–µ–ª—é
    cursor.execute("""
        SELECT 
        t.username, 
        COUNT(DISTINCT t.sentence_id) AS –≤—Å–µ–≥–æ_–ø–µ—Ä–µ–≤–æ–¥–æ–≤,
        COALESCE(AVG(t.score), 0) AS —Å—Ä–µ–¥–Ω—è—è_–æ—Ü–µ–Ω–∫–∞,
        COALESCE(p.avg_time, 0) AS —Å—Ä–µ–¥–Ω–µ–µ_–≤—Ä–µ–º—è_—Å–µ—Å—Å–∏–∏_–≤_–º–∏–Ω—É—Ç–∞—Ö, -- ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏
        COALESCE(p.total_time, 0) AS –æ–±—â–µ–µ_–≤—Ä–µ–º—è_–≤_–º–∏–Ω—É—Ç–∞—Ö, -- ‚úÖ –¢–µ–ø–µ—Ä—å –µ—Å—Ç—å –∏ –æ–±—â–µ–µ –≤—Ä–µ–º—è
        (SELECT COUNT(*) 
        FROM daily_sentences_deepseek 
        WHERE date >= CURRENT_DATE - INTERVAL '6 days' 
        AND user_id = t.user_id) 
        - COUNT(DISTINCT t.sentence_id) AS –ø—Ä–æ–ø—É—â–µ–Ω–æ_–∑–∞_–Ω–µ–¥–µ–ª—é,
        COALESCE(AVG(t.score), 0) 
            - (COALESCE(p.avg_time, 0) * 2) -- ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤ —à—Ç—Ä–∞—Ñ–µ
            - ((SELECT COUNT(*) 
                FROM daily_sentences_deepseek 
                WHERE date >= CURRENT_DATE - INTERVAL '6 days' 
                AND user_id = t.user_id) 
            - COUNT(DISTINCT t.sentence_id)) * 20
            AS –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª
    FROM translations_deepseek t
    LEFT JOIN (
        SELECT user_id, 
            AVG(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS avg_time, -- ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏
            SUM(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS total_time -- ‚úÖ –û–±—â–µ–µ –≤—Ä–µ–º—è
        FROM user_progress_deepseek 
        WHERE completed = TRUE 
        AND start_time >= CURRENT_DATE - INTERVAL '6 days'
        GROUP BY user_id
    ) p ON t.user_id = p.user_id
    WHERE t.timestamp >= CURRENT_DATE - INTERVAL '6 days'
    GROUP BY t.username, t.user_id, p.avg_time, p.total_time
    ORDER BY –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª DESC;

    """)
    rows = cursor.fetchall()

    cursor.close()
    conn.close()

    if not rows:
        await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text="üìä –ù–µ–¥–µ–ª—è –ø—Ä–æ—à–ª–∞, –Ω–æ –Ω–∏–∫—Ç–æ –Ω–µ –ø–µ—Ä–µ–≤–µ–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
        return

    summary = "üèÜ –ò—Ç–æ–≥–∏ –Ω–µ–¥–µ–ª–∏:\n\n"

    medals = ["ü•á", "ü•à", "ü•â"]
    for i, (username, count, avg_score, avg_minutes, total_minutes, missed, final_score) in enumerate(rows):
        medal = medals[i] if i < len(medals) else "üí©"
        summary += (
            f"{medal} {username}\n"
            f"üìú –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {count}\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}/100\n"
            f"‚è± –í—Ä–µ–º—è —Å—Ä–µ–¥–Ω–µ–µ: {avg_minutes:.1f} –º–∏–Ω\n"
            f"‚è± –í—Ä–µ–º—è –æ–±—â–µ–µ: {total_minutes:.1f} –º–∏–Ω\n"
            f"üö® –ü—Ä–æ–ø—É—â–µ–Ω–æ: {missed}\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {final_score:.1f}\n\n"
        )

    await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text=summary)



async def user_stats(update: Update, context: CallbackContext):
    user_id = update.message.from_user.id
    username = update.message.from_user.first_name

    conn = get_db_connection()
    cursor = conn.cursor()

    # üìå –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å (–æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏) –ï—Å–ª–∏ –∑–∞ —Å–µ–º—å –¥–Ω–µ–π —Å—á–∏—Ç–∞—Ç—å —Ç–æ –Ω—É–∂–Ω–æ —Ç–∞–∫: WHERE date BETWEEN CURRENT_DATE - INTERVAL '7 days' AND CURRENT_DATE - INTERVAL '1 day'
    cursor.execute("""
        SELECT 
            COUNT(DISTINCT t.sentence_id) AS –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ,  
            COALESCE(AVG(t.score), 0) AS —Å—Ä–µ–¥–Ω—è—è_–æ—Ü–µ–Ω–∫–∞,
            COALESCE((
                SELECT AVG(EXTRACT(EPOCH FROM (p.end_time - p.start_time)) / 60)  -- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º AVG –≤–º–µ—Å—Ç–æ SUM
                FROM user_progress_deepseek p
                WHERE p.user_id = t.user_id 
                    AND p.start_time::date = CURRENT_DATE
                    AND p.completed = TRUE
            ), 0) AS —Å—Ä–µ–¥–Ω–µ–µ_–≤—Ä–µ–º—è_—Å–µ—Å—Å–∏–∏_–≤_–º–∏–Ω—É—Ç–∞—Ö,  -- ‚úÖ –û–±–Ω–æ–≤–∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ, —á—Ç–æ–±—ã –±—ã–ª–æ –ø–æ–Ω—è—Ç–Ω–æ
            GREATEST(0, (SELECT COUNT(*) FROM daily_sentences_deepseek 
                        WHERE date = CURRENT_DATE AND user_id = t.user_id) - COUNT(DISTINCT t.sentence_id)) AS –ø—Ä–æ–ø—É—â–µ–Ω–æ,
            COALESCE(AVG(t.score), 0) 
                - (COALESCE((
                    SELECT AVG(EXTRACT(EPOCH FROM (p.end_time - p.start_time)) / 60)  -- ‚úÖ –ó–¥–µ—Å—å —Ç–æ–∂–µ AVG
                    FROM user_progress_deepseek p
                    WHERE p.user_id = t.user_id 
                        AND p.start_time::date = CURRENT_DATE
                        AND p.completed = TRUE
                ), 0) * 2) 
                - (GREATEST(0, (SELECT COUNT(*) FROM daily_sentences_deepseek
                                WHERE date = CURRENT_DATE AND user_id = t.user_id) - COUNT(DISTINCT t.sentence_id)) * 20) AS –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª
        FROM translations_deepseek t
        WHERE t.user_id = %s AND t.timestamp::date = CURRENT_DATE
        GROUP BY t.user_id;
    """, (user_id,))

    today_stats = cursor.fetchone()

    # üìå –ù–µ–¥–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–æ–±–Ω–æ–≤–ª–µ–Ω–æ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)
    cursor.execute("""
        SELECT 
            t.user_id,
            COUNT(DISTINCT t.sentence_id) AS –≤—Å–µ–≥–æ_–ø–µ—Ä–µ–≤–æ–¥–æ–≤,
            COALESCE(AVG(t.score), 0) AS —Å—Ä–µ–¥–Ω—è—è_–æ—Ü–µ–Ω–∫–∞,
            COALESCE(p.avg_session_time, 0) AS —Å—Ä–µ–¥–Ω–µ–µ_–≤—Ä–µ–º—è_—Å–µ—Å—Å–∏–∏_–≤_–º–∏–Ω—É—Ç–∞—Ö,  
            COALESCE(p.total_time, 0) AS –æ–±—â–µ–µ_–≤—Ä–µ–º—è_–∑–∞_–Ω–µ–¥–µ–ª—é,  
            GREATEST(0, COALESCE(ds.total_sentences, 0) - COUNT(DISTINCT t.sentence_id)) AS –ø—Ä–æ–ø—É—â–µ–Ω–æ_–∑–∞_–Ω–µ–¥–µ–ª—é,
            COALESCE(AVG(t.score), 0) 
                - (COALESCE(p.avg_session_time, 0) * 2)  
                - (GREATEST(0, COALESCE(ds.total_sentences, 0) - COUNT(DISTINCT t.sentence_id)) * 20) AS –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª
        FROM translations_deepseek t
        LEFT JOIN (
            -- ‚úÖ –û—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ–¥–∑–∞–ø—Ä–æ—Å –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ä–∞—Å—á—ë—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            SELECT 
                user_id, 
                AVG(EXTRACT(EPOCH FROM (end_time - start_time)) / 60) AS avg_session_time, 
                SUM(EXTRACT(EPOCH FROM (end_time - start_time)) / 60) AS total_time 
            FROM user_progress_deepseek
            WHERE completed = TRUE 
                AND start_time >= CURRENT_DATE - INTERVAL '6 days'
            GROUP BY user_id
        ) p ON t.user_id = p.user_id
        LEFT JOIN (
            SELECT user_id, COUNT(*) AS total_sentences
            FROM daily_sentences_deepseek
            WHERE date >= CURRENT_DATE - INTERVAL '6 days'
            GROUP BY user_id
        ) ds ON t.user_id = ds.user_id
        WHERE t.timestamp >= CURRENT_DATE - INTERVAL '6 days' 
            AND t.user_id = %s  -- ‚úÖ –§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        GROUP BY t.user_id, p.avg_session_time, p.total_time, ds.total_sentences;
    """, (user_id,))

    weekly_stats = cursor.fetchone()

    cursor.close()
    conn.close()

    # üìå –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    if today_stats:
        today_text = (
            f"üìÖ –°–µ–≥–æ–¥–Ω—è—à–Ω—è—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ({username})\n"
            f"üîπ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {today_stats[0]}\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {today_stats[1]:.1f}/100\n"
            f"‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏: {today_stats[2]:.1f} –º–∏–Ω\n"
            f"üö® –ü—Ä–æ–ø—É—â–µ–Ω–æ: {today_stats[3]}\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {today_stats[4]:.1f}\n"
        )
    else:
        today_text = f"üìÖ **–°–µ–≥–æ–¥–Ω—è—à–Ω—è—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ({username})**\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–≤—ã –µ—â—ë –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏)."

    if weekly_stats:
        weekly_text = (
            f"\nüìÜ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –Ω–µ–¥–µ–ª—é\n"
            f"üîπ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {weekly_stats[1]}\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {weekly_stats[2]:.1f}/100\n"
            f"‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏: {weekly_stats[3]:.1f} –º–∏–Ω\n"
            f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è –∑–∞ –Ω–µ–¥–µ–ª—é: {weekly_stats[4]:.1f} –º–∏–Ω\n"
            f"üö® –ü—Ä–æ–ø—É—â–µ–Ω–æ –∑–∞ –Ω–µ–¥–µ–ª—é: {weekly_stats[5]}\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {weekly_stats[6]:.1f}\n"
        )
    else:
        weekly_text = "\nüìÜ **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –Ω–µ–¥–µ–ª—é**\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö."

    await update.message.reply_text(today_text + weekly_text)



async def send_daily_summary(context: CallbackContext):

    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –°–æ–±–∏—Ä–∞–µ–º –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–∫—Ç–æ –ø–µ—Ä–µ–≤—ë–ª —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
    cursor.execute("""
        SELECT DISTINCT user_id, username 
        FROM translations_deepseek
        WHERE timestamp::date = CURRENT_DATE;
    """)
    active_users = {row[0]: row[1] for row in cursor.fetchall()}

    # üîπ –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö, –∫—Ç–æ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –ø–∏—Å–∞–ª –≤ —á–∞—Ç
    cursor.execute("""
        SELECT DISTINCT user_id, username
        FROM messages_deepseek
        WHERE timestamp >= date_trunc('month', CURRENT_DATE);
    """)
    all_users = {row[0]: row[1] for row in cursor.fetchall()}
    for user_id, username in all_users.items():
        print(f"User ID from rows: {user_id}, uswername: {username}")

    # üîπ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –¥–µ–Ω—å
    cursor.execute("""
       SELECT 
            ds.user_id, 
            COUNT(DISTINCT ds.id) AS total_sentences,
            COUNT(DISTINCT t.id) AS translated,
            (COUNT(DISTINCT ds.id) - COUNT(DISTINCT t.id)) AS missed,
            COALESCE(p.avg_time, 0) AS avg_time_minutes, 
            COALESCE(p.total_time, 0) AS total_time_minutes, 
            COALESCE(AVG(t.score), 0) AS avg_score,
            COALESCE(AVG(t.score), 0) 
            - (COALESCE(p.avg_time, 0) * 2) 
            - ((COUNT(DISTINCT ds.id) - COUNT(DISTINCT t.id)) * 20) AS final_score
        FROM daily_sentences_deepseek ds
        LEFT JOIN translations_deepseek t ON ds.user_id = t.user_id AND ds.id = t.sentence_id
        LEFT JOIN (
            SELECT user_id, 
                AVG(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS avg_time, 
                SUM(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS total_time
            FROM user_progress_deepseek
            WHERE completed = true
        		AND start_time::date = CURRENT_DATE -- ‚úÖ –¢–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ –∑–∞ –¥–µ–Ω—å
            GROUP BY user_id
        ) p ON ds.user_id = p.user_id
        WHERE ds.date = CURRENT_DATE
        GROUP BY ds.user_id, p.avg_time, p.total_time
        ORDER BY final_score DESC;
    """)
    rows = cursor.fetchall()

    cursor.close()
    conn.close()

    # üîπ –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    if not rows:
        await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text="üìä –°–µ–≥–æ–¥–Ω—è –Ω–∏–∫—Ç–æ –Ω–µ –ø–µ—Ä–µ–≤—ë–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
        return

    summary = "üìä –ò—Ç–æ–≥–∏ –¥–Ω—è:\n\n"
    medals = ["ü•á", "ü•à", "ü•â"]
    for i, (user_id, total_sentences, translated, missed, avg_minutes, total_time_minutes, avg_score, final_score) in enumerate(rows):
        username = all_users.get(int(user_id), '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å')  # ‚úÖ –ë–µ—Ä—ë–º –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Å–ª–æ–≤–∞—Ä—è
        medal = medals[i] if i < len(medals) else "üí©"
        summary += (
            f"{medal} {username}\n"
            f"üìú –í—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {total_sentences}\n"
            f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}\n"
            f"üö® –ù–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {missed}\n"
            f"‚è± –í—Ä–µ–º—è —Å—Ä–µ–¥–Ω–µ–µ: {avg_minutes:.1f} –º–∏–Ω\n"
            f"‚è± –í—Ä–µ–º—è –æ–±—â–µ–µ: {total_time_minutes:.1f} –º–∏–Ω\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}/100\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {final_score:.1f}\n\n"
        )


    # üö® **–î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ –ø—Ä–æ –ª–µ–Ω–∏–≤—ã—Ö**
    lazy_users = {uid: uname for uid, uname in all_users.items() if uid not in active_users}
    if lazy_users:
        summary += "\nü¶• –õ–µ–Ω–∏–≤—Ü—ã (–ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç, –Ω–æ –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏):\n"
        for username in lazy_users.values():
            summary += f"üë§ {username}: –Ω–∏—á–µ–≥–æ –Ω–µ –ø–µ—Ä–µ–≤—ë–ª!\n"

    await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text=summary)



async def send_progress_report(context: CallbackContext):
    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç **–∑–∞ –º–µ—Å—è—Ü**
    cursor.execute("""
        SELECT DISTINCT user_id, username 
        FROM messages_deepseek
        WHERE timestamp >= date_trunc('month', CURRENT_DATE);
    """)
    all_users = {int(row[0]): row[1] for row in cursor.fetchall()}

    # üîπ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö, –∫—Ç–æ –ø–µ—Ä–µ–≤—ë–ª —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ **–∑–∞ —Å–µ–≥–æ–¥–Ω—è**
    cursor.execute("""
        SELECT DISTINCT user_id FROM translations_deepseek WHERE timestamp::date = CURRENT_DATE;
    """)
    active_users = {row[0] for row in cursor.fetchall()}

    # üîπ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º **–∑–∞ —Å–µ–≥–æ–¥–Ω—è**(checked)
    cursor.execute("""
        SELECT 
        ds.user_id,
        COUNT(DISTINCT ds.id) AS –≤—Å–µ–≥–æ_–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π,
        COUNT(DISTINCT t.id) AS –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ,
        (COUNT(DISTINCT ds.id) - COUNT(DISTINCT t.id)) AS –ø—Ä–æ–ø—É—â–µ–Ω–æ,
        COALESCE(p.avg_time, 0) AS —Å—Ä–µ–¥–Ω–µ–µ_–≤—Ä–µ–º—è_—Å–µ—Å—Å–∏–∏_–≤_–º–∏–Ω—É—Ç–∞—Ö, -- ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∑–∞ –¥–µ–Ω—å
        COALESCE(p.total_time, 0) AS –æ–±—â–µ–µ_–≤—Ä–µ–º—è_–∑–∞_–¥–µ–Ω—å, -- ‚úÖ –û–±—â–µ–µ –≤—Ä–µ–º—è –∑–∞ –¥–µ–Ω—å
        COALESCE(AVG(t.score), 0) AS —Å—Ä–µ–¥–Ω—è—è_–æ—Ü–µ–Ω–∫–∞,
        COALESCE(AVG(t.score), 0) 
            - (COALESCE(p.avg_time, 0) * 2) -- ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≤ —Ä–∞—Å—á—ë—Ç–∞—Ö
            - ((COUNT(DISTINCT ds.id) - COUNT(DISTINCT t.id)) * 20) AS –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª
    FROM daily_sentences_deepseek ds
    LEFT JOIN translations_deepseek t ON ds.user_id = t.user_id AND ds.id = t.sentence_id
    LEFT JOIN (
        SELECT user_id, 
            AVG(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS avg_time, -- ‚úÖ –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ –∑–∞ –¥–µ–Ω—å
            SUM(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS total_time -- ‚úÖ –û–±—â–µ–µ –≤—Ä–µ–º—è –∑–∞ –¥–µ–Ω—å
        FROM user_progress_deepseek
        WHERE completed = TRUE 
            AND start_time::date = CURRENT_DATE -- ‚úÖ –¢–µ–ø–µ—Ä—å —Ç–æ–ª—å–∫–æ –∑–∞ –¥–µ–Ω—å
        GROUP BY user_id
    ) p ON ds.user_id = p.user_id
    WHERE ds.date = CURRENT_DATE
    GROUP BY ds.user_id, p.avg_time, p.total_time
    ORDER BY –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª DESC;
    """)
    rows = cursor.fetchall()

    cursor.close()
    conn.close()

    # üîπ –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
    if not rows:
        await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text="üìä –°–µ–≥–æ–¥–Ω—è –Ω–∏–∫—Ç–æ –Ω–µ –ø–µ—Ä–µ–≤—ë–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
        return
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    progress_report = f"üìä –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏—Ç–æ–≥–∏ –ø–µ—Ä–µ–≤–æ–¥–∞:\nüïí –í—Ä–µ–º—è –æ—Ç—á—ë—Ç–∞:\n{current_time}\n\n"

    for user_id, total, translated, missed, avg_minutes, total_minutes, avg_score, final_score in rows:
        progress_report += (
            f"üë§ {all_users.get(int(user_id), '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å')}\n"
            f"üìú –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}/{total}\n"
            f"üö® –ù–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {missed}\n"
            f"‚è± –í—Ä–µ–º—è —Å—Ä–µ–¥–Ω–µ–µ: {avg_minutes:.1f} –º–∏–Ω\n"
            f"‚è± –í—Ä–µ–º—è –æ–±—â.: {total_minutes:.1f} –º–∏–Ω\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}/100\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {final_score:.1f}\n\n"
        )

    # üö® **–î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ –ø—Ä–æ –ª–µ–Ω–∏–≤—ã—Ö (—É—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ—Ö, –∫—Ç–æ –ø–∏—Å–∞–ª –≤ —á–∞—Ç –∑–∞ –º–µ—Å—è—Ü)**
    lazy_users = {uid: uname for uid, uname in all_users.items() if uid not in active_users}
    if lazy_users:
        progress_report += "\nü¶• –õ–µ–Ω–∏–≤—Ü—ã (–ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç, –Ω–æ –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏):\n"
        for username in lazy_users.values():
            progress_report += f"üë§ {username}: –Ω–∏—á–µ–≥–æ –Ω–µ –ø–µ—Ä–µ–≤—ë–ª!\n"

    await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text=progress_report)


async def error_handler(update, context):
    logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ Telegram: {context.error}")


# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
GOOGLE_CREDS_FILE_PATH = None

# ‚úÖ # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env-—Ñ–∞–π–ª–∞ (—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)
# –≠—Ç–æ –∑–∞–≥—Ä—É–∑–∏—Ç –≤—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ file with name .env which was created by me –≤ os.environ

def prepare_google_creds_file():
    global GOOGLE_CREDS_FILE_PATH
    global success
    print("‚úÖ .env loaded?", success)
    print("üß™ –§—É–Ω–∫—Ü–∏—è prepare_google_creds_file –≤—ã–∑–≤–∞–Ω–∞")

    # ‚úÖ 1. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–º—É .json-—Ñ–∞–π–ª—É
    direct_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    print(f"üì¢ direct_path (print): {direct_path}")
    logging.info(f"direct_path: {direct_path}")

    if direct_path:
        print("üåê –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–∞–π–¥–µ–Ω–∞:", direct_path)
        print("üß± –°—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª?", Path(direct_path).exists())
        GOOGLE_CREDS_FILE_PATH = direct_path
        return GOOGLE_CREDS_FILE_PATH
    
    # ‚úÖ 2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GOOGLE_CREDS_JSON (–∏–∑ Railway)
    if GOOGLE_CREDS_FILE_PATH and Path(GOOGLE_CREDS_FILE_PATH).exists():
        return GOOGLE_CREDS_FILE_PATH
    
    raw_creds = os.getenv("GOOGLE_CREDS_JSON")
    if not raw_creds:
        raise RuntimeError("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ GOOGLE_APPLICATION_CREDENTIALS –∏–ª–∏ GOOGLE_CREDS_JSON.")

    with tempfile.NamedTemporaryFile(mode="w+", delete=False, suffix=".json") as temp_key_file:
        temp_key_file.write(raw_creds)
        temp_key_file.flush()
        # –ö–æ–≥–¥–∞ —Å–æ–∑–¥–∞—ë –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —á–µ—Ä–µ–∑ tempfile.NamedTemporaryFile, Python –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —ç—Ç–æ–≥–æ —Ñ–∞–π–ª–∞. 
        # –£ –Ω–µ–≥–æ –µ—Å—Ç—å –∞—Ç—Ä–∏–±—É—Ç .name, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —ç—Ç–æ–º—É —Ñ–∞–π–ª—É –≤ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ
        GOOGLE_CREDS_FILE_PATH = temp_key_file.name
        print(f"üß™ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–ª—é—á: {GOOGLE_CREDS_FILE_PATH}")

    return GOOGLE_CREDS_FILE_PATH



async def mistakes_to_voice(username, sentence_pairs):
    #global GOOGLE_CREDS_FILE_PATH
    key_path = prepare_google_creds_file()
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = key_path

    client = texttospeech.TextToSpeechClient()

    audio_segments = []

    def synthesize(text, language_code, voice_name):
        input_data = texttospeech.SynthesisInput(text = text)

        voice = texttospeech.VoiceSelectionParams(
            language_code = language_code, name=voice_name
        )

        config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=0.9 # 90% —Å–∫–æ—Ä–æ—Å—Ç–∏
        )

        response = client.synthesize_speech(
            input=input_data, voice=voice, audio_config=config 
        )

        return AudioSegment.from_file_using_temporary_files(io.BytesIO(response.audio_content))

    for russian, german in sentence_pairs:
        print(f"üé§ –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ–º: {russian} -> {german}")
        # –†—É—Å—Å–∫–∏–π (–æ–¥–∏–Ω —Ä–∞–∑)
        ru_audio = synthesize(russian, "ru-RU", "ru-RU-Wavenet-C")
        # –ù–µ–º–µ—Ü–∫–∏–π (–¥–≤–∞–∂–¥—ã)
        de_audio_1 = synthesize(german, "de-DE", "de-DE-Wavenet-B")
        de_audio_2 = synthesize(german, "de-DE", "de-DE-Wavenet-B")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º
        combined = ru_audio + de_audio_1 + de_audio_2
        audio_segments.append(combined)

    final_audio = sum(audio_segments)

    output_path = f"{username}.mp3"

    final_audio.export(output_path, format="mp3")
    print(f"üîä –°–æ—Ö—Ä–∞–Ω—ë–Ω –∏—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª: {output_path}")


async def get_yesterdays_mistakes_for_audio_message(context: CallbackContext):
    
    with get_db_connection() as conn:
        with conn.cursor() as cursor:

            # take all users who made at least one mistake from detailed_mistakes_deepseek table
            cursor.execute("""
                SELECT DISTINCT user_id FROM detailed_mistakes_deepseek
                WHERE added_data >= NOW() - INTERVAL '6 days';
            """)
            user_ids = [i[0] for i in cursor.fetchall() if i[0] is not None]
            print(user_ids)
            for user_id in user_ids:
                original_by_id = {}

                cursor.execute("""
                SELECT username FROM user_progress_deepseek
                WHERE user_id = %s;
                """, (user_id,))
                row = cursor.fetchone()
                username = row[0] if row and row[0] else f"useer_{user_id}"

                ## –®–∞–≥ 1 ‚Äî –°–æ–±–∏—Ä–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ user_id
                # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã –æ—à–∏–±–æ–∫
                cursor.execute("""
                    SELECT sentence, correct_translation
                    FROM detailed_mistakes_deepseek
                    WHERE user_id = %s
                    ORDER BY mistake_count DESC, last_seen ASC; 
                """, (user_id, ))
                
                # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º set() –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ sentence_id
                already_given_sentence_translation = set()
                unique_sentences = set()
                mistake_sentences = []
                result_for_audio = []
                
                rows = cursor.fetchall()
                max_to_collect = min(len(rows), 5)

                for sentence, correct_translation in rows:
                    if sentence and correct_translation and correct_translation not in already_given_sentence_translation and sentence not in mistake_sentences:
                        if correct_translation not in unique_sentences:
                            unique_sentences.add(correct_translation)
                            mistake_sentences.append(sentence)
                            already_given_sentence_translation.add(correct_translation)
                            original_by_id[correct_translation] = sentence

                            # ‚úÖ –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ –Ω—É–∂–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5)
                            
                            if len(mistake_sentences) == max_to_collect:
                                break

                sentence_pairs = [(origin_sentence, correct_transl) for correct_transl, origin_sentence in original_by_id.items()]
                try:
                    await mistakes_to_voice(username, sentence_pairs)
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ –¥–ª—è {username}: {e}")
                    continue
                audio_path = Path(f"{username}.mp3")
                print(f"üì¶ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {audio_path.stat().st_size / 1024 / 1024:.2f} MB ")

                if audio_path.exists():
                    try:
                        start = asyncio.get_running_loop().time()
                        with audio_path.open("rb") as audio_file:
                            await context.bot.send_audio(
                                chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, 
                                audio=audio_file,
                                caption=f"üéß –û—à–∏–±–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è @{username} –∑–∞ –≤—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å."
                            )
                        print(f"‚è± –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–Ω—è–ª–∞ {asyncio.get_running_loop().time() - start:.2f} —Å–µ–∫—É–Ω–¥")
                        await asyncio.sleep(5)
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –¥–ª—è @{username}: {e}")

                    try:    
                        audio_path.unlink()
                    except FileNotFoundError:
                        print(f"‚ö†Ô∏è –§–∞–π–ª —É–∂–µ –±—ã–ª —É–¥–∞–ª—ë–Ω: {audio_path}")
                
                else:
                    await context.bot.send_message(
                        chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
                        text=f"‚ùå –î–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è @{username} –Ω–µ –Ω–∞–π–¥–µ–Ω –∞—É–¥–∏–æ—Ñ–∞–π–ª."
                    )
                    await asyncio.sleep(5)


# import atexit

# def cleanup_creds_file():
#     global GOOGLE_CREDS_FILE_PATH
#     if GOOGLE_CREDS_FILE_PATH and os.path.exists(GOOGLE_CREDS_FILE_PATH):
#         os.remove(GOOGLE_CREDS_FILE_PATH)
#         print(f"üßπ –£–¥–∞–ª—ë–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–ª—é—á: {GOOGLE_CREDS_FILE_PATH}")

# atexit.register(cleanup_creds_file)




def main():
    global application

    #defaults = Defaults(timeout=60)  # —É–≤–µ–ª–∏—á–∏–ª–∏ —Ç–∞–π–º–∞—É—Ç –¥–æ 60 —Å–µ–∫—É–Ω–¥
    application = Application.builder().token(TELEGRAM_DeepSeek_BOT_TOKEN).build()
    application.bot.request.timeout = 60

    # üîπ –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
    application.add_handler(CommandHandler("start", start))
    # üî• –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–≥—Ä—É–ø–ø–∞ -1, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç —Ü–µ–ø–æ—á–∫—É)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, log_message, block=False), group=-1)

    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_user_message, block=False), group=1)  # ‚úÖ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_button_click, block=False), group=1)  # ‚úÖ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫–∏ 
    application.add_handler(CallbackQueryHandler(handle_explain_request, pattern=r"^explain:"))

    application.add_handler(CommandHandler("translate", check_user_translation))  # ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, check_translation_from_text, block=False), group=1)  # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã


    application.add_handler(CallbackQueryHandler(topic_selected)) #–û–Ω –∂–¥–µ—Ç –ª—é–±—ã–µ –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ inline-–∫–Ω–æ–ø–∫–∏.
    application.add_handler(MessageHandler(filters.TEXT, log_all_messages, block=False), group=2)  # üëà –î–æ–±–∞–≤–ª—è–µ–º –≤ main()

    application.add_error_handler(error_handler)

    scheduler = BackgroundScheduler()

    def run_async_job(async_func, context=None):
         if context is None:
             context = CallbackContext(application=application)   # –°–æ–∑–¥–∞–µ–º `context`, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç

         try:
             loop = asyncio.get_running_loop() # ‚úÖ –ë–µ—Ä–µ–º —É–∂–µ —Ä–∞–±–æ—Ç–∞—é—â–∏–π event loop
         except RuntimeError:
             loop = asyncio.new_event_loop()  # ‚ùå –í –ø–æ—Ç–æ–∫–µ `apscheduler` –Ω–µ—Ç loop ‚Äî —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
             asyncio.set_event_loop(loop)
         loop.run_until_complete(async_func(context)) # ‚úÖ –¢–µ–ø–µ—Ä—å event loop –≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç

    # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ `scheduler` –î–õ–Ø –£–¢–†–ê
    print("üìå –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ scheduler...")
    scheduler.add_job(lambda: run_async_job(send_morning_reminder,CallbackContext(application=application)),"cron", hour=5, minute=5)
    scheduler.add_job(lambda: run_async_job(send_morning_reminder,CallbackContext(application=application)),"cron", hour=15, minute=30)

    scheduler.add_job(
        lambda: run_async_job(send_german_news, CallbackContext(application=application)), 
        "cron",
        hour=4,
        minute=1,
        #day_of_week = "mon,tue,thu,fri,sat"
        day_of_week = "mon,fri"
    )
    
    scheduler.add_job(lambda: run_async_job(send_me_analytics_and_recommend_me, CallbackContext(application=application)), "cron", day_of_week="fri", hour=15, minute=15)
    scheduler.add_job(lambda: run_async_job(send_me_analytics_and_recommend_me, CallbackContext(application=application)), "cron", day_of_week="mon", hour=6, minute=5) 
    #scheduler.add_job(lambda: run_async_job(send_me_analytics_and_recommend_me, CallbackContext(application=application)), "cron", day_of_week="sun", hour=7, minute=7)
    
    scheduler.add_job(lambda: run_async_job(force_finalize_sessions, CallbackContext(application=application)), "cron", hour=21, minute=59)
    
    scheduler.add_job(lambda: run_async_job(send_daily_summary), "cron", hour=20, minute=52)
    scheduler.add_job(lambda: run_async_job(send_weekly_summary), "cron", day_of_week="sun", hour=20, minute=55)

    for hour in [7,12,16]:
        scheduler.add_job(lambda: run_async_job(send_progress_report), "cron", hour=hour, minute=5)

    scheduler.add_job(lambda: run_async_job(get_yesterdays_mistakes_for_audio_message, CallbackContext(application=application)), "cron", hour=5, minute=15)

    scheduler.start()
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω! –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è...")
    application.run_polling()






if __name__ == "__main__":
    main()