# To fix this, you need to get the `message_thread_id` from the `update.message` when the user sends `/start` *within a topic* and pass it to `context.bot.send_message`.

# Additionally, your initial comment `# –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –¥–æ–¥–µ–ª–∞—Ç—å —á—Ç–æ–±—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –æ—Ç–ø—Ä–∞–≤–ª—è–ª–æ—Å—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è` suggests you might want the scheduled messages (like news, summaries) to go into specific topic threads as well, rather than the main "General" thread. Your `TOPICS_TELEGRAM` dictionary already defines IDs for these topics. We can use these IDs in the scheduled job functions.

# Finally, the handlers in `main()` seem to have a redundant `MessageHandler` for `handle_button_click` and a call inside `handle_user_message` that should be removed or fixed. The text buttons on `ReplyKeyboardMarkup` are processed as regular text messages, not callback queries.

# Here's the refined code with the necessary fixes:

# 1.  **Modify `start` function:** Pass `message_thread_id` to `send_message`.
# 2.  **Modify Scheduled Functions:** Send messages to the specific `thread_id` defined in `TOPICS_TELEGRAM`.
# 3.  **Modify Interactive Functions (`choose_topic`, `letsgo`, `done`, `user_stats`, `check_translation_from_text`):** Ensure they correctly get `chat_id` and `message_thread_id` from *either* `update.message` (for Reply button clicks / commands) or `update.callback_query` (for Inline button clicks) at the start of the function. (Your current functions already seem mostly prepared for this).
# 4.  **Add `MessageHandler`s for Reply Keyboard Button Text:** Register specific handlers for the text strings of the buttons in `MAIN_MENU`.
# 5.  **Clean up `main()`:** Remove the redundant `MessageHandler` registration.
# 6.  **Clean up `handle_user_message`:** Remove the incorrect call to `handle_button_click`.



# –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –¥–æ–¥–µ–ª–∞—Ç—å —á—Ç–æ–±—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –æ—Ç–ø—Ä–∞–≤–ª—è–ª–æ—Å—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
# –≠—Ç–æ—Ç –±–æ—Ç –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å DEEPSEEK
import os
import logging
import openai
from openai import OpenAI
import psycopg2
import datetime
from datetime import datetime, time
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext, TypeHandler, Defaults
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import asyncio
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup
from telegram.ext import CallbackQueryHandler
import hashlib
import re
import requests
import aiohttp
from telegram.ext import CallbackContext
from googleapiclient.discovery import build
from telegram.error import TelegramError
from telegram.helpers import escape_markdown
import anthropic
from anthropic import AsyncAnthropic
from telegram.error import TimedOut, BadRequest
import tempfile
import sys

from google.cloud import texttospeech
import os
from pathlib import Path
from dotenv import load_dotenv
from pydub import AudioSegment
import io

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.DEBUG
)
logger = logging.getLogger(__name__)

#MessageHandler ‚Üí –æ–∂–∏–¥–∞–µ—Ç update.message.
#CallbackQueryHandler ‚Üí –æ–∂–∏–¥–∞–µ—Ç update.callback_query.

application = None
scheduler = None

TOPICS_TELEGRAM = {
    "General": {
        "id": None,  # –≠—Ç–æ —Å–∞–º —á–∞—Ç. –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ-1002258968332, threat_id: None
        "allowed_buttons": []  # –ú–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ü—Ä–æ—Å—Ç–æ –¥–ª—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏
    },
    "Empfehlungen": {
        "id": 3560,
        "allowed_buttons": [] # —Å—é–¥–∞ –±—É–¥—É—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    },
    "W√∂chenliche Statistik": {
        "id": 3495,
        "allowed_buttons": [] # —Å—é–¥–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    },
        "T√§gliche Statistik": {
        "id": 3492,
        "allowed_buttons": ["üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"] # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫—É "üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞" —Å—é–¥–∞
    },
    "Bewertungen von GPT": {
        "id": 3479,
        "allowed_buttons": [] # –Ω–∞–∂–∞—Ç–∏–µ–º —ç—Ç–æ–π –∫–Ω–æ–ø–∫–∏ GPT —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç
    },
        "Erkl√§rungen von Claude": {
        "id": 3481,
        "allowed_buttons": ["‚ùì Explain me with Claude"]
    },
        "√úbersetzungen": {
        "id": 3514,
        "allowed_buttons": ["üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É", "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥", "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥", "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥"]
    },
        "Nachrichten": {
        "id": 3576,
        "allowed_buttons": [] # —Å—é–¥–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é –Ω–æ–≤–æ—Å—Ç–∏
    },
        "L√ºstige Geschichten": {
        "id": 3582,
        "allowed_buttons": [] # —Å—é–¥–∞ –±—É–¥—É—Ç –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é –∏—Å—Ç–æ—Ä–∏–∏
    },
        "√úbungen": {
        "id": 3586,
        "allowed_buttons": [] # –≠—Ç–æ –Ω–∞ –±—É–¥—É—â–µ–µ —Ç–µ–º–∞ –¥–ª—è —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
    }
}


# –û—Å–Ω–æ–≤–Ω–æ–µ –º–µ–Ω—é —Å ReplyKeyboardMarkup
MAIN_MENU = ReplyKeyboardMarkup(
    [
        ["üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É", "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥"],
        ["üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥", "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥"],
        ["üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"] # ‚úÖ –ö–Ω–æ–ø–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    ],
    resize_keyboard=True,
    one_time_keyboard=False
)


print(f"DEBUG: MAIN_MENU –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {MAIN_MENU.keyboard}")

# Buttons in Telegramm
TOPICS = ["Business", "Medicine", "Hobbies", "Free Time", "Education",
    "Work", "Travel", "Science", "Technology", "Everyday Life", "Random sentences"]


# –ü–æ–ª—É—á–∏ –∫–ª—é—á –Ω–∞ https://console.cloud.google.com/apis/credentials
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# –í–∞—à API-–∫–ª—é—á –¥–ª—è CLAUDE 3.7
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")
if CLAUDE_API_KEY:
    logging.info("‚úÖ CLAUDE_API_KEY —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå –û—à–∏–±–∫–∞: CLAUDE_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

# –í–∞—à API-–∫–ª—é—á –¥–ª—è mediastack
API_KEY_NEWS = os.getenv("API_KEY_NEWS")

# ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —É—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
VALID_CATEGORIES = [
    'Nouns', 'Cases', 'Verbs', 'Tenses', 'Adjectives', 'Adverbs',
    'Conjunctions', 'Prepositions', 'Moods', 'Word Order', 'Other mistake'
]

VALID_SUBCATEGORIES = {
    'Nouns': ['Gendered Articles', 'Pluralization', 'Compound Nouns', 'Declension Errors'],
    'Cases': ['Nominative', 'Accusative', 'Dative', 'Genitive', 'Akkusativ + Preposition', 'Dative + Preposition', 'Genitive + Preposition'],
    'Verbs': ['Placement', 'Conjugation', 'Weak Verbs', 'Strong Verbs', 'Mixed Verbs', 'Separable Verbs', 'Reflexive Verbs', 'Auxiliary Verbs', 'Modal Verbs', 'Verb Placement in Subordinate Clause'],
    'Tenses': ['Present', 'Past', 'Simple Past', 'Present Perfect', 'Past Perfect', 'Future', 'Future 1', 'Future 2', 'Plusquamperfekt Passive', 'Futur 1 Passive', 'Futur 2 Passive'],
    'Adjectives': ['Endings', 'Weak Declension', 'Strong Declension', 'Mixed Declension', 'Placement', 'Comparative', 'Superlative', 'Incorrect Adjective Case Agreement'],
    'Adverbs': ['Placement', 'Multiple Adverbs', 'Incorrect Adverb Usage'],
    'Conjunctions': ['Coordinating', 'Subordinating', 'Incorrect Use of Conjunctions'],
    'Prepositions': ['Accusative', 'Dative', 'Genitive', 'Two-way', 'Incorrect Preposition Usage'],
    'Moods': ['Indicative', 'Declarative', 'Interrogative', 'Imperative', 'Subjunctive 1', 'Subjunctive 2'],
    'Word Order': ['Standard', 'Inverted', 'Verb-Second Rule', 'Position of Negation', 'Incorrect Order in Subordinate Clause', 'Incorrect Order with Modal Verb'],
    'Other mistake': ['Unclassified mistake']
}


# ‚úÖ –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º VALID_CATEGORIES –∏ VALID_SUBCATEGORIES –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø—Ä–æ–π—Ç–∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä–∫—É –≤ —Ñ—É–Ω–∫—Ü–∏–∏ log_translation_mistake
VALID_CATEGORIES_lower = [cat.lower() for cat in VALID_CATEGORIES]
VALID_SUBCATEGORIES_lower = {k.lower(): [v.lower() for v in values] for k, values in VALID_SUBCATEGORIES.items()}

# === –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö PostgreSQL ===
DATABASE_URL = os.getenv("DATABASE_URL_RAILWAY")

if DATABASE_URL:
    logging.info("‚úÖ DATABASE_URL —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå –û—à–∏–±–∫–∞: DATABASE_URL –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

def get_db_connection():
    return psycopg2.connect(DATABASE_URL, sslmode='require')

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
conn = get_db_connection()
cursor = conn.cursor()
cursor.execute("SELECT version();")
db_version = cursor.fetchone()

print(f"‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞! –í–µ—Ä—Å–∏—è: {db_version}")

cursor.close()
conn.close()


# # === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–æ—Ç–∞ ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")

if TELEGRAM_TOKEN:
    logging.info("‚úÖ TELEGRAM_TOKEN —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå TELEGRAM_TOKEN –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

# ID –≥—Ä—É–ø–ø—ã
TEST_DEEPSEEK_BOT_GROUP_CHAT_ID = int(os.getenv("TEST_DEEPSEEK_BOT_GROUP_CHAT_ID")) # –ü–æ–ª—É—á–∞–µ–º –∫–∞–∫ int


if TEST_DEEPSEEK_BOT_GROUP_CHAT_ID:
    logging.info(f"‚úÖ GROUP_CHAT_ID —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω: {TEST_DEEPSEEK_BOT_GROUP_CHAT_ID}")
else:
    logging.error("‚ùå GROUP_CHAT_ID –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")


# # === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DeepSeek API ===
# api_key_deepseek = os.getenv("DeepSeek_API_Key")

# if api_key_deepseek:
#     logging.info("‚úÖ DeepSeek_API_Key —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
# else:
#     logging.error("‚ùå –û—à–∏–±–∫–∞: DeepSeek_API_Key –Ω–µ –∑–∞–¥–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Open AI API ===
openai.api_key = os.getenv("OPENAI_API_KEY")
if openai.api_key:
    logging.info("‚úÖ OPENAI_API_KEY —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω!")
else:
    logging.error("‚ùå OPENAI_API_KEY –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

print("üöÄ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è Railway:")
for key, value in os.environ.items():
    print(f"{key}: {value[:10]}...")  # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 10 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏




# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –Ω–µ–º–µ—Ü–∫–æ–º
async def send_german_news(context: CallbackContext):
    # ‚úÖ –û–ø—Ä–µ–¥–µ–ª—è–µ–º thread_id –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π
    news_thread_id = TOPICS_TELEGRAM["Nachrichten"].get("id")
    if news_thread_id is None:
         logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ thread_id –¥–ª—è —Ç–µ–º—ã Nachrichten!")
         return


    url = f"http://api.mediastack.com/v1/news?access_key={API_KEY_NEWS}&languages=de&categories=technology&countries=de,au&limit=2" # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ 3 –Ω–æ–≤–æ—Å—Ç–µ–π
    #url = f"http://api.mediastack.com/v1/news?access_key={API_KEY_NEWS}&languages=de&countries=at&limit=3" for Austria

    response = requests.get(url)

    if response.status_code == 200:
        data = response.json()

        if "data" in data and len(data["data"]) > 0:
            print("üì¢ Nachrichten auf Deutsch:")
            for i, article in enumerate(data["data"], start=1):  # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–æ 3 –Ω–æ–≤–æ—Å—Ç–µ–π in API request
                title = article.get("title", "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞")
                source = article.get("source", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")
                url = article.get("url", "#")

                message = f"üì∞ {i}. *{title}*\n\nüìå {source}\n\n[–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({url})"
                await context.bot.send_message(
                    chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
                    text=message,
                    parse_mode="Markdown",
                    disable_web_page_preview=False,  # –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∂–∞–ª–∏—Å—å –ø—Ä–µ–≤—å—é —Å—Ç—Ä–∞–Ω–∏—Ü
                    message_thread_id=news_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ Nachrichten
                )
        else:
            await context.bot.send_message(
                 chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
                 text="‚ùå –ù–µ—Ç —Å–≤–µ–∂–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Å–µ–≥–æ–¥–Ω—è!",
                 message_thread_id=news_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ Nachrichten
                 )
    else:
        await context.bot.send_message(
            chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
            text=f"‚ùå –û—à–∏–±–∫–∞ API Mediastack: {response.status_code} - {response.text}",
            message_thread_id=news_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ Nachrichten
        )



# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–∫—Ä—ã–≤–∞—è –∫—É—Ä—Å–æ—Ä –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
def initialise_database():
    with get_db_connection() as connection:
        with connection.cursor() as curr:
            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
            curr.execute("""
                CREATE TABLE IF NOT EXISTS sentences_deepseek (
                        id SERIAL PRIMARY KEY,
                        sentence TEXT NOT NULL

                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            curr.execute("""
                CREATE TABLE IF NOT EXISTS translations_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL,
                        session_id BIGINT,
                        username TEXT,
                        sentence_id INT NOT NULL,
                        user_translation TEXT,
                        score INT,
                        feedback TEXT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)

            # ‚úÖ –ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (—á—Ç–æ–±—ã —É—á–∏—Ç—ã–≤–∞—Ç—å –ª–µ–Ω–∏–≤—ã—Ö)
            curr.execute("""
                CREATE TABLE IF NOT EXISTS messages_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL,
                        username TEXT NOT NULL,
                        message TEXT NOT NULL,
                        thread_id BIGINT,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ daily_sentences
            curr.execute("""
                CREATE TABLE IF NOT EXISTS daily_sentences_deepseek (
                        id SERIAL PRIMARY KEY,
                        date DATE NOT NULL DEFAULT CURRENT_DATE,
                        sentence TEXT NOT NULL,
                        unique_id INT NOT NULL,
                        user_id BIGINT,
                        session_id BIGINT
                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ user_progress
            curr.execute("""
                CREATE TABLE IF NOT EXISTS user_progress_deepseek (
                    session_id BIGINT PRIMARY KEY,
                    user_id BIGINT,
                    username TEXT,
                    start_time TIMESTAMP,
                    end_time TIMESTAMP,
                    completed BOOLEAN DEFAULT FALSE,
                    CONSTRAINT unique_user_session_deepseek UNIQUE (user_id, start_time)
                );
            """)

            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Å—Ç–∞—Ä–∞—è, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω–∞—è)
            # curr.execute("""
            #     CREATE TABLE IF NOT EXISTS translation_errors_deepseek (
            #             id SERIAL PRIMARY KEY,
            #             user_id BIGINT NOT NULL,
            #             category TEXT NOT NULL CHECK (category IN ('–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞', '–õ–µ–∫—Å–∏–∫–∞', '–ü–∞–¥–µ–∂–∏', '–û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—è', '–°–∏–Ω—Ç–∞–∫—Å–∏—Å')),
            #             error_description TEXT NOT NULL,
            #             timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            #     );
            # """)
            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–ø–∞—Å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–≤—è–∑–∏ –ò–ª–∏ –æ—à–∏–±–∫–∏ –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ Open AI API
            curr.execute("""
                CREATE TABLE IF NOT EXISTS spare_sentences_deepseek (
                    id SERIAL PRIMARY KEY,
                    sentence TEXT NOT NULL
                );

            """)


            # ‚úÖ –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–æ–∫
            curr.execute("""
                    CREATE TABLE IF NOT EXISTS detailed_mistakes_deepseek (
                        id SERIAL PRIMARY KEY,
                        user_id BIGINT NOT NULL,
                        sentence TEXT NOT NULL,
                        added_data TIMESTAMP,
                        main_category TEXT CHECK (main_category IN (
                            -- üîπ Nouns
                            'Nouns', 'Cases', 'Verbs', 'Tenses', 'Adjectives', 'Adverbs',
                            'Conjunctions', 'Prepositions', 'Moods', 'Word Order', 'Other mistake'
                        )),
                        sub_category TEXT CHECK (sub_category IN (
                            -- üîπ Nouns
                            'Gendered Articles', 'Pluralization', 'Compound Nouns', 'Declension Errors',

                            -- üîπ Cases
                            'Nominative', 'Accusative', 'Dative', 'Genitive',
                            'Akkusativ + Preposition', 'Dative + Preposition', 'Genitive + Preposition',

                            -- üîπ Verbs
                            'Placement', 'Conjugation', 'Weak Verbs', 'Strong Verbs', 'Mixed Verbs',
                            'Separable Verbs', 'Reflexive Verbs', 'Auxiliary Verbs', 'Modal Verbs',
                            'Verb Placement in Subordinate Clause',

                            -- üîπ Tenses
                            'Present', 'Past', 'Simple Past', 'Present Perfect',
                            'Past Perfect', 'Future', 'Future 1', 'Future 2',
                            'Plusquamperfekt Passive', 'Futur 1 Passive', 'Futur 2 Passive',

                            -- üîπ Adjectives
                            'Endings', 'Weak Declension', 'Strong Declension', 'Mixed Declension',
                            'Placement', 'Comparative', 'Superlative', 'Incorrect Adjective Case Agreement',

                            -- üîπ Adverbs
                            'Placement', 'Multiple Adverbs', 'Incorrect Adverb Usage',

                            -- üîπ Conjunctions
                            'Coordinating', 'Subordinating', 'Incorrect Use of Conjunctions',

                            -- üîπ Prepositions
                            'Accusative', 'Dative', 'Genitive', 'Two-way',
                            'Incorrect Preposition Usage',

                            -- üîπ Moods
                            'Indicative', 'Declarative', 'Interrogative', 'Imperative',
                            'Subjunctive 1', 'Subjunctive 2',

                            -- üîπ Word Order
                            'Standard', 'Inverted', 'Verb-Second Rule', 'Position of Negation',
                            'Incorrect Order in Subordinate Clause', 'Incorrect Order with Modal Verb',

                            -- üîπ Other
                            'Unclassified mistake' -- –î–ª—è –æ—à–∏–±–æ–∫, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–ø–∞–ª–∏ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        )),

                        severity INT DEFAULT 1,  -- –£—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏ (1 ‚Äî –Ω–∏–∑–∫–∏–π, 5 ‚Äî –≤—ã—Å–æ–∫–∏–π)
                        mistake_count INT DEFAULT 1, -- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑, –∫–æ–≥–¥–∞ –æ—à–∏–±–∫–∞ –±—ã–ª–∞ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞
                        first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- –í—Ä–µ–º—è –ø–µ—Ä–≤–æ–π —Ñ–∏–∫—Å–∞—Ü–∏–∏ –æ—à–∏–±–∫–∏
                        last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –æ—à–∏–±–∫–∏
                        error_count_week INT DEFAULT 0, -- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—à–∏–±–æ–∫ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é

                        -- ‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                        CONSTRAINT for_mistakes_table UNIQUE (user_id, sentence, main_category, sub_category)
                    );

            """)

    connection.commit()

    print("‚úÖ –¢–∞–±–ª–∏—Ü—ã sentences_deepseek, translations_deepseek, daily_sentences_deepseek, messages_deepseek, user_progress_deepseek, detailed_mistakes_deepseek, spare_sentences_deepseek –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")

initialise_database()

async def log_all_messages(update: Update, context: CallbackContext):
    """–õ–æ–≥–∏—Ä—É–µ–º –í–°–ï —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏."""
    try:
        if update.message and update.message.text:
            message_text = update.message.text.strip()
            message_thread_id = update.message.message_thread_id
            # Don't log commands in this generic handler
            if message_text.startswith('/'):
                return

            if message_thread_id:
                logging.info(f"üì© –ë–æ—Ç –ø–æ–ª—É—á–∏–ª —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç–µ–º–µ {message_thread_id}: {message_text}")
            else:
                logging.info(f"üì© –ë–æ—Ç –ø–æ–ª—É—á–∏–ª —Å–æ–æ–±—â–µ–Ω–∏–µ: {message_text}")
        else:
            logging.warning("‚ö†Ô∏è update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")


#–ò–º–∏—Ç–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ —Å typing-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º
async def simulate_typing(context, chat_id, duration=3, thread_id=None):
    """–≠–º—É–ª–∏—Ä—É–µ—Ç –Ω–∞–±–æ—Ä —Ç–µ–∫—Å—Ç–∞ –≤ —á–∞—Ç–µ."""
    try:
        await context.bot.send_chat_action(
            chat_id=chat_id,
            action="typing",
            message_thread_id=thread_id
        )
        await asyncio.sleep(duration)  # –ò–º–∏—Ç–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π —Ç–µ–∫—Å—Ç–∞
    except TelegramError as e:
        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å typing –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä: {e}")
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ simulate_typing: {e}")



# Buttons in Telegram
async def send_main_menu_inline(update: Update, context: CallbackContext):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –≤ —Ç–µ–∫—É—â–µ–π —Ç–µ–º–µ."""

    chat_id = update.effective_chat.id # –ò—Å–ø–æ–ª—å–∑—É–µ–º effective_chat –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    message_thread_id = update.effective_message.message_thread_id # –ò—Å–ø–æ–ª—å–∑—É–µ–º effective_message

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º—É –ø–æ thread_id
    topic_info = None
    for topic_name, info in TOPICS_TELEGRAM.items():
        if info.get("id") == message_thread_id:
            topic_info = info
            break

    # –ï—Å–ª–∏ —Ç–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ—Ç —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫
    if not topic_info or not topic_info.get("allowed_buttons"):
         logging.info(f"‚ö†Ô∏è –í —Ç–µ–º–µ {message_thread_id} –Ω–µ—Ç —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–æ–∫.")
         # Optionally, you could send a message saying no inline buttons are available here
         # await context.bot.send_message(chat_id=chat_id, text="–í —ç—Ç–æ–π —Ç–µ–º–µ –Ω–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫.", message_thread_id=message_thread_id)
         return # –ü—Ä–æ—Å—Ç–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏


    allowed_buttons = topic_info["allowed_buttons"]

    # –°–æ–∑–¥–∞—ë–º –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏ –∏–∑ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫
    buttons = [InlineKeyboardButton(button, callback_data=button) for button in allowed_buttons]

    # ‚úÖ –†–∞—Å–ø–æ–ª–∞–≥–∞–µ–º –∫–Ω–æ–ø–∫–∏ –ø–æ –¥–≤–µ –≤ —Ä—è–¥ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
    keyboard = [buttons[i:i + 2] for i in range(0, len(buttons), 2)]

    reply_markup = InlineKeyboardMarkup(keyboard)

    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π thread_id
    if message_thread_id:
        await context.bot.send_message(
            chat_id=chat_id,
            text="üîò *–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:*",
            reply_markup=reply_markup,
            message_thread_id=message_thread_id,
            parse_mode="Markdown"
        )
        print(f"DEBUG: ‚úÖ –ò–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ –ø–æ—Ç–æ–∫ {message_thread_id}")

    else:
        # If there's no thread_id (main chat), maybe don't send topic-specific buttons?
        # Or send them without thread_id if appropriate for the main chat
        logging.warning("‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏, –Ω–æ –Ω–µ—Ç message_thread_id.")
        # await context.bot.send_message(
        #     chat_id=chat_id,
        #     text="–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
        #     reply_markup=reply_markup
        # )
        # print("DEBUG: –ö–Ω–æ–ø–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Ç")


async def handle_button_click(update: Update, context: CallbackContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞–∂–∞—Ç–∏—è –Ω–∞ Inline –∫–Ω–æ–ø–∫–∏."""

    print("üõ† handle_button_click() –≤—ã–∑–≤–∞–Ω!")  # –õ–æ–≥–∏—Ä—É–µ–º —Å–∞–º –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏

    # ‚úÖ –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º callback_query –¥–ª—è Inline –∫–Ω–æ–ø–æ–∫
    if not update.callback_query:
        print("‚ùå handle_button_click –≤—ã–∑–≤–∞–Ω–∞ –±–µ–∑ callback_query!")
        return

    query = update.callback_query
    await query.answer() # Acknowledge the click

    chat_id = query.message.chat_id
    message_thread_id = query.message.message_thread_id # Get thread_id from the message the button was on
    user = query.from_user

    print(f"DEBUG: –ù–∞–∂–∞—Ç–∞ –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∞: {query.data} –≤ —á–∞—Ç–µ {chat_id}, –ø–æ—Ç–æ–∫–µ {message_thread_id}")

    # Determine which topic the button belongs to based on thread_id
    topic = next(
        (topic_info for topic_info in TOPICS_TELEGRAM.values() if topic_info.get("id") == message_thread_id),
        None
    )

    if topic is not None:
        allowed_buttons = topic.get("allowed_buttons", [])
        if query.data in allowed_buttons:
            print(f"DEBUG: –ö–Ω–æ–ø–∫–∞ '{query.data}' —Ä–∞–∑—Ä–µ—à–µ–Ω–∞ –≤ —Ç–µ–º–µ {message_thread_id}.")
            # ‚úÖ –í—ã–∑—ã–≤–∞–µ–º –Ω—É–∂–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –¥–µ–π—Å—Ç–≤–∏—è
            if query.data == "üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É":
                await choose_topic(update, context) # choose_topic will get thread_id from update
            elif query.data == "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
                await letsgo(update, context) # letsgo will get thread_id from update
            elif query.data == "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
                await done(update, context) # done will get thread_id from update
            # Note: "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥" from ReplyKeyboard is handled by MessageHandler below
            elif query.data == "üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞": # This button seems intended for ReplyKeyboard, adjust if needed
                 await user_stats(update, context) # user_stats will get thread_id from update
            elif query.data.startswith("explain:"):
                message_id = int(query.data.split(":")[1])
                logging.info(f"üìå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user.id} –∑–∞–ø—Ä–æ—Å–∏–ª –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è message_id={message_id}")

                # ‚úÖ –ò—â–µ–º –≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                data = context.user_data.get(f"translation_for_claude_{message_id}") # Use a specific key
                if data:
                    # ‚úÖ –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∞
                    original_text = data["original_text"]
                    user_translation = data["user_translation"]
                    # ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é Claude, –ø–µ—Ä–µ–¥–∞–≤–∞—è update
                    await check_translation_with_claude(original_text, user_translation, update, context)

                    # ‚úÖ –£–¥–∞–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    # del context.user_data[f"translation_for_claude_{message_id}"] # Keep data for potential re-explanation? Or remove to save memory? Let's remove for now.
                    print(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è message_id {message_id}")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞: –î–∞–Ω–Ω—ã–µ –¥–ª—è message_id {message_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ context.user_data")
                    await context.bot.send_message(
                        chat_id=chat_id,
                        text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è. –í–æ–∑–º–æ–∂–Ω–æ, —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä–æ–µ.",
                        message_thread_id=message_thread_id
                    )

        else:
            print(f"DEBUG: –ö–Ω–æ–ø–∫–∞ '{query.data}' –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∞ –≤ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ ({message_thread_id}).")
            await query.edit_message_text(text=f"–ö–Ω–æ–ø–∫–∞ '{query.data}' –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞ –≤ —ç—Ç–æ–π —Ç–µ–º–µ.", reply_markup=None) # Remove the button after clicking
    else:
        print(f"DEBUG: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–µ–º—É –ø–æ thread_id {message_thread_id} –¥–ª—è Inline –∫–Ω–æ–ø–∫–∏.")
        await query.edit_message_text(text="–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ.", reply_markup=None) # Remove the button after clicking


async def handle_reply_button_text(update: Update, context: CallbackContext):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–Ω–æ–ø–∫–∞–º ReplyKeyboardMarkup."""
    if not update.message or not update.message.text:
        return

    chat_id = update.message.chat_id
    message_thread_id = update.message.message_thread_id
    user_text = update.message.text.strip()

    print(f"DEBUG: –ü–æ–ª—É—á–µ–Ω —Ç–µ–∫—Å—Ç Reply –∫–Ω–æ–ø–∫–∏: '{user_text}' –≤ —á–∞—Ç–µ {chat_id}, –ø–æ—Ç–æ–∫–µ {message_thread_id}")

    # Route based on button text
    if user_text == "üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É":
        await choose_topic(update, context)
    elif user_text == "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
        await letsgo(update, context)
    elif user_text == "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
        # This button press means the user is ready to check pending translations
        logging.info(f"üìå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {update.message.from_user.id} –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'. –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É.")
        await check_translation_from_text(update, context)
    elif user_text == "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥":
        await done(update, context)
    elif user_text == "üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
        await user_stats(update, context)
    # Add other Reply button texts here if any


async def start(update: Update, context: CallbackContext):
    """–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –º–µ–Ω—é —Å ReplyKeyboard."""
    if update.message:
        chat_id = update.message.chat_id
        # ‚úÖ –ü–æ–ª—É—á–∞–µ–º thread_id, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å. –í–∞–∂–Ω–æ –¥–ª—è —Ç–µ–º!
        message_thread_id = update.message.message_thread_id
        logging.info(f"Received /start command in chat {chat_id}, thread {message_thread_id}")
    else:
        logger.error("‚ùå –ù–µ—Ç update.message –≤ start!")
        return

    logger.debug(f"MAIN_MENU –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π: {MAIN_MENU.keyboard}")
    logger.debug(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å reply_markup: {MAIN_MENU.to_dict()}")

    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å ReplyKeyboardMarkup, –∏—Å–ø–æ–ª—å–∑—É—è thread_id
    # –ï—Å–ª–∏ message_thread_id None, Telegram –æ—Ç–ø—Ä–∞–≤–∏—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Ç (thread_id=1)
    sent_message = await context.bot.send_message(
        chat_id=chat_id,
        text="üöÄ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∏–∂–µ:",
        reply_markup=MAIN_MENU,
        message_thread_id=message_thread_id # ‚úÖ Pass the thread_id here
    )
    logger.debug(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ, message_id: {sent_message.message_id} in thread {message_thread_id}")



# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
async def log_message(update: Update, context: CallbackContext):
    """–ª–æ–≥–∏—Ä—É—é—Ç—Å—è (—Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è) –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
    if not update.message: #–ï—Å–ª–∏ update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∑–Ω–∞—á–∏—Ç, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏–ª —á—Ç–æ-—Ç–æ –¥—Ä—É–≥–æ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–æ—Ç–æ, –≤–∏–¥–µ–æ, —Å—Ç–∏–∫–µ—Ä).
        return #–í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –º—ã –Ω–µ –ª–æ–≥–∏—Ä—É–µ–º —ç—Ç–æ –∏ –ø—Ä–æ—Å—Ç–æ –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏

    user = update.message.from_user # –î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ —Å–æ–¥–µ—Ä–∂–∏—Ç ID –∏ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    message_text = update.message.text.strip() if update.message else "" #—Å–∞–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è.
    message_thread_id = update.message.message_thread_id
    chat_id = update.message.chat_id

    if not message_text:
        print("‚ö†Ô∏è –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ.")
        return

    username = user.username or f"{user.first_name or ''} {user.last_name or ''}".strip()
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    if message_thread_id:
        print(f"üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {username} ({user.id}) –≤ —á–∞—Ç–µ {chat_id}, —Ç–µ–º–µ {message_thread_id}: {message_text}")
    else:
        print(f"üì• –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {username} ({user.id}) –≤ —á–∞—Ç–µ {chat_id}: {message_text}")

    conn = get_db_connection()
    cursor = conn.cursor()
    try:
        cursor.execute("""
            INSERT INTO messages_deepseek (user_id, username, message, thread_id)
            VALUES(%s, %s, %s, %s);
            """,
            (user.id, username, message_text, message_thread_id)
        )

        conn.commit()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑—É: {e}")
    finally:
        cursor.close()
        conn.close()

# —É—Ç—Ä–µ–Ω–Ω–µ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ —á–ª–µ–Ω–æ–º –≥—Ä—É–ø–ø—ã
async def send_morning_reminder(context:CallbackContext):
    # ‚úÖ –£—Ç—Ä–µ–Ω–Ω–∏–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –æ–±—ã—á–Ω–æ –∏–¥—É—Ç –≤ –æ–±—â–∏–π —á–∞—Ç (General)
    general_thread_id = TOPICS_TELEGRAM["General"].get("id") # None or 1

    time_now= datetime.now().time()
    # –§–æ—Ä–º–∏—Ä—É–µ–º —É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = (
        f"üåÖ {'–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ' if time(2, 0) < time_now < time(10, 0) else ('–î–æ–±—Ä—ã–π –¥–µ–Ω—å' if time(10, 1) < time_now < time(17, 0) else '–î–æ–±—Ä—ã–π –≤–µ—á–µ—Ä')}!\n\n"
        "–ß—Ç–æ–±—ã –ø—Ä–∏–Ω—è—Ç—å —É—á–∞—Å—Ç–∏–µ –≤ –ø–µ—Ä–µ–≤–æ–¥–µ, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É (—á–µ—Ä–µ–∑ –æ—Å–Ω–æ–≤–Ω–æ–µ –º–µ–Ω—é –∏–ª–∏ –µ—Å–ª–∏ –æ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Ç–µ–º–µ).\n"
        "–ü–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –Ω–∞—á–∞–ª–æ —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–∫–∏ üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥.\n\n"
        "üìå –í–∞–∂–Ω–æ:\n"
        "üîπ –û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ –ø–µ—Ä–µ–≤–æ–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n\n"
        "1. Mein Name ist Konchita.\n"
        "2. Ich wohne in Berlin.\n\n"
        "üîπ –ü–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤—Å–µ—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞–∂–º–∏—Ç–µ üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥, –∑–∞—Ç–µ–º ‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —á—Ç–æ–±—ã –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è.\n\n"
        "üîπ –í 09:00, 12:00 –∏ 15:00 - –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏—Ç–æ–≥–∏ –ø–æ –∫–∞–∂–¥–æ–º—É —É—á–∞—Å—Ç–Ω–∏–∫—É.\n\n"
        "üîπ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–ª—É—á–∏–º –≤ 23:30.\n\n"
        "üîπ –£–∑–Ω–∞—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞ - –∫–Ω–æ–ø–∫–∞ üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞.\n"
    )

    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ ( ReplyKeyboard buttons are like commands here)
    commands = (
        "üìú **–î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è (–∏—â–∏—Ç–µ –∏—Ö –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ–Ω—é):**\n"
        "üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É - –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞\n"
        "üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥ - –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã.\n"
        "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ - –ü–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥\n"
        "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ - –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ –∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è.\n"
        "üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ - –£–∑–Ω–∞—Ç—å —Å–≤–æ—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n"
    )

    await context.bot.send_message(
        chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
        text = message,
        message_thread_id = general_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ General
        )
    await context.bot.send_message(
        chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
        text= commands,
        message_thread_id = general_thread_id, # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ General
        parse_mode = "Markdown"
        )



async def letsgo(update: Update, context: CallbackContext):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–∫—É–¥–∞ –≤—ã–∑–≤–∞–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è: —á–µ—Ä–µ–∑ message (Reply button) –∏–ª–∏ callback_query (Inline button)
    if update.message:
        user = update.message.from_user
        chat_id = update.message.chat_id
        message_thread_id = update.message.message_thread_id
    elif update.callback_query:
        user = update.callback_query.from_user
        chat_id = update.callback_query.message.chat_id
        message_thread_id = update.callback_query.message.message_thread_id
    else:
        logging.error("‚ùå –ù–µ—Ç –Ω–∏ message, –Ω–∏ callback_query –≤ update!")
        return

    user_id = user.id
    username = user.username or user.first_name

    # ‚úÖ –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—è `start_times` –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –µ–≥–æ (—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ –Ω–∞—á–∞–ª–µ –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞)
    if "start_times" not in context.user_data:
        context.user_data["start_times"] = {}

    # ‚úÖ –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞ **–¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**
    context.user_data["start_times"][user_id] = datetime.now()

    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ç–∞–π–º–µ—Ä–æ–º
    timer_message = await context.bot.send_message(
        chat_id=chat_id,
        text="‚è≥ –í—Ä–µ–º—è –ø–µ—Ä–µ–≤–æ–¥–∞: 0 –º–∏–Ω 0 —Å–µ–∫",
        message_thread_id=message_thread_id
    )

    # ‚úÖ –ó–∞–ø—É—Å–∫–∞–µ–º `start_timer()` —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ (assuming start_timer exists elsewhere)
    # asyncio.create_task(start_timer(chat_id, context, timer_message.message_id, user_id))


    # üîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã–±—Ä–∞–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–µ–º—É (—Ç–µ–º–∞ —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ user_data –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ Inline –∫–Ω–æ–ø–∫–æ–π)
    chosen_topic = context.user_data.get("chosen_topic")
    if not chosen_topic:
        await context.bot.send_message(
            chat_id=chat_id,
            text="‚ùå –í—ã –Ω–µ –≤—ã–±—Ä–∞–ª–∏ —Ç–µ–º—É! –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –∏—Å–ø–æ–ª—å–∑—É—è –∫–Ω–æ–ø–∫—É 'üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É'",
            message_thread_id=message_thread_id
        )
        return

    conn = get_db_connection()
    cursor = conn.cursor()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª –ª–∏ —É–∂–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥ (–Ω–æ —Ç–æ–ª—å–∫–æ –∑–∞ –°–ï–ì–û–î–ù–Ø!)
    cursor.execute("""
        SELECT user_id FROM user_progress_deepseek
        WHERE user_id = %s AND start_time::date = CURRENT_DATE AND completed = FALSE;
        """, (user_id, ))
    active_session = cursor.fetchone()

    if active_session is not None:
        logging.info(f"‚è≥ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {username} ({user_id}) —É–∂–µ –Ω–∞—á–∞–ª –ø–µ—Ä–µ–≤–æ–¥ —Å–µ–≥–æ–¥–Ω—è.")
        #await update.message.reply_animation("https://media.giphy.com/media/3o7aD2saalBwwftBIY/giphy.gif") # GIFs require appropriate handler
        await context.bot.send_message(
            chat_id=chat_id,
            text="‚ùå –í—ã —É–∂–µ –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–≤–æ–¥! –ó–∞–≤–µ—Ä—à–∏—Ç–µ –µ–≥–æ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –∑–∞–ø—É—Å–∫–æ–º –Ω–∞–∂–∞–≤ –Ω–∞ –∫–Ω–æ–ø–∫—É '‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'",
            message_thread_id=message_thread_id
        )
        cursor.close()
        conn.close()
        return

    # ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–∞–µ–º –≤—á–µ—Ä–∞—à–Ω–∏–µ —Å–µ—Å—Å–∏–∏**
    cursor.execute("""
        UPDATE user_progress_deepseek
        SET end_time = NOW(), completed = TRUE
        WHERE user_id = %s AND start_time::date < CURRENT_DATE AND completed = FALSE;
    """, (user_id,))

    # üîπ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º session_id –Ω–∞ –æ—Å–Ω–æ–≤–µ user_id + —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    session_id = int(hashlib.md5(f"{user_id}{datetime.now()}".encode()).hexdigest(), 16) % (10 ** 12)

    # ‚úÖ **–°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å –≤ `user_progress`, –ù–ï –ó–ê–¢–ò–†–ê–Ø —Å—Ç–∞—Ä—ã–µ —Å–µ—Å—Å–∏–∏ –∏ –ø–æ–ª—É—á–∞–µ–º `session_id`****
    cursor.execute("""
        INSERT INTO user_progress_deepseek (session_id, user_id, username, start_time, completed)
        VALUES (%s, %s, %s, NOW(), FALSE);
    """, (session_id, user_id, username))

    conn.commit()


    # ‚úÖ **–í—ã–¥–∞—ë–º –Ω–æ–≤—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è**
    sentences = [s.strip() for s in await get_original_sentences(user_id, context) if s.strip()]

    if not sentences:
        await context.bot.send_message(
            chat_id=chat_id,
            text="‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            message_thread_id=message_thread_id
        )
        cursor.close()
        conn.close()
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å (–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–µ–ª–∞–ª /getmore - though /getmore is not implemented here)
    cursor.execute("""
        SELECT COUNT(*) FROM daily_sentences_deepseek WHERE date = CURRENT_DATE AND user_id = %s;
    """, (user_id,))
    last_index = cursor.fetchone()[0]

    # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å, –±—ã–ª–∏ –ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    original_sentences = sentences
    sentences = correct_numbering(sentences) # Assumes correct_numbering handles the list format

    for before, after in zip(original_sentences, sentences):
        if before != after:
            logging.info(f"‚ö†Ô∏è –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –Ω—É–º–µ—Ä–∞—Ü–∏—è: '{before}' ‚Üí '{after}'")

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –±–∞–∑—É
    tasks = []
    for i, sentence in enumerate(sentences, start=last_index + 1):
        # Store in DB
        cursor.execute("""
            INSERT INTO daily_sentences_deepseek (date, sentence, unique_id, user_id, session_id)
            VALUES (CURRENT_DATE, %s, %s, %s, %s);
        """, (sentence, i, user_id, session_id))
        # Format for user display
        tasks.append(f"{i}. {sentence}")


    conn.commit()
    cursor.close()
    conn.close()

    logging.info(f"üöÄ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {username} ({user_id}) –Ω–∞—á–∞–ª –ø–µ—Ä–µ–≤–æ–¥. –ó–∞–ø–∏—Å–∞–Ω–æ {len(tasks)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")

    # üîπ **–°–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**
    context.user_data["pending_translations"] = []


    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ **–∏ —Ç–∞–π–º–µ—Ä–æ–º**
    task_text = "\n".join(tasks)
    print(f"Sentences before sending to the user: {task_text}")

    intro_text= (
    f"üöÄ {user.first_name}, –í—ã –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–≤–æ–¥! –í—Ä–µ–º—è –ø–æ—à–ª–æ.\n\n"
    "‚úèÔ∏è –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à–∏ –ø–µ—Ä–µ–≤–æ–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ: 1. Mein Name ist Konchita.\n\n"
    "–ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ, –Ω–∞–∂–º–∏—Ç–µ:\n"
    "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥\n\n"
    "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ (—á—Ç–æ–±—ã –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è)"
    )


    await context.bot.send_message(
        chat_id=chat_id,
        text=intro_text,
        message_thread_id=message_thread_id
    )

    await context.bot.send_message(
        chat_id=chat_id,
        text=f"{user.first_name}, –í–∞—à–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è:\n{task_text}",
        message_thread_id=message_thread_id
    )



# üîπ **–§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥—ã, –Ω–æ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö**
async def handle_user_message(update: Update, context: CallbackContext):
    # ‚úÖ –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ update.message –¥–∞–Ω–Ω—ã–µ
    if update.message is None or update.message.text is None:
        logging.warning("‚ö†Ô∏è update.message –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ–µ.")
        return  # ‚õî –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç

    user_id = update.message.from_user.id
    text = update.message.text.strip()
    chat_id = update.message.chat_id
    message_thread_id = update.message.message_thread_id # Get thread_id

    # Check if the message is a command (e.g., /start, /stats).
    # If it is, let the command handler handle it and exit this function.
    if text.startswith('/'):
        print(f"DEBUG: –°–æ–æ–±—â–µ–Ω–∏–µ '{text}' - —ç—Ç–æ –∫–æ–º–∞–Ω–¥–∞. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º handle_user_message.")
        return # Let CommandHandler process it

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–æ–º (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π)
    # Regex updated to handle potential newlines within a single translation
    pattern = re.compile(r"(\d+)\.\s*(.+?)(?=\n\d+\.|$)", re.DOTALL)
    translations = pattern.findall(text)

    if translations:
        if "pending_translations" not in context.user_data:
            context.user_data["pending_translations"] = []

        found_translations = False
        for num, trans in translations:
             # Clean up each translation part
            cleaned_trans = trans.strip()
            if cleaned_trans:
                full_translation = f"{num}. {cleaned_trans}"
                context.user_data["pending_translations"].append(full_translation)
                logging.info(f"üìù –î–æ–±–∞–≤–ª–µ–Ω –ø–µ—Ä–µ–≤–æ–¥: {full_translation}")
                found_translations = True

        if found_translations:
             # Send confirmation message back to the same thread
             await context.bot.send_message(
                chat_id = chat_id, # Use current chat_id
                text = ("‚úÖ –í–∞—à –ø–µ—Ä–µ–≤–æ–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω.\n\n"
                "–ö–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã, –Ω–∞–∂–º–∏—Ç–µ:\n"
                "üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥.\n\n"
                "‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —á—Ç–æ–±—ã –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è.\n"),
                message_thread_id=message_thread_id # Use current thread_id
                )
        else:
             # If pattern matched but translations were empty after stripping
             logging.warning(f"‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω –ø–µ—Ä–µ–≤–æ–¥–∞ —Å–æ–≤–ø–∞–ª, –Ω–æ –ø–µ—Ä–µ–≤–æ–¥—ã –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –¥–ª—è user {user_id}. –¢–µ–∫—Å—Ç: '{text}'")
             # Optionally send a message asking for correct format
             # await context.bot.send_message(...)
             pass # Do nothing if no valid translations were found

    # If the message is NOT a translation pattern and NOT a command, it's just regular text.
    # Let the log_message handler (group -1) handle logging.
    # Do NOT call handle_button_click here. Reply button text is handled by specific MessageHandlers.
    # Inline button clicks are handled by CallbackQueryHandler.
    else:
        print(f"DEBUG: –°–æ–æ–±—â–µ–Ω–∏–µ '{text}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–µ–≤–æ–¥–æ–º –∏–ª–∏ –∫–æ–º–∞–Ω–¥–æ–π. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º handle_user_message.")
        pass # Do nothing more in this handler


async def done(update: Update, context: CallbackContext):
    if update.message:
        user = update.message.from_user
        chat_id = update.message.chat_id
        message_thread_id = update.message.message_thread_id
    elif update.callback_query:
        user = update.callback_query.from_user
        chat_id = update.callback_query.message.chat_id
        message_thread_id = update.callback_query.message.message_thread_id
    else:
        logging.error("‚ùå –ù–µ—Ç –Ω–∏ message, –Ω–∏ callback_query –≤ update!")
        return

    user_id = user.id

    # ‚úÖ –î–∞—ë–º 5 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    logging.info(f"‚åõ –ñ–¥—ë–º 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º —Å–µ—Å—Å–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}...")
    await asyncio.sleep(5)

    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è (–∑–∞ —Å–µ–≥–æ–¥–Ω—è)
    cursor.execute("""
        SELECT session_id
        FROM user_progress_deepseek
        WHERE user_id = %s AND completed = FALSE AND start_time::date = CURRENT_DATE
        ORDER BY start_time DESC
        LIMIT 1;""",
        (user_id,))
    session = cursor.fetchone()

    if not session:
        await context.bot.send_message(
            chat_id=chat_id,
            text="‚ùå –£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏: 'üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É' -> 'üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥' —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.",
            message_thread_id=message_thread_id
            )
        cursor.close()
        conn.close()
        return
    session_id = session[0]   # ID —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏

    # ‚úÖ –ü–æ–∑–≤–æ–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤—Å–µ–≥–¥–∞ –∑–∞–≤–µ—Ä—à–∞—Ç—å —Å–µ—Å—Å–∏—é –≤—Ä—É—á–Ω—É—é (—Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â—É—é)
    cursor.execute("""
        UPDATE user_progress_deepseek
        SET end_time = NOW(), completed = TRUE
        WHERE user_id = %s AND session_id = %s AND completed = FALSE;""",
        (user_id, session_id)) # Use session_id as well for precision
    conn.commit()

    # üîπ –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã
    cursor.execute("""
        SELECT COUNT(*) FROM daily_sentences_deepseek
        WHERE user_id = %s AND session_id = %s;
    """, (user_id, session_id))
    total_sentences = cursor.fetchone()[0]

    cursor.execute("""
        SELECT COUNT(*) FROM translations_deepseek
        WHERE user_id = %s AND session_id = %s;
        """,(user_id, session_id))
    translated_count = cursor.fetchone()[0]

    if translated_count < total_sentences:
        await context.bot.send_message(
            chat_id=chat_id,
            text =
            (f"‚ö†Ô∏è –í—ã –ø–µ—Ä–µ–≤–µ–ª–∏ {translated_count} –∏–∑ {total_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n"
            "–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω, –Ω–æ –Ω–µ –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã! –≠—Ç–æ –ø–æ–≤–ª–∏—è–µ—Ç –Ω–∞ –≤–∞—à –∏—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª."),
            message_thread_id=message_thread_id
        )
    else:
        await context.bot.send_message(
        chat_id=chat_id,
        text="‚úÖ **–í—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥! –í—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã.**",
        message_thread_id=message_thread_id
    )

    cursor.close()
    conn.close()


def correct_numbering(sentences):
    """!?! –ù–æ —ç—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–ª–∏–Ω—ã —à–∞–±–ª–æ–Ω–∞ –≤–Ω—É—Ç—Ä–∏ —Å–∫–æ–±–æ–∫(?<=^\d+\.), –ü–æ—ç—Ç–æ–º—É –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç.–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω—É–º–µ—Ä–∞—Ü–∏—é, —É–¥–∞–ª—è—è —Ç–æ–ª—å–∫–æ –≤—Ç–æ—Ä—É—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Ü–∏—Ñ—Ä—É.
    (?<=^\d+\.) ‚Äî –ù–∞–π–¥–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–µ—Ä–µ–¥ –Ω–∏–º –µ—Å—Ç—å —á–∏—Å–ª–æ —Å —Ç–æ—á–∫–æ–π –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
    –≠—Ç–æ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è lookbehind assertion. –ù–∞–ø—Ä–∏–º–µ—Ä, 29. –±—É–¥–µ—Ç –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –Ω–µ –∑–∞–º–µ–Ω–µ–Ω–æ.
    \s*\d+\.\s* ‚Äî —Ç–µ–ø–µ—Ä—å –∑–∞–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤—Ç–æ—Ä–∞—è —Ü–∏—Ñ—Ä–∞."""
    corrected_sentences = []
    for sentence in sentences:
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ **–≤—Ç–æ—Ä–æ–µ** —á–∏—Å–ª–æ, –æ—Å—Ç–∞–≤–ª—è—è –ø–µ—Ä–≤–æ–µ
        # Fix: Ensure regex matches only the *start* of the string
        # This regex looks for start-of-string (\d+\.) followed by optional space, then another (\d+\.)
        # It keeps the first (\1.) and replaces the rest.
        cleaned_sentence = re.sub(r"^(\d+)\.\s*\d+\.\s*", r"\1. ", sentence).strip()
        # Add another check for common issues like leading numbers without a dot or spaces
        cleaned_sentence = re.sub(r"^\d+\s+", "", cleaned_sentence).strip() # Remove leading number + space (if not 1. 2.)
        cleaned_sentence = re.sub(r"^-\s+", "", cleaned_sentence).strip() # Remove leading dash+space
        corrected_sentences.append(cleaned_sentence)
    return corrected_sentences


# –°–æ–∑–¥–∞—ë—Ç –∫–Ω–æ–ø–∫–∏ —Å —Ç–µ–º–∞–º–∏ (Business, Medicine, Hobbies –∏ —Ç. –¥.).
async def choose_topic(update: Update, context: CallbackContext):
    """–í—ã–≤–æ–¥–∏—Ç –∫–Ω–æ–ø–∫–∏ —Å —Ç–µ–º–∞–º–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º."""
    global TOPICS
    logging.info("üìå –í—ã–∑–≤–∞–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è choose_topic()")

    # Get chat and thread ID regardless if it's message or callback_query
    if update.message:
        chat_id = update.message.chat_id
        message_thread_id = update.message.message_thread_id
    elif update.callback_query:
        chat_id = update.callback_query.message.chat_id
        message_thread_id = update.callback_query.message.message_thread_id
    else:
        logging.error("‚ùå –ù–µ—Ç –Ω–∏ message, –Ω–∏ callback_query –≤ update!")
        return

    # Ensure the message is sent to the '√úbersetzungen' topic
    translation_thread_id = TOPICS_TELEGRAM["√úbersetzungen"].get("id")
    if translation_thread_id is None:
        logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ thread_id –¥–ª—è —Ç–µ–º—ã √úbersetzungen!")
        await context.bot.send_message(chat_id=chat_id, text="‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Ç–µ–º–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤.", message_thread_id=message_thread_id)
        return


    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –≤—ã–±–æ—Ä–æ–º —Ç–µ–º—ã, –µ—Å–ª–∏ –æ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if "topic_message_id" in context.user_data and "topic_message_chat_id" in context.user_data:
        try:
            await context.bot.delete_message(
                chat_id=context.user_data["topic_message_chat_id"], # Use saved chat_id
                message_id=context.user_data["topic_message_id"]
            )
            logging.info("‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –≤—ã–±–æ—Ä–æ–º —Ç–µ–º—ã.")
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –≤—ã–±–æ—Ä–æ–º —Ç–µ–º—ã: {e}")

    # –°–æ–∑–¥–∞—ë–º –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏ –ø–æ –¥–≤–µ –≤ —Ä—è–¥ –¥–ª—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏
    buttons = [
        [InlineKeyboardButton(TOPICS[i], callback_data=TOPICS[i]),
         InlineKeyboardButton(TOPICS[i+1], callback_data=TOPICS[i+1])]
         for i in range(0, len(TOPICS) -1, 2)
    ]
    # –ï—Å–ª–∏ –Ω–µ—á—ë—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–º ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∫–Ω–æ–ø–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ
    if len(TOPICS) %2 !=0:
        buttons.append([InlineKeyboardButton(TOPICS[-1], callback_data=TOPICS[-1])])

    reply_markup = InlineKeyboardMarkup(buttons)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏ –≤ —Ç–æ–ø–∏–∫ "√úbersetzungen"
    sent_message = await context.bot.send_message(
        chat_id = chat_id, # Use current chat_id (should be the group ID)
        text = "üìå –í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–æ–≤:",
        reply_markup=reply_markup,
        message_thread_id = translation_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ √úbersetzungen
        )
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID —Å–æ–æ–±—â–µ–Ω–∏—è –∏ chat_id –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏ –Ω–æ–≤–æ–º –≤—ã–∑–æ–≤–µ
    context.user_data["topic_message_id"] = sent_message.message_id
    context.user_data["topic_message_chat_id"] = chat_id


# –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç –Ω–∞ –∫–Ω–æ–ø–∫—É, Telegram –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç callback-–∑–∞–ø—Ä–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –º—ã –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –≤ topic_selected().
async def topic_selected(update: Update, context: CallbackContext):
    """Handles the Inline button click event when the user selects a topic."""
    query = update.callback_query
    await query.answer() # Acknowledge the click

    chosen_topic = query.data
    context.user_data["chosen_topic"] = chosen_topic

    logging.info(f"‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {query.from_user.id} –≤—ã–±—Ä–∞–ª —Ç–µ–º—É: {chosen_topic}")

    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏ –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã
    try:
        await context.bot.delete_message(
            chat_id=query.message.chat_id,
            message_id=query.message.message_id
        )
        logging.info(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ —Å –∫–Ω–æ–ø–∫–∞–º–∏ —É–¥–∞–ª–µ–Ω–æ –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã: {chosen_topic}")

    except Exception as e:
        logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è —Å –∫–Ω–æ–ø–∫–∞–º–∏: {e}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã
    await letsgo(update, context) # Pass update and context



# === –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–æ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é GPT-4 ===
async def generate_sentences(user_id, num_sentances, context: CallbackContext = None):
    client = openai.AsyncOpenAI(api_key=openai.api_key)
    #client_deepseek = OpenAI(api_key = api_key_deepseek,base_url="https://api.deepseek.com")

    # Get chosen topic from user_data if available
    chosen_topic = context.user_data.get("chosen_topic", "Random sentences")  # Default: General topic


    if chosen_topic != "Random sentences":
        prompt = f"""
        –ü—Ä–∏–¥—É–º–∞–π {num_sentances} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —É—Ä–æ–≤–Ω—è B2-C1 –Ω–∞ —Ç–µ–º—É "{chosen_topic}" –Ω–∞ **—Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ** –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ **–Ω–µ–º–µ—Ü–∫–∏–π**.

        **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
        - –°–≤—è–∂–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –æ–¥–Ω—É –ª–æ–≥–∏—á–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é.
        - –ò—Å–ø–æ–ª—å–∑—É–π **–ø–∞—Å—Å–∏–≤–Ω—ã–π –∑–∞–ª–æ–≥** –∏ **Konjunktiv II** –í 30% –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
        - –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å **–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ**.
        - **–ù–ï –¥–æ–±–∞–≤–ª—è–π –ø–µ—Ä–µ–≤–æ–¥!** –¢–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
        - –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∞—Å—Ç–æ —É–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å–Ω—É—é –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏ –ª–µ–∫—Å–∏–∫—É –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É.
            
        **–ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ –≤—ã–≤–æ–¥–∞:**
        –ï—Å–ª–∏ –±—ã —É –Ω–µ–≥–æ –±—ã–ª –¥—Ä—É–≥ —Ä—è–¥–æ–º, –∏–≥—Ä–∞—Ç—å –±—ã–ª–æ –±—ã –≤–µ—Å–µ–ª–µ–µ.
        –ó–Ω–∞—è, —á—Ç–æ —Å–∫–æ—Ä–æ –Ω—É–∂–Ω–æ –∏–¥—Ç–∏ –¥–æ–º–æ–π, –æ–Ω –ø–æ—Å—Ç–∞—Ä–∞–ª—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É.
        –ö–æ–≥–¥–∞ —Å—Ç–∞–ª–æ —Ç–µ–º–Ω–µ—Ç—å, –æ–Ω –ø–æ–ø—Ä–æ—â–∞–ª—Å—è —Å —Å–æ—Å–µ–¥—Å–∫–∏–º –∫–æ—Ç–æ–º –∏ –ø–æ–±–µ–∂–∞–ª –≤ –¥–æ–º.
        –°–¥–µ–ª–∞–≤ —É—Ä–æ–∫–∏, –æ–Ω –ª—ë–≥ —Å–ø–∞—Ç—å —Å –º—ã—Å–ª—è–º–∏ –æ –∑–∞–≤—Ç—Ä–∞—à–Ω–µ–º –¥–Ω–µ.
        """

    else:
        prompt = f"""
        –ü—Ä–∏–¥—É–º–∞–π {num_sentances} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —É—Ä–æ–≤–Ω—è B2-C1 –Ω–∞ **—Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ** –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ **–Ω–µ–º–µ—Ü–∫–∏–π**.

        **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
        - –ò—Å–ø–æ–ª—å–∑—É–π **–ø–∞—Å—Å–∏–≤–Ω—ã–π –∑–∞–ª–æ–≥** –∏ **Konjunktiv II** –í 30% –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.
        - –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å **–Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ**.
        - **–ù–ï –¥–æ–±–∞–≤–ª—è–π –ø–µ—Ä–µ–≤–æ–¥!** –¢–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä—É—Å—Å–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
        - –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∞—Å—Ç–æ —É–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å–Ω—É—é –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏ –ª–µ–∫—Å–∏–∫—É(–±–∏–∑–Ω–µ—Å –º–µ–¥–∏—Ü–∏–Ω–∞, –•–æ–±–±–∏, –°–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è, –£—á—ë–±–∞, –†–∞–±–æ—Ç–∞, –ü—É—Ç–µ—à–µ—Å—Ç–≤–∏—è) –∏ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É.

        **–ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ –≤—ã–≤–æ–¥–∞:**
        –ë—ã–ª–æ –±—ã –ª—É—á—à–µ, –µ—Å–ª–∏ –±—ã –æ–Ω —Å–æ–≥–ª–∞—Å–∏–ª—Å—è –Ω–∞ —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.
        –ù–∞–º —Å–∫–∞–∑–∞–ª–∏, —á—Ç–æ –ø—Ä–æ–µ–∫—Ç –±—É–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —á–µ—Ä–µ–∑ –Ω–µ–¥–µ–ª—é.
        –ï—Å–ª–∏ –±—ã –æ–Ω –º–æ–≥ –≥–æ–≤–æ—Ä–∏—Ç—å –Ω–∞ –Ω–µ–º–µ—Ü–∫–æ–º, –æ–Ω –±—ã –ª–µ–≥–∫–æ –Ω–∞—à–µ–ª —Ä–∞–±–æ—Ç—É.
        –°–¥–µ–ª–∞–≤ —Ä–∞–±–æ—Ç—É –æ–Ω –ø–æ—à—ë–ª –æ—Ç–¥—ã—Ö–∞—Ç—å.
        –ó–Ω–∞—è –æ –≤–µ–∂–ª–∏–≤–æ—Å—Ç–∏ –Ω–µ–º—Ü–µ–≤ —è –≤—ã–±—Ä–∞–ª –≤–µ–∂–ª–∏–≤—É—é —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É.
        –ù–µ –∑–Ω–∞—è –µ–≥–æ –ª–∏—á–Ω–æ, –µ–≥–æ –ø–æ—Å—Ç—É–ø–æ–∫ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å.
        –£—á–∏—Ç—ã–≤–∞—è –ø—Ä–∞–≤–∏–ª–∞ –≤–µ–∂–ª–∏–≤–æ—Å—Ç–∏, –æ–Ω –≥–æ–≤–æ—Ä–∏–ª —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ.
        """
    #–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é GPT
    for attempt in range(5): # –ü—Ä–æ–±—É–µ–º –¥–æ 5 —Ä–∞–∑ –ø—Ä–∏ –æ—à–∏–±–∫–µ
        try:
            response = await client.chat.completions.create(
                model = "gpt-4-turbo", # or "gpt-3.5-turbo" for faster/cheaper option
                messages = [{"role": "user", "content": prompt}]
            )
            sentences = response.choices[0].message.content.split("\n")
            filtered_sentences = [s.strip() for s in sentences if s.strip()] # ‚úÖ –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏

            if filtered_sentences:
                return filtered_sentences

        except openai.RateLimitError:
            wait_time = (attempt +1) * 2 # –ó–∞–¥–µ—Ä–∂–∫–∞: 2, 4, 6 —Å–µ–∫...
            print(f"‚ö†Ô∏è OpenAI API Rate Limit. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
            await asyncio.sleep(wait_time)
        except Exception as e: # Catch other potential OpenAI errors
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {e}")
            wait_time = (attempt + 1) * 3 # Wait a bit longer for other errors
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ OpenAI. –ñ–¥–µ–º {wait_time} —Å–µ–∫...")
            await asyncio.sleep(wait_time)

    print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç OpenAI –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.")


    # # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é DeepSeek API ( Uncomment if you want to use DeepSeek as fallback or primary)
    # try:
    #     client_deepseek = OpenAI(api_key=api_key_deepseek, base_url="https://api.deepseek.com")
    #     for attempt in range(3): # Try DeepSeek a few times
    #         try:
    #             response = await client_deepseek.chat.completions.create(
    #                 model="deepseek-chat",
    #                 messages=[{"role": "user", "content": prompt}], stream=False
    #             )
    #             sentences = response.choices[0].message.content.split("\n")
    #             filtered_sentences = [s.strip() for s in sentences if s.strip()]
    #             if filtered_sentences:
    #                 print("‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ DeepSeek.")
    #                 return filtered_sentences
    #         except Exception as e:
    #             logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ DeepSeek API: {e}. –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/3")
    #             await asyncio.sleep(5) # Wait before retrying DeepSeek
    #     print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç DeepSeek –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫.")
    # except Exception as e:
    #      logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –≤—ã–∑–æ–≤–∞ DeepSeek: {e}")
    #      print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –≤—ã–∑–æ–≤–∞ DeepSeek: {e}")


    conn = get_db_connection()
    cursor = conn.cursor()

    # Fallback to spare sentences if API calls failed
    try:
        cursor.execute("""
            SELECT sentence FROM spare_sentences_deepseek ORDER BY RANDOM() LIMIT %s;""", (num_sentances,))
        spare_rows = cursor.fetchall()

        if spare_rows:
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º {len(spare_rows)} –∑–∞–ø–∞—Å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.")
            return [row[0].strip() for row in spare_rows if row[0].strip()]
        else:
            print("‚ùå –û—à–∏–±–∫–∞: –¥–∞–∂–µ –∑–∞–ø–∞—Å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
            # Return a few hardcoded examples if spare sentences are also missing
            return ["–ó–∞–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 1.", "–ó–∞–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 2.", "–ó–∞–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ 3."]
    finally:
        cursor.close()
        conn.close()


async def check_translation(original_text, user_translation, update: Update, context: CallbackContext, sentence_number):
    client = openai.AsyncOpenAI(api_key=openai.api_key)

    bewertungen_von_gpt_topic_id = TOPICS_TELEGRAM["Bewertungen von GPT"].get("id") # Use .get() for safety
    if bewertungen_von_gpt_topic_id is None: # Check for None
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω thread_id –¥–ª—è —Ç–µ–º—ã Bewertungen von GPT")
        # Fallback: Send to the thread where the command was issued? Or General?
        # Let's send to the thread where the check was initiated if topic id is missing
        target_thread_id = update.effective_message.message_thread_id
        if target_thread_id is None:
            target_thread_id = TOPICS_TELEGRAM["General"].get("id") or None # Fallback to General if command was in main chat
        await context.bot.send_message(
             chat_id=update.effective_chat.id,
             text="‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Ç–µ–º–∞ –¥–ª—è –æ—Ü–µ–Ω–æ–∫ GPT. –û—Ç–ø—Ä–∞–≤–ª—è—é —Å—é–¥–∞.",
             message_thread_id=target_thread_id
             )
        target_thread_id = target_thread_id # Use this fallback thread_id for the actual message
    else:
        target_thread_id = bewertungen_von_gpt_topic_id


    # Send initial "thinking" message to the target thread
    message = await context.bot.send_message(
        chat_id=update.effective_chat.id,
        text="‚è≥ –ù—É, –≥–ª—è–Ω–µ–º —á—Ç–æ —Ç—ã —Ç—É—Ç –Ω–∞–ø–µ—Ä–µ–≤–æ–¥–∏–ª...",
        message_thread_id=target_thread_id
        )

    # Simulate typing in the target thread
    await simulate_typing(context, update.effective_chat.id, duration=3, thread_id=target_thread_id)


    prompt = f"""
    You are an expert German language teacher. Analyze the student's translation.

    **Original sentence (Russian):** "{original_text}"
    **User's translation (German):** "{user_translation}"

    **Your task:**
    1. **Give a score from 0 to 100** based on the original content, correct vocabulary usage, grammatical accuracy (this is the most important criterion when grading), and style. If the content is completely inaccurate, the score is zero.

    2. **Identify all mistake categories** (you may select multiple categories if needed, but STRICTLY from enumeration below, return as a comma separated string, e.g., "Nouns, Verbs"):
    - Nouns, Cases, Verbs, Tenses, Adjectives, Adverbs, Conjunctions, Prepositions, Moods, Word Order, Other mistake

    3. **Identify all specific mistake subcategories** (you may select multiple subcategories if needed, but STRICTLY from enumeration below, return as a comma separated string, e.g., "Gendered Articles, Conjugation"):

    **Fixed mistake subcategories:**
    - **Nouns:** Gendered Articles, Pluralization, Compound Nouns, Declension Errors
    - **Cases:** Nominative, Accusative, Dative, Genitive, Akkusativ + Preposition, Dative + Preposition, Genitive + Preposition
    - **Verbs:** Placement, Conjugation, Weak Verbs, Strong Verbs, Mixed Verbs, Separable Verbs, Reflexive Verbs, Auxiliary Verbs, Modal Verbs, Verb Placement in Subordinate Clause
    - **Tenses:** Present, Past, Simple Past, Present Perfect, Past Perfect, Future, Future 1, Future 2, Plusquamperfekt Passive, Futur 1 Passive, Futur 2 Passive
    - **Adjectives:** Endings, Weak Declension, Strong Declension, Mixed Declension, Placement, Comparative, Superlative, Incorrect Adjective Case Agreement
    - **Adverbs:** Placement, Multiple Adverbs, Incorrect Adverb Usage
    - **Conjunctions:** Coordinating, Subordinating, Incorrect Use of Conjunctions
    - **Prepositions:** Accusative, Dative, Genitive, Two-way, Incorrect Preposition Usage
    - **Moods:** Indicative, Declarative, Interrogative, Imperative, Subjunctive 1, Subjunctive 2
    - **Word Order:** Standard, Inverted, Verb-Second Rule, Position of Negation, Incorrect Order in Subordinate Clause, Incorrect Order with Modal Verb
    - **Other mistake:** Unclassified mistake

    4. **Provide a severity level from 1 to 5** where:
    - 1 = Minor stylistic error
    - 2 = Common mistake
    - 3 = Noticeable grammatical issue
    - 4 = Severe grammatical mistake
    - 5 = Critical mistake that changes the meaning

    5. **Provide the correct translation.**

    ---

    **Format your response STRICTLY as follows (without extra words, use newlines between fields):**
    Score: X/100
    Mistake Categories: ...
    Subcategories: ...
    Severity: ...
    Correct Translation: ...
        """


    collected_text = ""
    last_update_time = asyncio.get_running_loop().time()
    finished = False
    score = None
    categories = []
    subcategories = []
    severity = None
    correct_translation = None

    for attempt in range(3):
        try:
            stream_response = await client.chat.completions.create(
                model="gpt-4-turbo", # or gpt-3.5-turbo
                messages=[{"role": "user", "content": prompt}],
                stream=True
            )

            async for chunk in stream_response:
                if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:
                    new_text = chunk.choices[0].delta.content
                    collected_text += new_text

                    # Update message periodically to show progress
                    if asyncio.get_running_loop().time() - last_update_time > 2: # Update more frequently
                        try:
                            # Escape text for MarkdownV2 before editing
                            safe_text = escape_markdown_v2(collected_text)
                            # Limit text length for edit_message_text
                            if len(safe_text) > 4000: # Telegram limit is ~4096 chars
                                safe_text = safe_text[:3900] + "..." # Truncate if too long
                            await message.edit_text(safe_text, parse_mode="MarkdownV2") # Use MarkdownV2
                            last_update_time = asyncio.get_running_loop().time()
                        except TelegramError as e:
                            # Handle potential Telegram errors during edit (e.g., message modified)
                             if 'message is not modified' in str(e).lower():
                                 pass # Ignore if message hasn't changed
                             else:
                                 logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                                 # If editing fails repeatedly, maybe send a new message instead?
                                 # For now, just log and continue
                        except Exception as e:
                             logging.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")


            # ‚úÖ Finished streaming
            if collected_text:
                finished = True
                # Final edit after stream ends
                try:
                    safe_text = escape_markdown_v2(collected_text)
                    await message.edit_text(safe_text, parse_mode="MarkdownV2") # Final edit with MarkdownV2
                except TelegramError as e:
                     if 'message is not modified' in str(e).lower():
                         pass # Ignore if message hasn't changed
                     else:
                         logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
                except Exception as e:
                     logging.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

                # ‚úÖ Parse the full collected text
                score_match = re.search(r"Score:\s*(\d+)/100", collected_text)
                score = int(score_match.group(1)) if score_match else None

                categories_match = re.search(r"Mistake Categories:\s*(.*)", collected_text)
                categories = [cat.strip() for cat in categories_match.group(1).split(',') if cat.strip()] if categories_match else []
                # Clean categories
                categories = [re.sub(r"[^0-9a-zA-Z\s,+\-‚Äì]", "", cat).strip() for cat in categories if cat.strip()]


                subcategories_match = re.search(r"Subcategories:\s*(.*)", collected_text)
                subcategories = [subcat.strip() for subcat in subcategories_match.group(1).split(',') if subcat.strip()] if subcategories_match else []
                # Clean subcategories
                subcategories = [re.sub(r"[^0-9a-zA-Z\s,+\-‚Äì]", "", subcat).strip() for subcat in subcategories if subcat.strip()]


                severity_match = re.search(r"Severity:\s*(\d+)", collected_text)
                severity = int(severity_match.group(1)) if severity_match else None

                correct_translation_match = re.search(r"Correct Translation:\s*(.*)", collected_text, re.DOTALL) # Use DOTALL to match newlines
                correct_translation = correct_translation_match.group(1).strip() if correct_translation_match else None

                # ‚úÖ Log parsed data
                print(f"üîé PARSED DATA: Score={score}, Categories={categories}, Subcategories={subcategories}, Severity={severity}, Correct Translation={correct_translation[:50]}...") # Log partial translation


                # ‚úÖ Remove the initial "thinking" message if editing was successful
                # await message.delete() # Better keep the message with the final response

                # ‚úÖ Add Inline button after sending the message (edit the final message)
                if target_thread_id == TOPICS_TELEGRAM["Bewertungen von GPT"].get("id"): # Only add button in the GPT topic
                     # Add a key to store translation data for Claude explanation
                     message_id_for_claude = message.message_id
                     context.user_data[f"translation_for_claude_{message_id_for_claude}"] = {
                         "original_text": original_text,
                         "user_translation": user_translation
                     }
                     keyboard = [[InlineKeyboardButton("‚ùì Explain me with Claude", callback_data=f"explain:{message_id_for_claude}")]]
                     reply_markup = InlineKeyboardMarkup(keyboard)

                     try:
                        # Edit the final message to add the button
                        # Need to get the current text content first, or reconstruct it
                        # Or simply edit the reply_markup of the message object
                        await context.bot.edit_message_reply_markup(
                            chat_id=message.chat_id,
                            message_id=message.message_id,
                            reply_markup=reply_markup
                        )
                        print(f"‚úÖ Added 'Explain with Claude' button to message {message.message_id}")
                     except Exception as e:
                         logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –∏–Ω–ª–∞–π–Ω-–∫–Ω–æ–ø–∫–∏ –∫ —Å–æ–æ–±—â–µ–Ω–∏—é {message.message_id}: {e}")


                # ‚úÖ Log successful check
                logging.info(f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–æ–≤–µ—Ä–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.id}")

                # Return parsed results
                return collected_text, categories, subcategories, score, severity, correct_translation

            else:
                 logging.warning("‚ö†Ô∏è GPT returned empty response after stream.")
                 print("‚ùå –û—à–∏–±–∫–∞: GPT –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")


        except TelegramError as e:
            if 'flood control' in str(e).lower():
                wait_time = int(re.search(r'\d+', str(e)).group()) if re.search(r'\d+', str(e)) else 5
                wait_time = min(wait_time, 30) # Limit max wait time
                logging.warning(f"‚ö†Ô∏è Flood control exceeded. Retrying GPT check in {wait_time} seconds...")
                await asyncio.sleep(wait_time)
            else:
                 logging.error(f"‚ùå Telegram Error during GPT check: {e}")
                 break # Exit loop on other Telegram errors


        except openai.RateLimitError:
            wait_time = (attempt + 1) * 5
            logging.warning(f"‚ö†Ô∏è OpenAI API –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω. –ñ–¥—ë–º {wait_time} —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏...")
            await asyncio.sleep(wait_time)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ GPT –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")
            break # Exit loop on unexpected errors

    # If all attempts fail
    logging.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {update.effective_user.id} –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å.")
    try:
         await message.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", reply_markup=None) # Update the message indicating failure
    except Exception:
         await context.bot.send_message(chat_id=update.effective_chat.id, text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", message_thread_id=target_thread_id)

    return None, [], [], None, None, None # Return None/empty on failure


#‚úÖ Explain with Claude
async def check_translation_with_claude(original_text, user_translation, update, context):
    # Ensure Claude API key is loaded
    if not CLAUDE_API_KEY:
        logging.error("‚ùå CLAUDE_API_KEY –Ω–µ –∑–∞–¥–∞–Ω. –ù–µ –º–æ–≥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Claude.")
        await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="‚ùå API –∫–ª—é—á Claude –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ù–µ –º–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ.",
            message_thread_id=update.effective_message.message_thread_id
            )
        return

    client = AsyncAnthropic(api_key=CLAUDE_API_KEY)

    claud_topic_id = TOPICS_TELEGRAM["Erkl√§rungen von Claude"].get("id") # Use .get()
    if claud_topic_id is None: # Check for None
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω thread_id –¥–ª—è —Ç–µ–º—ã 'Erkl√§rungen von Claude'")
        # Fallback: Send to the thread where the button was clicked, or General
        target_thread_id = update.callback_query.message.message_thread_id
        if target_thread_id is None:
            target_thread_id = TOPICS_TELEGRAM["General"].get("id") or None # Fallback to General if command was in main chat
        await context.bot.send_message(
             chat_id=update.effective_chat.id,
             text="‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ —Ç–µ–º–∞ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏–π Claude. –û—Ç–ø—Ä–∞–≤–ª—è—é —Å—é–¥–∞.",
             message_thread_id=target_thread_id
             )
        target_thread_id = target_thread_id # Use this fallback thread_id for the actual message
    else:
         target_thread_id = claud_topic_id

    # Send initial "thinking" message to the target thread
    message = await context.bot.send_message(
        chat_id=update.effective_chat.id,
        text="‚è≥ Claude –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–≤–æ–¥...",
        message_thread_id=target_thread_id
        )
    # Simulate typing in the target thread
    await simulate_typing(context, update.effective_chat.id, duration=3, thread_id=target_thread_id)

    prompt = f"""
    You are an expert in Russian and German languages, a professional translator, and a German grammar instructor.
    Your task is to analyze the student's translation from Russian to German and provide detailed feedback according to the following criteria:
    ‚ùó Do NOT repeat the original text or the translation in your response ‚Äî only provide conclusions and explanations.
    Analysis Criteria:
    1. Errors:

    - Identify the key errors in the translation and classify them into the following categories:
        - Grammar (nouns, cases, verbs, tenses, prepositions, etc.)
        - Vocabulary (incorrect word choice, false friends, etc.)
        - Style (formal/informal register, clarity, tone, etc.)

    - Grammar Explanation:
        - Explain why the grammatical structure in the phrase is incorrect.
        - Provide a corrected version of the structure.
        - If the error is related to verb usage or prepositions, specify the correct form and usage.

    - Alternative Sentence Construction:
        - Suggest one alternative construction of the sentence.
        - Explain how the alternative differs in tone, formality, or meaning.

    - Synonyms:
        - Suggest possible synonyms for incorrect or less appropriate words.
        - Provide no more than two alternatives.
    ----------------------
    **Response Format**:
    **The response must follow this strict structured format**:
    Error 1: (Grammatical or lexical or stylistic error)
    Error 2: (Grammatical or lexical or stylistic error)
    Correct Translation: ...
    Grammar Explanation:
    Alternative Sentence Construction: ... (just a Alternative Sentence Construction without explanation)
    Synonyms:
    Original Word: ...
    Possible Synonyms: ... (no more than two)

    -------------------
    üîé Important Instructions:

    Follow the specified format strictly.
    Provide objective and constructive feedback.
    Do NOT add introductory phrases (e.g., "Here‚Äôs what I think...").
    The response should be clear and concise.

    Below you can find:
    **Original sentence (Russian):** "{original_text}"
    **User's translation (German):** "{user_translation}"

    """
    #available_models = await client.models.list() # Use list() to check available models
    # logging.info(f"üì¢ Available models: {available_models}")
    # print(f"üì¢ Available models: {available_models}")

    model_name = "claude-3-7-sonnet-20250219" # Specify the model

    cloud_response = None
    for attempt in range(3):
        try:
            response = await client.messages.create(
                model=model_name,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000, # Increase max_tokens for potentially longer explanations
                temperature=0.2
            )

            logging.info(f"üì• FULL CLAUDE RESPONSE: {response.content[0].text}")

            if response and response.content and response.content[0].text:
                cloud_response = response.content[0].text
                break
            else:
                logging.warning("‚ö†Ô∏è Claude returned an empty response content.")
                print("‚ùå –û—à–∏–±–∫–∞: Claude –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")
                await asyncio.sleep(5)

        except anthropic.APIError as e:
            logging.error(f"‚ùå API Error from Claude: {e}")
            if "authentication" in str(e).lower() or "invalid token" in str(e).lower():
                logging.error("üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Claude ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ–º —Ü–∏–∫–ª.")
                break
            else:
                logging.warning("‚ö†Ô∏è –û—à–∏–±–∫–∞ Claude. –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞ —á–µ—Ä–µ–∑ 5 —Å–µ–∫—É–Ω–¥...")
                await asyncio.sleep(5)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Claude: {e}")
            await asyncio.sleep(5) # Wait on other errors


    if not cloud_response:
        print("‚ùå –û—à–∏–±–∫–∞: –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç Claude –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
        await message.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç Claude. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.", reply_markup=None)
        return

    # Basic formatting for the response
    formatted_response = escape_markdown_v2(cloud_response) # Escape Claude's response

    # Send to the target thread
    try:
         await message.edit_text(formatted_response, parse_mode="MarkdownV2") # Edit the thinking message
    except TelegramError as e:
         logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è Claude: {e}. –û—Ç–ø—Ä–∞–≤–ª—è—é –∫–∞–∫ –Ω–æ–≤–æ–µ.")
         await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text=formatted_response,
            message_thread_id=target_thread_id, # Send as new message to the target thread
            parse_mode="MarkdownV2"
        )
    except Exception as e:
         logging.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞ Claude: {e}")
         await context.bot.send_message(
            chat_id=update.effective_chat.id,
            text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ Claude –∏–∑-–∑–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –æ—à–∏–±–∫–∏.",
            message_thread_id=target_thread_id
        )



async def log_translation_mistake(user_id, original_text, user_translation, categories, subcategories, score, severity, correct_translation):
    global VALID_CATEGORIES, VALID_SUBCATEGORIES, VALID_CATEGORIES_lower, VALID_SUBCATEGORIES_lower

    # ‚úÖ Log raw input for debugging
    print(f"üêõ log_translation_mistake received: UserID={user_id}, Original='{original_text[:50]}...', UserTrans='{user_translation[:50]}...', Categories={categories}, Subcategories={subcategories}, Score={score}, Severity={severity}")

    # ‚úÖ Normalize inputs to lower case for matching
    norm_categories = [cat.lower() for cat in categories]
    norm_subcategories = [subcat.lower() for subcat in subcategories]


    # ‚úÖ –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ—á–µ—Ç–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤
    valid_combinations = []
    for cat_lower in norm_categories:
        # Check if the category itself is valid (optional but good practice)
        if cat_lower not in VALID_CATEGORIES_lower:
            logging.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è '{cat_lower}' –∏–∑ GPT. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º.")
            continue

        for subcat_lower in norm_subcategories:
            # Check if the subcategory is valid for the current category
            if cat_lower in VALID_SUBCATEGORIES_lower and subcat_lower in VALID_SUBCATEGORIES_lower[cat_lower]:
                 # ‚úÖ Add normalized values to valid_combinations
                valid_combinations.append((cat_lower, subcat_lower))
            else:
                 # If a subcategory from the list doesn't match any valid subcategory for this category
                 logging.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è '{subcat_lower}' –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{cat_lower}' –∏–∑ GPT. –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∏–ª–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é.")
                 # Optionally add as unclassified if you want to log *something*
                 # valid_combinations.append(("other mistake", "unclassified mistake"))


    # ‚úÖ If no specific valid combinations were found, add an unclassified entry
    if not valid_combinations and (norm_categories or norm_subcategories):
         logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∞–ª–∏–¥–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π/–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π. –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫ –Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É.")
         valid_combinations.append(("other mistake", "unclassified mistake"))
    elif not valid_combinations and not (norm_categories or norm_subcategories):
         # This case should ideally not happen if score < 75, but as a safeguard
         logging.warning("‚ö†Ô∏è –ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏–ª–∏ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π, –∏ Score < 75? –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É.")
         return


    # ‚úÖ Remove duplicates from valid_combinations
    valid_combinations = list(set(valid_combinations))

    # ‚úÖ Parse severity, default to 3 if not found
    severity = int(severity) if severity is not None and str(severity).isdigit() else 3
    severity = max(1, min(5, severity)) # Ensure severity is between 1 and 5


    # ‚úÖ Log the final combinations to be saved
    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –æ—à–∏–±–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ ({len(valid_combinations)}):")
    for main_cat_lower, sub_cat_lower in valid_combinations:
         print(f"‚û°Ô∏è {main_cat_lower} - {sub_cat_lower}")


    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        for main_cat_lower, sub_cat_lower in valid_combinations:
            # Find the original casing from VALID_CATEGORIES and VALID_SUBCATEGORIES
            main_category_orig = next((cat for cat in VALID_CATEGORIES if cat.lower() == main_cat_lower), main_cat_lower)
            # Need to find the correct list of subcategories based on original main_category
            sub_category_orig = next((subcat for subcat in VALID_SUBCATEGORIES.get(main_category_orig, []) if subcat.lower() == sub_cat_lower), sub_cat_lower)


            print(f"üîç –ó–∞–ø–∏—Å—å –≤ –ë–î: user_id={user_id}, sentence='{original_text[:50]}...', main_cat='{main_category_orig}', sub_cat='{sub_category_orig}', severity={severity}")

            cursor.execute("""
                INSERT INTO detailed_mistakes_deepseek (
                    user_id, sentence, added_data, main_category, sub_category, severity, mistake_count
                ) VALUES (%s, %s, NOW(), %s, %s, %s, 1)
                ON CONFLICT (user_id, sentence, main_category, sub_category)
                DO UPDATE SET
                    mistake_count = detailed_mistakes_deepseek.mistake_count + 1,
                    last_seen = NOW();
            """, (user_id, original_text, main_category_orig, sub_category_orig, severity))

        conn.commit()
        print(f"‚úÖ –û—à–∏–±–∫–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –±–∞–∑—É detailed_mistakes_deepseek.")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ –ë–î detailed_mistakes_deepseek: {e}")
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ –ë–î detailed_mistakes_deepseek: {e}", exc_info=True) # Log traceback
        if conn:
            conn.rollback() # Rollback changes on error

    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

    # ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    print(f"‚úÖ log_translation_mistake –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")


async def check_translation_from_text(update: Update, context: CallbackContext):
    """Handles the '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥' action, triggering check_user_translation."""
    if update.message:
        user = update.message.from_user
        chat_id = update.message.chat_id
        message_thread_id = update.message.message_thread_id
    elif update.callback_query:
        user = update.callback_query.from_user
        chat_id = update.callback_query.message.chat_id
        message_thread_id = update.callback_query.message.message_thread_id
    else:
        logging.warning("‚ö†Ô∏è –ù–µ—Ç –Ω–∏ message, –Ω–∏ callback_query –≤ update!")
        return

    user_id = user.id


    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã
    if "pending_translations" not in context.user_data or not context.user_data["pending_translations"]:
        logging.info(f"‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–∞–∂–∞–ª 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥', –Ω–æ —É –Ω–µ–≥–æ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤!")
        await context.bot.send_message(
            chat_id = chat_id,
            text = "‚ùå –£ –≤–∞—Å –Ω–µ—Ç –Ω–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤! –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ø–µ—Ä–µ–≤–æ–¥, –∑–∞—Ç–µ–º –Ω–∞–∂–º–∏—Ç–µ 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'.",
            message_thread_id = message_thread_id
        )
        return

    logging.info(f"üìå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–∞–∂–∞–ª –∫–Ω–æ–ø–∫—É 'üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥'. –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–≤–æ–¥–æ–≤.")

    # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è check_user_translation
    # We need to pass the raw list, check_user_translation handles parsing
    translations_list = context.user_data["pending_translations"]

    # ‚úÖ –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–∂–∏–¥–∞—é—â–∏—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (—á—Ç–æ–±—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–ª–∏—Å—å)
    context.user_data["pending_translations"] = []

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π –≤ `check_user_translation()`
    logging.info(f"üìú –ü–µ—Ä–µ–¥–∞—ë–º {len(translations_list)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ check_user_translation():\n{translations_list}")

    # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ `check_user_translation()`
    await check_user_translation(update, context, translations_list)


async def check_user_translation(update: Update, context: CallbackContext, pending_translations_list=None):
    """Processes a list of user translations against original sentences."""
    if update.message:
        user = update.message.from_user
        chat_id = update.message.chat_id
        message_thread_id = update.message.message_thread_id
    elif update.callback_query:
        user = update.callback_query.from_user
        chat_id = update.callback_query.message.chat_id
        message_thread_id = update.callback_query.message.message_thread_id
    else:
        logging.warning("‚ö†Ô∏è –ù–µ—Ç –Ω–∏ message, –Ω–∏ callback_query –≤ update.")
        return

    user_id = user.id
    username = user.first_name

    # If no list is provided, get from user_data (e.g., if called directly via /translate)
    if pending_translations_list is None:
        if "pending_translations" in context.user_data and context.user_data["pending_translations"]:
            pending_translations_list = context.user_data["pending_translations"]
            context.user_data["pending_translations"] = [] # Clear after getting
        else:
            await context.bot.send_message(
                chat_id=chat_id,
                text="‚ùå –ù–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏. –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ø–µ—Ä–µ–≤–æ–¥—ã.",
                message_thread_id=message_thread_id
            )
            return

    if not pending_translations_list:
        await context.bot.send_message(
            chat_id=chat_id,
            text="‚ùå –ù–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏.",
            message_thread_id=message_thread_id
        )
        return

    # Parse the list into a dictionary {sentence_number: user_translation_text}
    translations_dict = {}
    pattern = re.compile(r"(\d+)\.\s*(.+)") # Basic pattern to extract number and text
    for item in pending_translations_list:
        match = pattern.match(item)
        if match:
            num = int(match.group(1))
            text = match.group(2).strip()
            translations_dict[num] = text
        else:
             logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–≤–æ–¥–∞: '{item}'")
             # Optionally inform the user about the problematic line
             # await context.bot.send_message(chat_id, f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º —Å—Ç—Ä–æ–∫–∏: '{item}'", message_thread_id=message_thread_id)

    if not translations_dict:
         await context.bot.send_message(
            chat_id=chat_id,
            text="‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.",
            message_thread_id=message_thread_id
        )
         return


    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(translations_dict)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {translations_dict.keys()}")


    conn = get_db_connection()
    cursor = conn.cursor()

    # Get allowed sentence numbers for this user today
    cursor.execute("""
        SELECT unique_id, id, sentence, session_id FROM daily_sentences_deepseek
        WHERE date = CURRENT_DATE AND user_id = %s;
    """, (user_id,))

    allowed_sentences_data = {row[0]: {'id': row[1], 'sentence': row[2], 'session_id': row[3]} for row in cursor.fetchall()}

    # Check if translations for these sentences already exist today
    cursor.execute("""
        SELECT sentence_id FROM translations_deepseek
        WHERE user_id = %s AND timestamp::date = CURRENT_DATE;
    """, (user_id,))
    existing_translation_sentence_ids = {row[0] for row in cursor.fetchall()}


    results_summary = [] # For a final summary message
    processed_count = 0

    # Process each translation provided by the user
    for sentence_number, user_translation_text in translations_dict.items():
        # 1. Check if the sentence number is valid for this user today
        if sentence_number not in allowed_sentences_data:
            results_summary.append(f"‚ùå –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number}: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –≤–∞–º –Ω–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç.")
            continue # Skip this translation

        sentence_info = allowed_sentences_data[sentence_number]
        sentence_id = sentence_info['id']
        original_text = sentence_info['sentence']
        session_id = sentence_info['session_id']


        # 2. Check if this sentence has already been translated by the user today
        if sentence_id in existing_translation_sentence_ids:
            results_summary.append(f"‚ö†Ô∏è –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number}: –£–∂–µ –±—ã–ª–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ —Å–µ–≥–æ–¥–Ω—è. –£—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥.")
            continue # Skip this translation

        logging.info(f"üìå –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–≤–æ–¥ ‚Ññ{sentence_number} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: '{user_translation_text}'")

        # 3. Check translation using GPT
        # Passing the correct update, context, and sentence_number
        feedback_text, categories, subcategories, score_val, severity_val, correct_translation_val = await check_translation(
            original_text, user_translation_text, update, context, sentence_number
        )

        # Default values in case check_translation failed
        score_val = int(score_val) if score_val is not None else 0
        severity_val = int(severity_val) if severity_val is not None else None # Keep None if parsing failed

        if feedback_text:
             results_summary.append(f"üìú **–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ {sentence_number}**: –û—Ü–µ–Ω–µ–Ω–æ.") # Simple summary line

        # 4. Save translation result to translations_deepseek table
        try:
            cursor.execute("""
                INSERT INTO translations_deepseek (user_id, session_id, username, sentence_id, user_translation, score, feedback)
                VALUES (%s, %s, %s, %s, %s, %s, %s);
            """, (user_id, session_id, username, sentence_id, user_translation_text, score_val, feedback_text))
            conn.commit()
            processed_count += 1
            logging.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ {sentence_number} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ translations_deepseek.")

            # 5. Log detailed mistakes if score is not perfect (and categories were identified)
            if score_val < 100:
                # log_translation_mistake handles score > 75 logic internally
                await log_translation_mistake(user_id, original_text, user_translation_text, categories, subcategories, score_val, severity_val, correct_translation_val)

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ {sentence_number} –∏–ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—à–∏–±–æ–∫: {e}", exc_info=True)
            if conn:
                conn.rollback() # Rollback changes for this transaction


    cursor.close()
    conn.close()

    # Send a final message summarizing the process
    summary_message = f"‚úÖ **–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**\n\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n\n"
    if results_summary:
         summary_message += "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n" + "\n".join(results_summary)
    else:
         summary_message += "–í—Å–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –ª–∏–±–æ —É–∂–µ –±—ã–ª–∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã, –ª–∏–±–æ –∏–º–µ–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –Ω–æ–º–µ—Ä–∞."


    await context.bot.send_message(
        chat_id=chat_id,
        text=summary_message,
        message_thread_id=message_thread_id
    )


async def get_original_sentences(user_id, context: CallbackContext):
    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        # 1. Get sentences user made mistakes on frequently or recently (e.g., last week)
        # Prioritize recent mistakes, then most frequent mistakes
        cursor.execute("""
            SELECT sentence FROM detailed_mistakes_deepseek
            WHERE user_id = %s AND last_seen >= NOW() - INTERVAL '7 days' -- Mistakes in the last week
            ORDER BY mistake_count DESC, last_seen DESC
            LIMIT 3; -- Get up to 3 sentences from recent mistakes
        """, (user_id, ))
        recent_mistake_sentences = [row[0] for row in cursor.fetchall()]
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –Ω–µ–¥–∞–≤–Ω–∏—Ö –æ—à–∏–±–æ–∫ ({len(recent_mistake_sentences)}): {recent_mistake_sentences}")

        # 2. Get general sentences from the 'sentences_deepseek' pool
        num_general_sentences_needed = 7 - len(recent_mistake_sentences)
        general_sentences = []
        if num_general_sentences_needed > 0:
            cursor.execute("""
                SELECT sentence FROM sentences_deepseek ORDER BY RANDOM() LIMIT %s;""", (num_general_sentences_needed,))
            general_sentences = [row[0] for row in cursor.fetchall()]
            print(f"üìå –ù–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑–µ –æ–±—â–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π ({len(general_sentences)}): {general_sentences}")


        # 3. If still need more, generate via GPT
        num_gpt_sentences_needed = 7 - len(recent_mistake_sentences) - len(general_sentences)
        gpt_sentences = []
        if num_gpt_sentences_needed > 0:
            print(f"‚ö†Ô∏è –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ—â—ë {num_gpt_sentences_needed} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ GPT...")
            gpt_sentences = await generate_sentences(user_id, num_gpt_sentences_needed, context)
            print(f"üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ GPT –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è ({len(gpt_sentences)}): {gpt_sentences}")


        # Combine and shuffle the list
        final_sentences = recent_mistake_sentences + general_sentences + gpt_sentences
        # Shuffle to mix mistake sentences and new ones
        import random
        random.shuffle(final_sentences)

        # Ensure we don't exceed 7 sentences (just in case, though logic should prevent it)
        final_sentences = final_sentences[:7]

        print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} ({len(final_sentences)}): {final_sentences}")

        if not final_sentences:
            print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!")
            # Fallback to hardcoded if everything fails
            return ["–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.", "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–æ–±—â–∏—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –æ –ø—Ä–æ–±–ª–µ–º–µ."]

        return final_sentences

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_original_sentences: {e}", exc_info=True)
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_original_sentences: {e}")
        # Fallback to hardcoded if any error occurs during DB/API
        return ["–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.", "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–æ–±—â–∏—Ç–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –æ –ø—Ä–æ–±–ª–µ–º–µ."]

    finally: # Close cursor and connection
        cursor.close()
        conn.close()

# –£–∫–∞–∑—ã–≤–∞–µ–º ID –Ω—É–∂–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
PREFERRED_CHANNELS = [
    "UCthmoIZKvuR1-KuwednkjHg",  # Deutsch mit Yehor
    "UCHLkEhIoBRu2JTqYJlqlgbw",  # Deutsch mit Rieke
    "UCeVQK7ZPXDOAyjY0NYqmX-Q"   # Benjamin - Der Deutschlehrer
]

def search_youtube_videous(topic, max_results=5):
    query=topic
    if not YOUTUBE_API_KEY:
        print("‚ùå –û—à–∏–±–∫–∞: YOUTUBE_API_KEY –Ω–µ –∑–∞–¥–∞–Ω!")
        return ["‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: YouTube API –∫–ª—é—á –Ω–µ –∑–∞–¥–∞–Ω."]
    try:
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)

        # –ü–æ–∏—Å–∫ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–º –∫–∞–Ω–∞–ª–∞–º
        video_data = []
        for channal_id in PREFERRED_CHANNELS:

            request = youtube.search().list(
                part="snippet",
                q=query,
                type="video",
                maxResults=max_results,
                channelId=channal_id,
                relevanceLanguage="de", # Prioritize German
                regionCode="DE" # Prioritize Germany
            )
            response = request.execute()

            for item in response.get("items", []):
                title = item["snippet"]["title"]
                # title = title.replace('{', '{{').replace('}', '}}') # Escape for f-string (not needed for MarkdownV2)
                # title = title.replace('%', '%%') # Escape % (not needed for MarkdownV2)
                video_id = item["id"].get("videoId", "") # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ videoId
                if video_id:
                    # Store video_id and title
                    video_data.append({'title': title, 'video_id': video_id})

        # If not enough videos found on preferred channels, search more broadly
        if len(video_data) < max_results:
            print(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∏–¥–µ–æ ({len(video_data)}) –Ω–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–∞—Ö. –ò—â–µ–º –µ—â—ë {max_results - len(video_data)} –ø–æ –≤—Å–µ–º –∫–∞–Ω–∞–ª–∞–º.")
            request = youtube.search().list(
                part="snippet",
                q=query,
                type="video",
                maxResults=max_results - len(video_data), # Get fewer from general search
                relevanceLanguage="de",
                regionCode="DE"
            )
            response = request.execute()

            for item in response.get("items", []):
                title = item["snippet"]["title"]
                # title = title.replace('{', '{{').replace('}', '}}') # Escape for f-string (not needed for MarkdownV2)
                # title = title.replace('%', '%%') # Escape % (not needed for MarkdownV2)
                video_id = item["id"].get("videoId", "") # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ videoId
                 # Avoid adding duplicates if a video appeared in both searches
                if video_id and video_id not in [v['video_id'] for v in video_data]:
                    video_data.append({'title': title, 'video_id': video_id})


        if not video_data:
            return ["‚ùå –í–∏–¥–µ–æ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É."]

        # ‚úÖ –¢–µ–ø–µ—Ä—å –ø–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ
        video_ids = ",".join([video['video_id'] for video in video_data if video['video_id']])
        if video_ids:
            try:
                stats_request = youtube.videos().list(
                    part = "statistics",
                    id=video_ids
                )
                stats_response = stats_request.execute()

                for item in stats_response.get("items", []):
                    video_id = item["id"]
                    view_count = int(item["statistics"].get("viewCount", 0))
                    for video in video_data:
                        if video['video_id'] == video_id:
                            video["views"] = view_count
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É YouTube: {e}")
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É YouTube: {e}")
                # Continue without view counts if API fails

        # ‚úÖ –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞—Ö –Ω–µ—Ç)
        for video in video_data:
            video.setdefault("views", 0)

        # ‚úÖ –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–ø–æ —É–±—ã–≤–∞–Ω–∏—é)
        sorted_videos = sorted(video_data, key=lambda x: x["views"], reverse=True)

        # ‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ 2 —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –≤–∏–¥–µ–æ
        top_videos = sorted_videos[:2]

        # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏ –≤ Telegram-—Ñ–æ—Ä–º–∞—Ç–µ MarkdownV2
        preferred_videos_markdown = [
            f"[‚ñ∂Ô∏è {escape_markdown_v2(video['title'])}]({escape_markdown_v2('https://www.youtube.com/watch?v=' + video['video_id'])})"
            for video in top_videos if video.get('video_id')
        ]

        return preferred_videos_markdown # Return list of MarkdownV2 links

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤–∏–¥–µ–æ –≤ YouTube: {e}", exc_info=True)
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤–∏–¥–µ–æ –≤ YouTube: {e}")
        return ["‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤–∏–¥–µ–æ –≤ YouTube."]


#üìå this function will filter and rate mistakes
async def rate_mistakes(user_id):
    # ‚úÖ Ensure user_id is an integer
    if not isinstance(user_id, int):
         logging.error(f"‚ùå –û—à–∏–±–∫–∞: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π user_id ({user_id}, —Ç–∏–ø {type(user_id)}) –≤ rate_mistakes.")
         return 0, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'


    with get_db_connection() as conn:
        with conn.cursor() as cursor:

            # ‚úÖ 1. Calculate amount of translated sentences of the user in a week
            cursor.execute("""
                SELECT COUNT(DISTINCT sentence_id) -- Use DISTINCT sentence_id to count unique sentences translated
                FROM translations_deepseek
                WHERE user_id = %s AND timestamp >= NOW() - INTERVAL '7 days'; -- Last 7 full days
            """, (user_id,))
            total_sentences_translated = cursor.fetchone()[0] or 0

            # ‚úÖ 2. Calculate total sentences assigned in the last week
            cursor.execute("""
                 SELECT COUNT(DISTINCT id)
                 FROM daily_sentences_deepseek
                 WHERE user_id = %s AND date >= CURRENT_DATE - INTERVAL '7 days';
            """, (user_id,))
            total_sentences_assigned = cursor.fetchone()[0] or 0


            # ‚úÖ 3. Calculate all mistakes KPI within a week (last 7 days)
            cursor.execute("""
                WITH user_mistakes AS (
                    SELECT main_category, sub_category, COUNT(*) AS mistake_count
                    FROM detailed_mistakes_deepseek
                    WHERE user_id = %s
                    AND last_seen >= NOW() - INTERVAL '7 days'
                    GROUP BY main_category, sub_category
                ),
                ranked_categories AS (
                    SELECT
                        main_category,
                        SUM(mistake_count) AS total_main_category_mistakes,
                        ROW_NUMBER() OVER (ORDER BY SUM(mistake_count) DESC) as rank
                    FROM user_mistakes
                    GROUP BY main_category
                    ORDER BY total_main_category_mistakes DESC
                ),
                top_main_category AS (
                     SELECT main_category FROM ranked_categories WHERE rank = 1
                ),
                top_subcategories AS (
                    SELECT
                        sub_category,
                        mistake_count,
                        ROW_NUMBER() OVER (ORDER BY mistake_count DESC) as sub_rank
                    FROM user_mistakes
                    WHERE main_category = (SELECT main_category FROM top_main_category) -- Filter by the top main category
                    ORDER BY mistake_count DESC
                    LIMIT 2
                )
                -- ‚úÖ FINAL QUERY TO SELECT ALL PIECES
                SELECT
                    (SELECT SUM(mistake_count) FROM user_mistakes) AS total_mistakes_week, -- Total mistakes in the week
                    (SELECT main_category FROM top_main_category) AS top_mistake_category,
                    (SELECT total_main_category_mistakes FROM ranked_categories WHERE rank = 1) AS number_of_top_category_mistakes, -- Correct count for the top category
                    (SELECT sub_category FROM top_subcategories WHERE sub_rank = 1) AS top_subcategory_1,
                    (SELECT sub_category FROM top_subcategories WHERE sub_rank = 2) AS top_subcategory_2
                ;
            """, (user_id,))

            result = cursor.fetchone()
            if result is not None:
                # Unpack with default values in case query parts return NULL
                mistakes_week = result[0] if result[0] is not None else 0
                top_mistake_category = result[1] if result[1] is not None else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
                number_of_top_category_mistakes = result[2] if result[2] is not None else 0
                top_mistake_subcategory_1 = result[3] if result[3] is not None else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
                top_mistake_subcategory_2 = result[4] if result[4] is not None else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            else:
                # If no mistake data for the week
                mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2 = 0, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', 0, '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'


    # Calculate missed sentences
    missed_week = GREATEST(0, total_sentences_assigned - total_sentences_translated)


    return total_sentences_translated, mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2, missed_week


# Using Telegram's built-in helper for MarkdownV2 escaping
# from telegram.helpers import escape_markdown_v2

# This function already imported at the top


# üìåüìåüìåüìåüìå
async def send_me_analytics_and_recommend_me(context: CallbackContext):
    client = openai.AsyncOpenAI(api_key=openai.api_key)

    # ‚úÖ Determine the thread_id for recommendations
    recommendations_thread_id = TOPICS_TELEGRAM["Empfehlungen"].get("id")
    if recommendations_thread_id is None:
         logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ thread_id –¥–ª—è —Ç–µ–º—ã Empfehlungen!")
         # Fallback? Or just skip sending recommendations? Let's skip for now.
         return


    #get all user_id's from _DB who had mistakes in the last week
    with get_db_connection() as conn:
        with conn.cursor() as cursor:
            cursor.execute("""
            SELECT DISTINCT user_id FROM detailed_mistakes_deepseek
            WHERE last_seen >= NOW() - INTERVAL '7 days';
            """)
            user_ids_with_mistakes = [row[0] for row in cursor.fetchall()]

             # Also get users who translated but had no mistakes (to include them in count)
            cursor.execute("""
            SELECT DISTINCT user_id FROM translations_deepseek
            WHERE timestamp >= NOW() - INTERVAL '7 days'
            AND user_id NOT IN (SELECT user_id FROM detailed_mistakes_deepseek WHERE last_seen >= NOW() - INTERVAL '7 days');
            """)
            user_ids_translated_no_mistakes = [row[0] for row in cursor.fetchall()]

    # Combine all relevant user IDs and get unique ones
    all_user_ids_this_week = list(set(user_ids_with_mistakes + user_ids_translated_no_mistakes))


    if not all_user_ids_this_week:
        print("‚ùå –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é (–ø–µ—Ä–µ–≤–æ–¥—ã/–æ—à–∏–±–∫–∏) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é.")
        await context.bot.send_message(
             chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
             text="üìà –ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–µ—Ä–µ–≤–æ–¥–∞–º –∏–ª–∏ –æ—à–∏–±–∫–∞–º.",
             message_thread_id=recommendations_thread_id
             )
        return

    for user_id in all_user_ids_this_week:
        # Get statistics for the user
        total_sentences_translated, mistakes_week, top_mistake_category, number_of_top_category_mistakes, top_mistake_subcategory_1, top_mistake_subcategory_2, missed_week = await rate_mistakes(user_id)

        # Get username
        with get_db_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute("""
                    SELECT DISTINCT username FROM translations_deepseek WHERE user_id = %s LIMIT 1;""",
                    (user_id, ))
                result = cursor.fetchone()
                username = result[0] if result else f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}" # Fallback username


        # ‚úÖ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–µ–º—É –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —É OpenAI —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±—ã–ª–∏ –æ—à–∏–±–∫–∏
        topic = None
        if mistakes_week > 0 and (top_mistake_category != '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ' or top_mistake_subcategory_1 != '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'):
             prompt = f"""
            –¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–∑—É—á–µ–Ω–∏—é –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–µ–º–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞.
            –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ø—É—Å—Ç–∏–ª —Å–ª–µ–¥—É—é—â–∏–µ –æ—à–∏–±–∫–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é:

            - **–ö–∞—Ç–µ–≥–æ—Ä–∏—è –æ—à–∏–±–∫–∏:** {top_mistake_category}
            - **–ü–µ—Ä–≤–∞—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è:** {top_mistake_subcategory_1}
            - **–í—Ç–æ—Ä–∞—è –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è:** {top_mistake_subcategory_2}

            –û–ø—Ä–µ–¥–µ–ª–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–µ–º—É –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –¥–ª—è –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ –∏ –∏–∑—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Plusquamperfekt", "Konjunktiv II", "Dativ Pr√§positionen").
            **–í—ã–≤–æ–¥–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫—É—é —Ñ—Ä–∞–∑—É –Ω–∞ –ù–ï–ú–ï–¶–ö–û–ú —è–∑—ã–∫–µ, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ç–µ–º–µ.**
            –ï—Å–ª–∏ –æ—à–∏–±–∫–∏ –Ω–µ —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ç–µ–º—É –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏, –ø—Ä–µ–¥–ª–æ–∂–∏ –æ–±—â—É—é —Ç–µ–º—É, –Ω–∞–ø—Ä–∏–º–µ—Ä "Deutsche Grammatik B2" –∏–ª–∏ "Wortschatz lernen".
            """

             for attempt in range(3): # Try up to 3 times for topic generation
                try:
                    response = await client.chat.completions.create(
                    model="gpt-4-turbo", # or gpt-3.5-turbo
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=50 # Limit response length
                    )
                    topic = response.choices[0].message.content.strip()
                    print(f"üìå –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —Ç–µ–º–∞ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {topic}")
                    break # Exit loop on success
                except openai.RateLimitError:
                    wait_time = (attempt + 1) * 5
                    logging.warning(f"‚ö†Ô∏è OpenAI API –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Ç–µ–º—ã. –ñ–¥—ë–º {wait_time} —Å–µ–∫...")
                    await asyncio.sleep(wait_time)
                except Exception as e:
                    logging.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–º—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}", exc_info=True)
                    wait_time = (attempt + 1) * 3
                    await asyncio.sleep(wait_time) # Wait on other errors

        # ‚úÖ –ò—â–µ–º –≤–∏–¥–µ–æ –Ω–∞ YouTube —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–º–∞ –±—ã–ª–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞
        valid_links = ["_–í–∏–¥–µ–æ-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:_"] # Start with a header
        if topic:
             video_data = search_youtube_videous(topic) # This function returns MarkdownV2 links or error strings
             valid_links.extend(video_data) # Add the search results

        if len(valid_links) == 1: # Only the header is present means no videos were found
             valid_links.append("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –≤–∏–¥–µ–æ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ.")


        # ‚úÖ –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        recommendations = (
            f"üìà *–ù–µ–¥–µ–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –¥–ª—è {escape_markdown_v2(username)}*\n\n" # Escape username for MarkdownV2
            f"üìú *–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∑–∞–¥–∞–Ω–æ –∑–∞ –Ω–µ–¥–µ–ª—é:* {total_sentences_assigned}\n"
            f"‚úÖ *–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ:* {total_sentences_translated}\n"
            f"üö® *–ù–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ:* {missed_week}\n"
            f"üî¥ *–í—Å–µ–≥–æ –æ—à–∏–±–æ–∫ –∑–∞ –Ω–µ–¥–µ–ª—é:* {mistakes_week}\n"
        )

        if mistakes_week > 0:
             recommendations += (
                f"üìä *–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:*\n"
                f"ü•á *–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º —á–∏—Å–ª–æ–º –æ—à–∏–±–æ–∫* ({number_of_top_category_mistakes}): {escape_markdown_v2(top_mistake_category)}\n"
             )
             if top_mistake_subcategory_1 != '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ':
                recommendations += f"ü•à *–ß–∞—Å—Ç—ã–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏:* {escape_markdown_v2(top_mistake_subcategory_1)}\n"
             if top_mistake_subcategory_2 != '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ':
                 recommendations += f"ü•â *–í—Ç–æ—Ä—ã–µ –ø–æ —á–∞—Å—Ç–æ—Ç–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏:* {escape_markdown_v2(top_mistake_subcategory_2)}\n"
        else:
             recommendations += f"‚ú® *–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é –Ω–µ—Ç –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫.*\n"


        if topic:
             recommendations += (f"\nüßê *–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Ç–µ–º–∞ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—à–∏–±–æ–∫:*\n `{escape_markdown_v2(topic)}`\n\n") # Escape topic for MarkdownV2 and use code block
             recommendations += "\n".join(valid_links) # Add video links (already in MarkdownV2)
        else:
             recommendations += "\n\n" + "\n".join(valid_links) # Add video links (already in MarkdownV2, even if it's just the error message)


        #Debugging...
        print("DEBUG Recommendations message:\n", recommendations)


        # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –≤ —Ç–æ–ø–∏–∫ "Empfehlungen"
        try:
            await context.bot.send_message(
                chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
                text=recommendations,
                parse_mode = "MarkdownV2", # Use MarkdownV2
                message_thread_id=recommendations_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ Empfehlungen
                )
        except TelegramError as e:
             logging.error(f"‚ùå Telegram Error –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e}", exc_info=True)
             print(f"‚ùå Telegram Error –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e}")
             # Fallback: send to general chat or handle error

        except Exception as e:
             logging.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e}", exc_info=True)
             print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}: {e}")



# SQL –ó–∞–ø—Ä–æ—Å –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ
async def send_weekly_summary(context: CallbackContext):

    # ‚úÖ –û–ø—Ä–µ–¥–µ–ª—è–µ–º thread_id –¥–ª—è –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    weekly_stats_thread_id = TOPICS_TELEGRAM["W√∂chenliche Statistik"].get("id")
    if weekly_stats_thread_id is None:
         logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ thread_id –¥–ª—è —Ç–µ–º—ã W√∂chenliche Statistik!")
         return

    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é (last 7 days)
    # Include users who had sentences assigned but didn't translate
    cursor.execute("""
        WITH AllUsersWithSentences AS (
             SELECT DISTINCT user_id
             FROM daily_sentences_deepseek
             WHERE date >= CURRENT_DATE - INTERVAL '7 days' -- Sentences assigned in the last 7 days
        ),
        UserTranslationStats AS (
            SELECT
                t.user_id,
                t.username,
                COUNT(DISTINCT t.sentence_id) AS translated_count,
                COALESCE(AVG(t.score), 0) AS avg_score
            FROM translations_deepseek t
            WHERE t.timestamp >= CURRENT_DATE - INTERVAL '7 days' -- Translations in the last 7 days
            GROUP BY t.user_id, t.username
        ),
        UserProgressStats AS (
            SELECT
                user_id,
                AVG(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS avg_time,
                SUM(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS total_time
            FROM user_progress_deepseek
            WHERE completed = TRUE -- Only completed sessions
            AND start_time >= CURRENT_DATE - INTERVAL '7 days' -- Sessions started in the last 7 days
            GROUP BY user_id
        ),
        UserAssignedSentences AS (
            SELECT
                user_id,
                COUNT(DISTINCT id) AS assigned_count
            FROM daily_sentences_deepseek
            WHERE date >= CURRENT_DATE - INTERVAL '7 days' -- Sentences assigned in the last 7 days
            GROUP BY user_id
        )
        -- Final Select joining all CTEs
        SELECT
            au.user_id,
            COALESCE(uts.username, (SELECT username FROM messages_deepseek WHERE user_id = au.user_id LIMIT 1), '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å'), -- Get username from translations or messages
            COALESCE(uas.assigned_count, 0) AS –≤—Å–µ–≥–æ_–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π,
            COALESCE(uts.translated_count, 0) AS –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ,
            GREATEST(0, COALESCE(uas.assigned_count, 0) - COALESCE(uts.translated_count, 0)) AS –ø—Ä–æ–ø—É—â–µ–Ω–æ_–∑–∞_–Ω–µ–¥–µ–ª—é,
            COALESCE(uts.avg_score, 0) AS —Å—Ä–µ–¥–Ω—è—è_–æ—Ü–µ–Ω–∫–∞,
            COALESCE(ups.avg_time, 0) AS —Å—Ä–µ–¥–Ω–µ–µ_–≤—Ä–µ–º—è_—Å–µ—Å—Å–∏–∏_–≤_–º–∏–Ω—É—Ç–∞—Ö,
            COALESCE(ups.total_time, 0) AS –æ–±—â–µ–µ_–≤—Ä–µ–º—è_–≤_–º–∏–Ω—É—Ç–∞—Ö,
            -- Calculate final score: avg_score - (avg_time * 2) - (missed * 20)
            COALESCE(uts.avg_score, 0)
            - (COALESCE(ups.avg_time, 0) * 2)
            - (GREATEST(0, COALESCE(uas.assigned_count, 0) - COALESCE(uts.translated_count, 0)) * 20) AS –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª
        FROM AllUsersWithSentences au
        LEFT JOIN UserTranslationStats uts ON au.user_id = uts.user_id
        LEFT JOIN UserProgressStats ups ON au.user_id = ups.user_id
        LEFT JOIN UserAssignedSentences uas ON au.user_id = uas.user_id
        ORDER BY –∏—Ç–æ–≥–æ–≤—ã–π_–±–∞–ª–ª DESC;
    """)
    rows = cursor.fetchall()

    cursor.close()
    conn.close()

    if not rows:
        await context.bot.send_message(
             chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
             text="üìä –ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é –Ω–∏–∫—Ç–æ –Ω–µ –ø–µ—Ä–µ–≤–µ–ª –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è!",
             message_thread_id=weekly_stats_thread_id # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ W√∂chenliche Statistik
             )
        return

    summary = "üèÜ –ò—Ç–æ–≥–∏ –Ω–µ–¥–µ–ª–∏:\n\n"

    medals = ["ü•á", "ü•à", "ü•â"]
    for i, (user_id, username, total_assigned, translated, missed, avg_score, avg_minutes, total_minutes, final_score) in enumerate(rows):
        medal = medals[i] if i < len(medals) else "üí©"
        # Escape username for Markdown
        safe_username = escape_markdown(username)
        summary += (
            f"{medal} {safe_username}\n"
            f"üìú –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∑–∞–¥–∞–Ω–æ: {total_assigned}\n"
            f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}\n"
            f"üö® –ü—Ä–æ–ø—É—â–µ–Ω–æ: {missed}\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}/100\n"
            f"‚è± –í—Ä–µ–º—è —Å—Ä–µ–¥–Ω–µ–µ: {avg_minutes:.1f} –º–∏–Ω\n"
            f"‚è± –í—Ä–µ–º—è –æ–±—â–µ–µ: {total_minutes:.1f} –º–∏–Ω\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {final_score:.1f}\n\n"
        )

    await context.bot.send_message(
         chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
         text=summary,
         message_thread_id=weekly_stats_thread_id, # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ W√∂chenliche Statistik
         parse_mode = "Markdown" # Use Markdown
         )


async def user_stats(update: Update, context: CallbackContext):
    """Sends daily and weekly statistics for the user."""
    if update.message:
        user = update.message.from_user
        chat_id = update.message.chat_id
        message_thread_id = update.message.message_thread_id
    elif update.callback_query:
        user = update.callback_query.from_user
        chat_id = update.callback_query.message.chat_id
        message_thread_id = update.callback_query.message.message_thread_id
    else:
        logging.error("‚ùå –ù–µ—Ç –Ω–∏ message, –Ω–∏ callback_query –≤ update!")
        return

    user_id = user.id
    username = user.first_name

    conn = get_db_connection()
    cursor = conn.cursor()

    # üìå –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å
    cursor.execute("""
        WITH UserDailySentences AS (
            SELECT COUNT(DISTINCT id) AS total_assigned
            FROM daily_sentences_deepseek
            WHERE user_id = %s AND date = CURRENT_DATE
        ),
        UserDailyTranslations AS (
             SELECT
                 COUNT(DISTINCT sentence_id) AS translated_count,
                 COALESCE(AVG(score), 0) AS avg_score
             FROM translations_deepseek
             WHERE user_id = %s AND timestamp::date = CURRENT_DATE
        ),
        UserDailyProgress AS (
             SELECT
                 COALESCE(AVG(EXTRACT(EPOCH FROM (end_time - start_time)) / 60), 0) AS avg_time,
                 COALESCE(SUM(EXTRACT(EPOCH FROM (end_time - start_time)) / 60), 0) AS total_time
             FROM user_progress_deepseek
             WHERE user_id = %s AND start_time::date = CURRENT_DATE AND completed = TRUE
        )
        SELECT
             COALESCE(uds.total_assigned, 0) AS total_assigned_today,
             COALESCE(udt.translated_count, 0) AS translated_today,
             GREATEST(0, COALESCE(uds.total_assigned, 0) - COALESCE(udt.translated_count, 0)) AS missed_today,
             COALESCE(udt.avg_score, 0) AS avg_score_today,
             COALESCE(udp.avg_time, 0) AS avg_time_today_minutes,
             COALESCE(udp.total_time, 0) AS total_time_today_minutes,
             -- Calculate daily final score: avg_score - (avg_time * 2) - (missed * 20)
             COALESCE(udt.avg_score, 0)
             - (COALESCE(udp.avg_time, 0) * 2)
             - (GREATEST(0, COALESCE(uds.total_assigned, 0) - COALESCE(udt.translated_count, 0)) * 20) AS final_score_today
        FROM UserDailySentences uds, UserDailyTranslations udt, UserDailyProgress udp;
    """, (user_id, user_id, user_id))

    today_stats = cursor.fetchone()


    # üìå –ù–µ–¥–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (last 7 days) - Reusing the logic from send_weekly_summary but filtered by user
    cursor.execute("""
        WITH UserWeeklySentences AS (
             SELECT COUNT(DISTINCT id) AS total_assigned
             FROM daily_sentences_deepseek
             WHERE user_id = %s AND date >= CURRENT_DATE - INTERVAL '7 days'
        ),
        UserWeeklyTranslations AS (
             SELECT
                 COUNT(DISTINCT sentence_id) AS translated_count,
                 COALESCE(AVG(score), 0) AS avg_score
             FROM translations_deepseek
             WHERE user_id = %s AND timestamp >= CURRENT_DATE - INTERVAL '7 days'
             GROUP BY user_id -- Group by user_id (redundant here as we filter by user_id)
        ),
        UserWeeklyProgress AS (
             SELECT
                 COALESCE(AVG(EXTRACT(EPOCH FROM (end_time - start_time)) / 60), 0) AS avg_time,
                 COALESCE(SUM(EXTRACT(EPOCH FROM (end_time - start_time)) / 60), 0) AS total_time
             FROM user_progress_deepseek
             WHERE user_id = %s AND completed = TRUE
             AND start_time >= CURRENT_DATE - INTERVAL '7 days'
             GROUP BY user_id -- Group by user_id
        )
        SELECT
             COALESCE(uws.total_assigned, 0) AS total_assigned_week,
             COALESCE(uwt.translated_count, 0) AS translated_week,
             GREATEST(0, COALESCE(uws.total_assigned, 0) - COALESCE(uwt.translated_count, 0)) AS missed_week,
             COALESCE(uwt.avg_score, 0) AS avg_score_week,
             COALESCE(uwp.avg_time, 0) AS avg_time_week_minutes,
             COALESCE(uwp.total_time, 0) AS total_time_week_minutes,
             -- Calculate weekly final score: avg_score - (avg_time * 2) - (missed * 20)
             COALESCE(uwt.avg_score, 0)
             - (COALESCE(uwp.avg_time, 0) * 2)
             - (GREATEST(0, COALESCE(uws.total_assigned, 0) - COALESCE(uwt.translated_count, 0)) * 20) AS final_score_week
        FROM UserWeeklySentences uws, UserWeeklyTranslations uwt, UserWeeklyProgress uwp;
    """, (user_id, user_id, user_id))

    weekly_stats = cursor.fetchone()

    cursor.close()
    conn.close()

    # üìå –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    stats_text = f"üìä –í–∞—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞, {username}:\n\n"

    if today_stats:
        stats_text += (
            f"üìÖ **–°–µ–≥–æ–¥–Ω—è**\n"
            f"üìú –ó–∞–¥–∞–Ω–æ: {today_stats[0]}\n"
            f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {today_stats[1]}\n"
            f"üö® –ü—Ä–æ–ø—É—â–µ–Ω–æ: {today_stats[2]}\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {today_stats[3]:.1f}/100\n"
            f"‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏: {today_stats[4]:.1f} –º–∏–Ω\n"
            f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è: {today_stats[5]:.1f} –º–∏–Ω\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {today_stats[6]:.1f}\n"
        )
    else:
        stats_text += f"üìÖ **–°–µ–≥–æ–¥–Ω—è**\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–≤—ã –µ—â—ë –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏ –∏–ª–∏ –Ω–µ –∑–∞–≤–µ—Ä—à–∞–ª–∏ —Å–µ—Å—Å–∏–∏)."

    stats_text += "\n" # Add a newline between daily and weekly

    if weekly_stats:
         # Check if there was any activity assigned/translated/progress in the week
         if weekly_stats[0] > 0 or weekly_stats[1] > 0 or weekly_stats[5] > 0:
            stats_text += (
                f"üìÜ **–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π**\n"
                f"üìú –ó–∞–¥–∞–Ω–æ: {weekly_stats[0]}\n"
                f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {weekly_stats[1]}\n"
                f"üö® –ü—Ä–æ–ø—É—â–µ–Ω–æ: {weekly_stats[2]}\n"
                f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {weekly_stats[3]:.1f}/100\n"
                f"‚è± –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏: {weekly_stats[4]:.1f} –º–∏–Ω\n"
                f"‚è± –û–±—â–µ–µ –≤—Ä–µ–º—è: {weekly_stats[5]:.1f} –º–∏–Ω\n"
                f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {weekly_stats[6]:.1f}\n"
            )
         else:
             stats_text += f"üìÜ **–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π**\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)."

    else:
        stats_text += "\nüìÜ **–ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π**\n‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö (–Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏)."

    await context.bot.send_message(
        chat_id=chat_id,
        text=stats_text,
        message_thread_id=message_thread_id,
        parse_mode = "Markdown" # Use Markdown
        )


async def send_daily_summary(context: CallbackContext):
    # ‚úÖ –û–ø—Ä–µ–¥–µ–ª—è–µ–º thread_id –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    daily_stats_thread_id = TOPICS_TELEGRAM["T√§gliche Statistik"].get("id")
    if daily_stats_thread_id is None:
         logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ thread_id –¥–ª—è —Ç–µ–º—ã T√§gliche Statistik!")
         return


    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç **–∑–∞ —Å–µ–≥–æ–¥–Ω—è** (to include lazy ones today)
    cursor.execute("""
        SELECT DISTINCT user_id, username
        FROM messages_deepseek
        WHERE timestamp::date = CURRENT_DATE;
    """)
    all_users_today_interacted = {int(row[0]): row[1] for row in cursor.fetchall()}


    # üîπ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º **–∑–∞ —Å–µ–≥–æ–¥–Ω—è**
    cursor.execute("""
       WITH UserDailySentences AS (
            SELECT user_id, COUNT(DISTINCT id) AS total_assigned
            FROM daily_sentences_deepseek
            WHERE date = CURRENT_DATE
            GROUP BY user_id
       ),
       UserDailyTranslations AS (
            SELECT
                t.user_id,
                COUNT(DISTINCT t.id) AS translated_count,
                COALESCE(AVG(t.score), 0) AS avg_score
            FROM translations_deepseek t
            WHERE t.timestamp::date = CURRENT_DATE
            GROUP BY t.user_id
       ),
       UserDailyProgress AS (
            SELECT user_id,
                AVG(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS avg_time,
                SUM(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS total_time
            FROM user_progress_deepseek
            WHERE completed = true AND start_time::date = CURRENT_DATE
            GROUP BY user_id
       )
       SELECT
            uds.user_id,
            COALESCE(uds.total_assigned, 0) AS total_sentences,
            COALESCE(udt.translated_count, 0) AS translated,
            GREATEST(0, COALESCE(uds.total_assigned, 0) - COALESCE(udt.translated_count, 0)) AS missed,
            COALESCE(udp.avg_time, 0) AS avg_time_minutes,
            COALESCE(udp.total_time, 0) AS total_time_minutes,
            COALESCE(udt.avg_score, 0) AS avg_score,
            COALESCE(udt.avg_score, 0)
            - (COALESCE(udp.avg_time, 0) * 2)
            - (GREATEST(0, COALESCE(uds.total_assigned, 0) - COALESCE(udt.translated_count, 0)) * 20) AS final_score
       FROM UserDailySentences uds
       LEFT JOIN UserDailyTranslations udt ON uds.user_id = udt.user_id
       LEFT JOIN UserDailyProgress udp ON uds.user_id = udp.user_id
       ORDER BY final_score DESC;
    """)
    rows = cursor.fetchall()

    cursor.close()
    conn.close()

    # üîπ Identify users who had sentences assigned but didn't translate (lazy ones)
    assigned_users_ids = {row[0] for row in rows} # Users who were assigned sentences today
    lazy_users_today = {uid: uname for uid, uname in all_users_today_interacted.items() if uid not in assigned_users_ids}


    # üîπ Formulate the report
    if not rows and not lazy_users_today:
        await context.bot.send_message(
             chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
             text="üìä –°–µ–≥–æ–¥–Ω—è –Ω–∏–∫—Ç–æ –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª –∏ –Ω–µ –ø–∏—Å–∞–ª –≤ —á–∞—Ç!",
             message_thread_id=daily_stats_thread_id
             )
        return

    summary = "üìä –ò—Ç–æ–≥–∏ –¥–Ω—è:\n\n"
    medals = ["ü•á", "ü•à", "ü•â"]
    for i, (user_id, total_sentences, translated, missed, avg_minutes, total_time_minutes, avg_score, final_score) in enumerate(rows):
        username = all_users_today_interacted.get(int(user_id), f'–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}') # Get username, fallback if needed
        medal = medals[i] if i < len(medals) else "üí©"
        # Escape username for Markdown
        safe_username = escape_markdown(username)
        summary += (
            f"{medal} {safe_username}\n"
            f"üìú –ó–∞–¥–∞–Ω–æ: {total_sentences}\n"
            f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}\n"
            f"üö® –ù–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {missed}\n"
            f"‚è± –í—Ä–µ–º—è —Å—Ä–µ–¥–Ω–µ–µ: {avg_minutes:.1f} –º–∏–Ω\n"
            f"‚è± –í—Ä–µ–º—è –æ–±—â.: {total_time_minutes:.1f} –º–∏–Ω\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}/100\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {final_score:.1f}\n\n"
        )


    # üö® **–î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ –ø—Ä–æ –ª–µ–Ω–∏–≤—ã—Ö (–ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç, –Ω–æ –Ω–µ –±—ã–ª–∏ assigned sentences today)**
    if lazy_users_today:
        summary += "\nü¶• –õ–µ–Ω–∏–≤—Ü—ã (–ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç —Å–µ–≥–æ–¥–Ω—è, –Ω–æ –Ω–µ –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–≤–æ–¥):\n"
        for username in lazy_users_today.values():
            summary += f"üë§ {escape_markdown(username)}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É —Å–µ–≥–æ–¥–Ω—è!\n"

    await context.bot.send_message(
        chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
        text=summary,
        message_thread_id=daily_stats_thread_id, # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ T√§gliche Statistik
        parse_mode = "Markdown" # Use Markdown
        )



async def send_progress_report(context: CallbackContext):
    # ‚úÖ –û–ø—Ä–µ–¥–µ–ª—è–µ–º thread_id –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (—Ç–æ—Ç –∂–µ, —á—Ç–æ –∏ –¥–ª—è –∏—Ç–æ–≥–æ–≤ –¥–Ω—è)
    progress_report_thread_id = TOPICS_TELEGRAM["T√§gliche Statistik"].get("id")
    if progress_report_thread_id is None:
         logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ thread_id –¥–ª—è —Ç–µ–º—ã T√§gliche Statistik –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞!")
         return


    conn = get_db_connection()
    cursor = conn.cursor()

    # üîπ –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç **–∑–∞ —Å–µ–≥–æ–¥–Ω—è**
    cursor.execute("""
        SELECT DISTINCT user_id, username
        FROM messages_deepseek
        WHERE timestamp::date = CURRENT_DATE;
    """)
    all_users_today_interacted = {int(row[0]): row[1] for row in cursor.fetchall()}


    # üîπ –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º **–∑–∞ —Å–µ–≥–æ–¥–Ω—è**
    cursor.execute("""
       WITH UserDailySentences AS (
            SELECT user_id, COUNT(DISTINCT id) AS total_assigned
            FROM daily_sentences_deepseek
            WHERE date = CURRENT_DATE
            GROUP BY user_id
       ),
       UserDailyTranslations AS (
            SELECT
                t.user_id,
                COUNT(DISTINCT t.id) AS translated_count,
                COALESCE(AVG(t.score), 0) AS avg_score
            FROM translations_deepseek t
            WHERE t.timestamp::date = CURRENT_DATE
            GROUP BY t.user_id
       ),
       UserDailyProgress AS (
            SELECT user_id,
                AVG(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS avg_time,
                SUM(EXTRACT(EPOCH FROM (end_time - start_time))/60) AS total_time
            FROM user_progress_deepseek
            WHERE completed = true AND start_time::date = CURRENT_DATE
            GROUP BY user_id
       )
       SELECT
            uds.user_id,
            COALESCE(uds.total_assigned, 0) AS total_sentences,
            COALESCE(udt.translated_count, 0) AS translated,
            GREATEST(0, COALESCE(uds.total_assigned, 0) - COALESCE(udt.translated_count, 0)) AS missed,
            COALESCE(udp.avg_time, 0) AS avg_time_minutes,
            COALESCE(udp.total_time, 0) AS total_time_minutes,
            COALESCE(udt.avg_score, 0) AS avg_score,
            COALESCE(udt.avg_score, 0)
            - (COALESCE(udp.avg_time, 0) * 2)
            - (GREATEST(0, COALESCE(uds.total_assigned, 0) - COALESCE(udt.translated_count, 0)) * 20) AS final_score
       FROM UserDailySentences uds
       LEFT JOIN UserDailyTranslations udt ON uds.user_id = udt.user_id
       LEFT JOIN UserDailyProgress udp ON uds.user_id = udp.user_id
       ORDER BY final_score DESC;
    """)
    rows = cursor.fetchall()

    cursor.close()
    conn.close()

    # üîπ Identify users who had sentences assigned but didn't translate
    assigned_users_ids = {row[0] for row in rows}
    lazy_users_today = {uid: uname for uid, uname in all_users_today_interacted.items() if uid not in assigned_users_ids}


    # üîπ Formulate the report
    if not rows and not lazy_users_today:
        # No assigned sentences AND no chat interaction today, maybe skip intermediate report?
        logging.info("üìä –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å–µ–≥–æ–¥–Ω—è.")
        return

    current_time = datetime.now().strftime("%H:%M") # Shorter time format
    progress_report = f"üìä –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∏—Ç–æ–≥–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞ {current_time}:\n\n"

    # Sort rows again by final score descending
    rows.sort(key=lambda x: x[-1], reverse=True)

    for user_id, total, translated, missed, avg_minutes, total_minutes, avg_score, final_score in rows:
        username = all_users_today_interacted.get(int(user_id), f'–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}') # Get username, fallback
        # Escape username for Markdown
        safe_username = escape_markdown(username)
        progress_report += (
            f"üë§ {safe_username}\n"
            f"üìú –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}/{total}\n"
            f"üö® –ù–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {missed}\n"
            f"‚è± –í—Ä–µ–º—è —Å—Ä–µ–¥–Ω–µ–µ: {avg_minutes:.1f} –º–∏–Ω\n"
            f"‚è± –í—Ä–µ–º—è –æ–±—â.: {total_minutes:.1f} –º–∏–Ω\n"
            f"üéØ –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}/100\n"
            f"üèÜ –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª: {final_score:.1f}\n\n"
        )

    # üö® **–î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫ –ø—Ä–æ –ª–µ–Ω–∏–≤—ã—Ö (–ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç, –Ω–æ –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∏)**
    if lazy_users_today:
        progress_report += "\nü¶• –õ–µ–Ω–∏–≤—Ü—ã (–ø–∏—Å–∞–ª–∏ –≤ —á–∞—Ç —Å–µ–≥–æ–¥–Ω—è, –Ω–æ –Ω–µ –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–≤–æ–¥):\n"
        for username in lazy_users_today.values():
            progress_report += f"üë§ {escape_markdown(username)}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É —Å–µ–≥–æ–¥–Ω—è!\n"

    await context.bot.send_message(
        chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
        text=progress_report,
        message_thread_id=progress_report_thread_id, # ‚úÖ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —Ç–æ–ø–∏–∫ T√§gliche Statistik
        parse_mode = "Markdown" # Use Markdown
        )


async def force_finalize_sessions(context: CallbackContext = None):
    """–ó–∞–≤–µ—Ä—à–∞–µ—Ç –í–°–ï –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ —Ç–æ–ª—å–∫–æ –∑–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –≤ 23:59."""
    conn = get_db_connection()
    cursor = conn.cursor()

    cursor.execute("""
        UPDATE user_progress_deepseek
        SET end_time = NOW(), completed = TRUE
        WHERE completed = FALSE AND start_time::date = CURRENT_DATE;
    """)

    conn.commit()
    count = cursor.rowcount
    cursor.close()
    conn.close()

    if count > 0:
         await context.bot.send_message(
             chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID,
             text=f"üîî **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–∫—Ä—ã—Ç–æ {count} –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è!**",
             message_thread_id=TOPICS_TELEGRAM["General"].get("id") # Send to General
             )
    else:
         logging.info("‚úÖ –ù–µ—Ç –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π –∑–∞ —Å–µ–≥–æ–¥–Ω—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è.")
         # Optionally send a message if no sessions were closed
         # await context.bot.send_message(chat_id=TEST_DEEPSEEK_BOT_GROUP_CHAT_ID, text="–°–µ–≥–æ–¥–Ω—è –Ω–µ –±—ã–ª–æ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è.", message_thread_id=TOPICS_TELEGRAM["General"].get("id"))


async def error_handler(update, context):
    """Log the error and send a telegram message to the user."""
    # Log the error before sending a message
    logger.error("Exception while handling an update:", exc_info=context.error)

    try:
        # Try to get the chat and thread ID where the error occurred
        chat_id = update.effective_chat.id if update and update.effective_chat else None
        message_thread_id = update.effective_message.message_thread_id if update and update.effective_message else None
        user_id = update.effective_user.id if update and update.effective_user else None

        # Create error message
        error_message = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞."
        if user_id:
             error_message += f" (–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_id})"
        error_message += "\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."

        # Send message to the user/chat/thread where it happened
        if chat_id:
             await context.bot.send_message(
                 chat_id=chat_id,
                 text=error_message,
                 message_thread_id=message_thread_id
                 )
        else:
             # If cannot determine chat_id, perhaps send to a predefined admin chat
             logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —Ç.–∫. chat_id –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω.")

    except Exception as e:
        logger.error(f"‚ùå Exception while sending error message: {e}", exc_info=True)


async def main():
    # Initialize application
    application = Application.builder().token(TELEGRAM_TOKEN).build()
    
    # Initialize scheduler
    scheduler = AsyncIOScheduler()
    
    print("üìå Adding handlers...")
    # üîπ Logging for all messages (group -1, non-blocking)
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, log_message, block=False), group=-1)

    # Command handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("stats", user_stats))
    
    # Message handlers for user text input
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_user_message, block=False), group=1)
    
    # Reply keyboard button handlers
    application.add_handler(MessageHandler(filters.Text("üìå –í—ã–±—Ä–∞—Ç—å —Ç–µ–º—É") & ~filters.COMMAND, handle_reply_button_text), group=2)
    application.add_handler(MessageHandler(filters.Text("üöÄ –ù–∞—á–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥") & ~filters.COMMAND, handle_reply_button_text), group=2)
    application.add_handler(MessageHandler(filters.Text("üìú –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥") & ~filters.COMMAND, handle_reply_button_text), group=2)
    application.add_handler(MessageHandler(filters.Text("‚úÖ –ó–∞–≤–µ—Ä—à–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥") & ~filters.COMMAND, handle_reply_button_text), group=2)
    application.add_handler(MessageHandler(filters.Text("üü° –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞") & ~filters.COMMAND, handle_reply_button_text), group=2)
    
    # Inline button handlers
    application.add_handler(CallbackQueryHandler(handle_button_click))
    
    # Error handler
    application.add_error_handler(error_handler)
    
    # Set up scheduler jobs
    print("üìå Adding scheduler jobs...")
    
    # Morning reminders
    scheduler.add_job(
        send_morning_reminder, 
        "cron", 
        hour=6, 
        minute=30, 
        timezone='Europe/Berlin', 
        kwargs={'context': CallbackContext(application=application)}
    )
    
    # Other scheduled jobs
    scheduler.add_job(
        send_german_news, 
        "cron", 
        hour=6, 
        minute=45, 
        timezone='Europe/Berlin', 
        kwargs={'context': CallbackContext(application=application)}
    )
    
    scheduler.add_job(
        send_me_analytics_and_recommend_me, 
        "cron", 
        day_of_week="mon,wed", 
        hour=7, 
        minute=7, 
        timezone='Europe/Berlin', 
        kwargs={'context': CallbackContext(application=application)}
    )
    
    scheduler.add_job(
        force_finalize_sessions, 
        "cron", 
        hour=23, 
        minute=59, 
        timezone='Europe/Berlin', 
        kwargs={'context': CallbackContext(application=application)}
    )
    
    # Progress reports throughout the day
    for hour in [9, 14, 18]:
        scheduler.add_job(
            send_progress_report, 
            "cron", 
            hour=hour, 
            minute=5, 
            timezone='Europe/Berlin', 
            kwargs={'context': CallbackContext(application=application)}
        )
    
    # Daily summary
    scheduler.add_job(
        send_daily_summary, 
        "cron", 
        hour=22, 
        minute=45, 
        timezone='Europe/Berlin', 
        kwargs={'context': CallbackContext(application=application)}
    )
    
    # Weekly summary
    scheduler.add_job(
        send_weekly_summary, 
        "cron", 
        day_of_week="sun", 
        hour=22, 
        minute=55, 
        timezone='Europe/Berlin', 
        kwargs={'context': CallbackContext(application=application)}
    )
    
    # Initialize the application
    print("üîß Initializing Telegram bot...")
    await application.initialize()
    print("‚úÖ Bot initialized.")
    
    # Start the scheduler
    print("‚öôÔ∏è Starting APScheduler...")
    scheduler.start()
    print("‚úÖ APScheduler started.")
    
    # Start the bot
    print("üöÄ Starting bot...")
    await application.start()
    print("‚úÖ Bot started.")
    
    # Start polling
    print("üì° Starting polling...")
    await application.updater.start_polling(
        allowed_updates=[Update.MESSAGE.value, Update.CALLBACK_QUERY.value, Update.CHAT_MEMBER.value],
        drop_pending_updates=True
    )
    
    # Keep the application running
    print("üîÑ Bot is running. Press Ctrl+C to stop.")
    
    # This will keep the coroutine running until it's interrupted
    try:
        # This creates a never-ending task that prevents the coroutine from exiting
        stopping_signal = asyncio.Future()
        await stopping_signal
    except asyncio.CancelledError:
        # Handle cancellation (e.g., KeyboardInterrupt)
        pass
    finally:
        # Clean shutdown
        print("üõë Stopping bot and scheduler...")
        await application.updater.stop()
        await application.stop()
        await application.shutdown()
        scheduler.shutdown()
        print("‚úÖ Bot and scheduler stopped.")

if __name__ == "__main__":
    try:
        # Run the bot
        asyncio.run(main())
    except KeyboardInterrupt:
        print("Bot stopped by user")
    except Exception as e:
        print(f"Error in main: {e}")

# **Summary of Changes and Explanations:**

# 1.  **`start` function:**
#     *   Removed the commented-out line and added `message_thread_id = update.message.message_thread_id`.
#     *   Passed `message_thread_id=message_thread_id` to `context.bot.send_message`. When called inside a topic, this will be the topic's ID. When called in the main chat, it will be `None`, and Telegram handles sending to the main chat. This is the primary fix for the ReplyKeyboardMarkup not appearing in topics.

# 2.  **Scheduled Functions (`send_german_news`, `send_me_analytics_and_recommend_me`, `send_weekly_summary`, `send_daily_summary`, `send_progress_report`, `force_finalize_sessions`):**
#     *   Each function now retrieves the appropriate `thread_id` from `TOPICS_TELEGRAM` using `.get("id")` for safety.
#     *   It checks if the `thread_id` is `None` and logs an error if the topic ID is not found (this means the topic might not be created or the ID is wrong in the config).
#     *   The `thread_id` is passed to `context.bot.send_message`. This ensures news goes to the Nachrichten topic, different stats reports go to the T√§gliche/W√∂chenliche Statistik topics, recommendations go to Empfehlungen, and morning/final messages go to General.

# 3.  **`handle_button_click`:**
#     *   Corrected to only run if `update.callback_query` is present (it's registered as a `CallbackQueryHandler`).
#     *   Ensured `chat_id` and `message_thread_id` are correctly extracted from `query.message`.
#     *   Added a check if the clicked button (`query.data`) is allowed within the topic identified by `message_thread_id`. This prevents users from clicking "Start Translation" if the button somehow appears in the "News" topic, for example.
#     *   Added a fallback message and button removal if the button is not allowed or the topic is not found.
#     *   Clarified the `explain:` callback data handling, ensuring data is retrieved from `context.user_data` and passed to `check_translation_with_claude`. Changed the context key name slightly (`translation_for_claude_`) to be more specific.

# 4.  **`handle_user_message`:**
#     *   Added a check at the beginning to ignore messages starting with `/`, letting the `CommandHandler`s handle them.
#     *   Removed the incorrect call to `handle_button_click(update, context)` at the end. This function is only for processing text matching the numbered translation pattern.
#     *   Updated regex to handle multi-line translations slightly better and added error logging for unparseable lines.
#     *   Sent confirmation message back to the `message_thread_id` where the translation was sent.

# 5.  **`check_translation` and `check_translation_with_claude`:**
#     *   Ensured `target_thread_id` is correctly identified using `.get("id")` from `TOPICS_TELEGRAM`.
#     *   Added fallback logic to send messages to the effective thread ID (where the action originated) if the predefined topic ID is missing.
#     *   Updated `simulate_typing` and `edit_message_text` calls to use the correct `target_thread_id`.
#     *   Used `escape_markdown_v2` for message text and `parse_mode="MarkdownV2"` for better compatibility.
#     *   Added basic error handling for Telegram API errors during message editing.
#     *   Corrected logging of parsed data.

# 6.  **`log_translation_mistake`:**
#     *   Improved input validation and logging.
#     *   Enhanced logic to match normalized (lowercase) categories/subcategories against the validation lists.
#     *   Ensured original casing is restored when inserting into the database.
#     *   Added logging and rollback for database errors.

# 7.  **`check_user_translation`:**
#     *   Modified to accept the list of pending translations directly.
#     *   Added more robust parsing of the `pending_translations_list`.
#     *   Included checks to prevent double-checking translations for the same user and sentence on the same day.
#     *   Ensured `log_translation_mistake` is called correctly.

# 8.  **`get_original_sentences`:**
#     *   Slightly refined the logic to prioritize recent mistake sentences, then general ones, then GPT-generated ones, and shuffled the final list.
#     *   Added error handling and fallback if sentence retrieval/generation fails.

# 9.  **`search_youtube_videous`:**
#     *   Added `relevanceLanguage="de"` and `regionCode="DE"` to search queries for better German results.
#     *   Refined search logic to try preferred channels first, then broader search if not enough videos are found.
#     *   Used `escape_markdown_v2` for YouTube titles and URLs in the final Markdown links.

# 10. **`rate_mistakes`:**
#     *   Updated SQL query to count *unique* translated sentences per week.
#     *   Added calculation for *total sentences assigned* in the last week to correctly calculate *missed* sentences.
#     *   Refined the CTEs (Common Table Expressions) in the SQL to more correctly identify the top mistake category and subcategories based on counts in the last 7 days.
#     *   Added checks for NULL results from subqueries.

# 11. **`send_me_analytics_and_recommend_me`:**
#     *   Ensured the user list includes anyone with *any* activity (translations or mistakes) in the last week.
#     *   Only requests a topic from GPT if there were mistakes.
#     *   Used `escape_markdown_v2` for Markdown formatting.
#     *   Included the recommended topic in code block format.

# 12. **`send_daily_summary` and `send_progress_report`:**
#     *   Updated SQL queries to use more accurate CTEs (based on the weekly summary query structure) to calculate stats per user based on assigned sentences, translations, and progress entries *only for the current day*.
#     *   Identified "lazy" users as those who *interacted* (sent messages) today but had *no sentences assigned* (meaning they didn't start a session) today.
#     *   Used `escape_markdown` for usernames in summaries.

# 13. **`main` function:**
#     *   Registered specific `MessageHandler`s for the *text* of each button in `MAIN_MENU`. These point to `handle_reply_button_text`, which then calls the appropriate function.
#     *   Removed the incorrect `MessageHandler(filters.TEXT & ~filters.COMMAND, handle_button_click, block=False), group=1)`.
#     *   Switched from `BackgroundScheduler` to `AsyncIOScheduler` to allow scheduled jobs to directly use `await` and Telegram API calls without needing a helper `run_async_job` wrapper (which can sometimes cause event loop issues).
#     *   Added timezones to scheduled jobs (`timezone='Europe/Berlin'`).
#     *   Ensured `context=CallbackContext(application=application)` is passed to scheduled job functions where needed.
#     *   Refined `allowed_updates` in `application.run_polling` for better performance.

# These changes should address the ReplyKeyboardMarkup issue in topics and properly route your scheduled reports to the configured topic threads.–•–æ—Ä–æ—à–æ, –¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –Ω–æ–≤—É—é –æ—à–∏–±–∫—É:
